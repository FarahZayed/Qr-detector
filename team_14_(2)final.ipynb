{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LieUdBISTZO8",
        "3imjv2MEUQYc",
        "vvu_ikY4SFz1"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FarahZayed/Qr-detector/blob/master/team_14_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **import** **libraries**"
      ],
      "metadata": {
        "id": "UOj6ulzFR7Ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade reedsolo\n",
        "import reedsolo as rs"
      ],
      "metadata": {
        "id": "ErfNmQ3MC7ra",
        "outputId": "abe5cd13-0c0b-44bf-df8a-f240cdcbcaea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reedsolo in /usr/local/lib/python3.10/dist-packages (1.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgLWkJvJR5Tu"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import reedsolo\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFilter\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import io, color, filters, feature\n",
        "from math import sqrt\n",
        "from scipy.ndimage import binary_opening"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTmbo0e1y_2L",
        "outputId": "f30286ce-14b2-40df-825e-c34f7252ce51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the image"
      ],
      "metadata": {
        "id": "c3EIx7B1SRfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#insert the path of the image\n",
        "img = cv2.imread(\"/content/drive/MyDrive/testcases/01-Getting-started.png\", cv2.IMREAD_GRAYSCALE)"
      ],
      "metadata": {
        "id": "3ShONM6vSXcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Function ma7tgnha"
      ],
      "metadata": {
        "id": "0pH4EtGBSPDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def angle_ABC(a, b, c):\n",
        "    ba = a - b\n",
        "    bc = c - b\n",
        "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "    angle = np.arccos(cosine_angle)\n",
        "    return np.degrees(angle)\n",
        "\n",
        "def find_bad_dists(hull, distance = 10):\n",
        "    mask = []\n",
        "    points, _, _ = hull.shape\n",
        "    for i in range(points):\n",
        "        ai = i\n",
        "        bi = (i+1)%points\n",
        "        x1 = hull[ai][0][0]\n",
        "        y1 = hull[ai][0][1]\n",
        "        x2 = hull[bi][0][0]\n",
        "        y2 = hull[bi][0][1]\n",
        "\n",
        "\n",
        "        dist = np.sqrt((x2 - x1)**2 + (y2 - y1)**2 )\n",
        "        if dist < distance:\n",
        "            mask.append(bi)\n",
        "    return mask\n",
        "\n",
        "\n",
        "\n",
        "def find_bad_angles(hull, acute_angle = 30, obtuse_angle = 140):\n",
        "    mask = []\n",
        "    points, _, _ = hull.shape\n",
        "    for i in range(points):\n",
        "        ai = i\n",
        "        bi = (i+1)%points\n",
        "        ci = (i+2)%points\n",
        "\n",
        "        a = hull[ai][0]\n",
        "        b = hull[bi][0]\n",
        "        c = hull[ci][0]\n",
        "        angle = angle_ABC(a, b, c)\n",
        "        if angle > obtuse_angle or angle < acute_angle:\n",
        "            mask.append(bi)\n",
        "    return mask\n",
        "\n",
        "def mark_points(hull):\n",
        "    a_list=[]\n",
        "    points, _, _ = hull.shape\n",
        "    for i in range(points):\n",
        "        r = int(np.random.randint(100,255,1)[0])\n",
        "        g = int(np.random.randint(100,255,1)[0])\n",
        "        b = int(np.random.randint(100,255,1)[0])\n",
        "        a_list.append(tuple([hull[i][0][0], hull[i][0][1]]))\n",
        "\n",
        "    return a_list\n",
        "\n",
        "\n",
        "\n",
        "def shahd(img,thresh):\n",
        "\n",
        "        invimg = invert_image(img)\n",
        "\n",
        "        ret,thresh = cv2.threshold(invimg,127,255,0)\n",
        "\n",
        "        contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        length = len(contours)\n",
        "        cont = np.concatenate([contours[i] for i in range(length)], axis=0)\n",
        "\n",
        "        cnt_len = cv2.arcLength(cont, True)\n",
        "        cont = cv2.approxPolyDP(cont, .01*cnt_len, True)\n",
        "        hull = cv2.convexHull(cont)\n",
        "\n",
        "\n",
        "        mask = find_bad_dists(hull)\n",
        "        hull = np.delete(hull, mask, axis=0)\n",
        "\n",
        "        mask = find_bad_angles(hull)\n",
        "        hull = np.delete(hull, mask, axis=0)\n",
        "\n",
        "        a_list=mark_points(hull)\n",
        "\n",
        "        uni_hull = []\n",
        "        uni_hull.append(hull)\n",
        "\n",
        "\n",
        "        shahdlist =  mark_points(hull)\n",
        "        return shahdlist\n",
        "\n",
        "def find_first_black_pixel(img):\n",
        "    start_row = -1\n",
        "    start_col = -1\n",
        "    end_row=-1\n",
        "    consecutive_black = 0\n",
        "    for row_index, row in enumerate(img):\n",
        "        for pixel in row:\n",
        "            if pixel == 255:\n",
        "                consecutive_black = 0  # Reset counter if white pixel encountered\n",
        "            else:\n",
        "                consecutive_black += 1\n",
        "                if consecutive_black == 5:\n",
        "                    start_row = row_index\n",
        "                    break\n",
        "        if start_row != -1:\n",
        "            break\n",
        "\n",
        "    for col_index, col in enumerate(cv2.transpose(img)):\n",
        "      for pixel in col:\n",
        "        if pixel != 255:\n",
        "            start_col = col_index\n",
        "            break\n",
        "      if start_col != -1:\n",
        "        break\n",
        "    return (start_row,start_col)\n",
        "\n"
      ],
      "metadata": {
        "id": "OJByWf-9B_h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def remove_quietnoise(img):\n",
        "    start_row = -1\n",
        "    start_col = -1\n",
        "    end_row = -1\n",
        "    end_col = -1\n",
        "\n",
        "    for row_index, row in enumerate(img):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                start_row = row_index\n",
        "                break\n",
        "        if start_row != -1:\n",
        "            break\n",
        "\n",
        "    for row_index, row in enumerate(img[::-1]):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                end_row = img.shape[0] - row_index\n",
        "                break\n",
        "        if end_row != -1:\n",
        "            break\n",
        "\n",
        "    for col_index, col in enumerate(cv2.transpose(img)):\n",
        "        for pixel in col:\n",
        "            if pixel != 255:\n",
        "                start_col = col_index\n",
        "\n",
        "                break\n",
        "        if start_col != -1:\n",
        "            break\n",
        "\n",
        "    for col_index, col in enumerate(cv2.transpose(img)[::-1]):\n",
        "        for pixel in col:\n",
        "            if pixel != 255:\n",
        "                end_col = img.shape[1] - col_index\n",
        "                break\n",
        "        if end_col != -1:\n",
        "            break\n",
        "    if(start_row==0 and start_col==0):\n",
        "      start_row =img.shape[0]- end_row\n",
        "      start_col= img.shape[1]- end_col\n",
        "      print(start_row, start_col)\n",
        "    qr_no_quiet_zone = img[start_row:end_row, start_col:end_col]\n",
        "\n",
        "    return qr_no_quiet_zone\n",
        "\n",
        "\n",
        "def distance(point1, point2):\n",
        "    return sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
        "\n",
        "\n",
        "def butterworthLP(D0, imgShape, n):\n",
        "    base = np.zeros(imgShape[:2])\n",
        "    rows, cols = imgShape[:2]\n",
        "    center = (rows / 2, cols / 2)\n",
        "    for x in range(cols):\n",
        "        for y in range(rows):\n",
        "            base[y, x] = 1 / (1 + (distance((y, x), center) / D0) ** (2 * n))\n",
        "    return base\n",
        "\n",
        "def getcellsize(imgremove):\n",
        "    size=0\n",
        "    for pixel in imgremove[0]:\n",
        "      if (pixel != 0): break\n",
        "      size += 1\n",
        "    if(size ==0): return 0,0\n",
        "    grid_cell_size = round(size/7)\n",
        "    grid_cells_num = round(imgremove.shape[0]/grid_cell_size)\n",
        "    return grid_cell_size,grid_cells_num\n",
        "\n",
        "\n",
        "def get_start_row_col(img):\n",
        "    start_row = -1\n",
        "    start_col = -1\n",
        "    for row_index, row in enumerate(img):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                start_row = row_index\n",
        "                break\n",
        "        if start_row != -1:\n",
        "            break\n",
        "    for col_index, col in enumerate(cv2.transpose(img)):\n",
        "        for pixel in col:\n",
        "            if pixel != 255:\n",
        "                start_col = col_index\n",
        "                break\n",
        "        if start_col != -1:\n",
        "            break\n",
        "    return start_row, start_col\n",
        "\n",
        "\n",
        "def getcellsizeForRotation(imgremove):\n",
        "    size=0\n",
        "    for pixel in imgremove[-1, ::-1]:\n",
        "      if (pixel != 0): break\n",
        "      size += 1\n",
        "    if(size ==0): return 0,0\n",
        "    grid_cell_size = round(size/7)\n",
        "    grid_cells_num = round(imgremove.shape[0]/grid_cell_size)\n",
        "    return grid_cell_size,grid_cells_num\n",
        "\n",
        "\n",
        "def getqrcell(remove, grid_cell_size, grid_cells_num):\n",
        "    if remove.shape[0] % grid_cell_size != 0 or remove.shape[1] % grid_cell_size != 0:\n",
        "            value=grid_cell_size*grid_cells_num\n",
        "            print(value)\n",
        "            print(\"Warning: Grid cell size resulted in fraction. Adjusting...\")\n",
        "            img_resized = cv2.resize(remove, (value,value))\n",
        "            # remove=img_resized\n",
        "\n",
        "    # If the resized image is larger than the target size, crop it\n",
        "            if remove.shape[0] > value or remove.shape[1] > value:\n",
        "                remove = img_resized[:value, :value]\n",
        "            else:\n",
        "                remove = img_resized\n",
        "    try:\n",
        "            qr_cells = remove.reshape((\n",
        "            grid_cells_num,\n",
        "            grid_cell_size,\n",
        "            grid_cells_num,\n",
        "            grid_cell_size,\n",
        "            )).swapaxes(1, 2)\n",
        "\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"Error: Unable to reshape image into grid cells.\")\n",
        "        qr_cells=0\n",
        "    return qr_cells\n",
        "\n"
      ],
      "metadata": {
        "id": "LkeUEJYZSmMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# function that raise the flags"
      ],
      "metadata": {
        "id": "LieUdBISTZO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def checkrotation(img):\n",
        "\n",
        "    imgremove= remove_quietnoise(img)\n",
        "    grid_cell_size,grid_cell_num= getcellsizeForRotation(imgremove)\n",
        "\n",
        "    if grid_cell_size==0:\n",
        "        print(\"The image is not rotated it may have some other noise that must be solved first!!!\")\n",
        "        return False\n",
        "    inverted_img = cv2.bitwise_not(imgremove)\n",
        "    shapeofste=3*grid_cell_size -1\n",
        "    se_rect = cv2.getStructuringElement(cv2.MORPH_RECT, (shapeofste, shapeofste))\n",
        "    _, se_binarized = cv2.threshold(se_rect, 128, 1, cv2.THRESH_BINARY)\n",
        "    se_binarized = se_binarized.astype(int)\n",
        "    se_binarized[se_binarized == 0] = -1\n",
        "    erosion = cv2.erode(inverted_img, se_rect, iterations=1)\n",
        "    partwithrotato=erosion[(imgremove.shape[0]-7*grid_cell_size):imgremove.shape[0], imgremove.shape[1]-7*grid_cell_size:imgremove.shape[1]];\n",
        "    count=0\n",
        "    for row in range(partwithrotato.shape[0]):\n",
        "        for col in range(partwithrotato.shape[1]):\n",
        "            if partwithrotato[row,col] == 255:\n",
        "                count=count+1\n",
        "    if(count>0 and count<10):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def checkblured(image):\n",
        "    f_transform = np.fft.fft2(image)\n",
        "    f_transform_shifted = np.fft.fftshift(f_transform)\n",
        "    magnitude_spectrum = 20*np.log(np.abs(f_transform_shifted))\n",
        "    rows, cols = image.shape\n",
        "    center_row = rows // 2\n",
        "    center_col = cols // 2\n",
        "    roi_size = 10\n",
        "    dc_component = magnitude_spectrum[center_row, center_col]\n",
        "    roi = magnitude_spectrum[center_row - roi_size:center_row + roi_size + 1,\n",
        "                              center_col - roi_size:center_col + roi_size + 1]\n",
        "    avg_roi = round(np.mean(roi))\n",
        "    if(np.mean(magnitude_spectrum[100:-100, 100:-100])== float('-inf')):\n",
        "        return False\n",
        "    else:\n",
        "        high_freq_avg=round(np.mean(magnitude_spectrum[100:-100, 100:-100]))\n",
        "\n",
        "    low_accepted_freqcompatcenter=290\n",
        "    highest_accepted_change=120\n",
        "    if(avg_roi>290 and high_freq_avg<120):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "#check mostly white\n",
        "def is_mostly_white(img):\n",
        "    row, col = img.shape\n",
        "    count=0\n",
        "    for i in range(row):\n",
        "        for j in range(col):\n",
        "            if (img[i][j] < 150) :\n",
        "                count=count+1\n",
        "    if count>0:\n",
        "       return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "#check shifting\n",
        "\n",
        "def detect_shift_rows(img):\n",
        "    row,col=get_start_row_col(img)\n",
        "    print(row,col)\n",
        "    count_black =0\n",
        "    count_white =0\n",
        "    flag=True\n",
        "    first_black_pixel = 0\n",
        "    last_black_pixel = 0\n",
        "    for i in range(len(img[row])-1):\n",
        "        if img[row][i] !=255:\n",
        "            first_black_pixel = i\n",
        "            count_black=count_black+1\n",
        "        if count_black==1:\n",
        "            break\n",
        "    for j in range(first_black_pixel,len(img[row])-1):\n",
        "        if img[row][j]!=0:\n",
        "            last_black_pixel=j-1\n",
        "            count_white+=1\n",
        "        if count_white==1:\n",
        "            break\n",
        "    for k in range(first_black_pixel,last_black_pixel):\n",
        "       if img[row][k]!=0:\n",
        "          flag=False\n",
        "\n",
        "\n",
        "    if row>0 and col>0 and col!=0 and row!=0 and col!=row and flag==True:\n",
        "        if 0<(row-col) and (row-col)<12:\n",
        "            return True\n",
        "        else:\n",
        "          return False\n",
        "    else:\n",
        "          return False\n",
        "\n",
        "\n",
        "#checks skewness\n",
        "def checkskew(img):\n",
        "    skewflag=False\n",
        "    unwarpedflag=False\n",
        "    img = np.uint8(img)\n",
        "    edges = cv2.Canny(img, 100, 200)\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if(contours ==() ):\n",
        "        return skewflag,unwarpedflag\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "    qr_code_region = img[y:y + h, x:x + w]\n",
        "    edges = cv2.Canny(qr_code_region, 50, 150, apertureSize=3)\n",
        "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)\n",
        "    if lines is None:\n",
        "        return skewflag,unwarpedflag\n",
        "    vertical_angles = []\n",
        "    horizontal_angles = []\n",
        "\n",
        "    for line in lines:\n",
        "        rho, theta = line[0]\n",
        "        if np.pi / 4 < theta < 3 * np.pi / 4:\n",
        "            vertical_angles.append(theta)\n",
        "        else:\n",
        "            horizontal_angles.append(theta)\n",
        "    vertical_skewness = np.mean(vertical_angles) if vertical_angles else 0\n",
        "    horizontal_skewness = np.mean(horizontal_angles) if horizontal_angles else 0\n",
        "\n",
        "    vertical_skewness_deg = round(np.rad2deg(vertical_skewness))\n",
        "    horizontal_skewness_deg = round(np.rad2deg(horizontal_skewness))\n",
        "    difference=round(abs(horizontal_skewness_deg - vertical_skewness_deg))\n",
        "    if(difference==90 and vertical_skewness_deg!=90 and horizontal_skewness_deg!=90):\n",
        "        skewflag=True\n",
        "        return skewflag,unwarpedflag\n",
        "    elif(horizontal_skewness_deg < 90 and horizontal_skewness_deg>10 and vertical_skewness_deg<90):\n",
        "        unwarpedflag=True\n",
        "        return skewflag,unwarpedflag\n",
        "    else:\n",
        "        return skewflag,unwarpedflag\n",
        "\n",
        "\n",
        "#check black image\n",
        "def is_mostly_black(image):\n",
        "    image = np.uint8(image)\n",
        "    hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
        "    hist /= hist.sum()\n",
        "\n",
        "    cumulative_sum = hist.cumsum()\n",
        "\n",
        "    return cumulative_sum.argmax() < 30\n",
        "\n",
        "def checkflip(img):\n",
        "    flipped_image = cv2.flip(img, 1) # original  flipp\n",
        "    imgremove = remove_quietnoise(flipped_image)\n",
        "    grid_cell_size,grid_cells_num=getcellsize(imgremove)\n",
        "    if grid_cell_size==0 or (grid_cell_size<20 or grid_cell_size>50): return False\n",
        "    print(\"##########################\")\n",
        "    print(grid_cell_size)\n",
        "    qr_cells=getqrcell(imgremove,grid_cell_size,grid_cells_num)\n",
        "    if isinstance(qr_cells, (int)):\n",
        "        print(\"cant do qrcell\")\n",
        "        return False\n",
        "    qr_cells_numeric = np.ndarray((grid_cells_num, grid_cells_num), dtype=np.uint8)\n",
        "    for i, row in enumerate(qr_cells):\n",
        "      for j, cell in enumerate(row):\n",
        "          qr_cells_numeric[i, j] = (np.median(cell) // 255)\n",
        "\n",
        "    fec = []\n",
        "    fec.append(qr_cells_numeric[8, 0:6])\n",
        "    fec.extend(qr_cells_numeric[8, 7:8])\n",
        "\n",
        "    fec.extend(qr_cells_numeric[0:6, 8])\n",
        "    fec.extend(qr_cells_numeric[7:9, 8])\n",
        "    fec = [int(c) for sublist in fec for c in (sublist.ravel() if isinstance(sublist, np.ndarray) else [sublist])]\n",
        "\n",
        "    fec2 = []\n",
        "    fec2.append(qr_cells_numeric[-1:-8:-1, 8])\n",
        "    fec2.extend(qr_cells_numeric[8, -1:-9:-1])\n",
        "    fec2 = [int(c) for sublist in fec2 for c in (sublist.ravel() if isinstance(sublist, np.ndarray) else [sublist])]\n",
        "\n",
        "    if (np.array_equal(fec2, fec)):\n",
        "      print(\"photo was flipped\")\n",
        "      return True\n",
        "    else:\n",
        "      print(\"not flipped\")\n",
        "      return False\n",
        "\n",
        "def inversioncheck(img):\n",
        "    mean_intensity = cv2.mean(img)[0]\n",
        "    return (mean_intensity < 100 and mean_intensity>30)\n",
        "\n",
        "\n",
        "def detect_periodic_noise(image,threshold_factor=1 / 4):\n",
        "    resized_image = cv2.resize(image, (256, 256))\n",
        "    fft_image = np.fft.fft2(resized_image)\n",
        "    max_intensity = np.max(fft_image)\n",
        "\n",
        "    high_frequency_component = np.abs(np.fft.fftshift(fft_image)[:, :fft_image.shape[1] // 2])\n",
        "    max_high_frequency_component = np.max(high_frequency_component)\n",
        "    noise_threshold = max_intensity * threshold_factor\n",
        "    if max_high_frequency_component > noise_threshold:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def detect_patterns_in_roi(image, threshold_factor=1.2):\n",
        "    resized_image = cv2.resize(image, (256, 256))\n",
        "    dft_noise = np.fft.fft2(resized_image)\n",
        "    dft_noise_shift = np.fft.fftshift(dft_noise)\n",
        "    epsilon = 1e-10\n",
        "    magnitude_spectrum = 20 * np.log(np.abs(dft_noise_shift)+ epsilon)\n",
        "\n",
        "    rows, cols = dft_noise_shift.shape\n",
        "    center_row, center_col = rows // 2, cols // 2\n",
        "\n",
        "    roi_size = 250\n",
        "    roi = magnitude_spectrum[center_row - roi_size:center_row + roi_size,\n",
        "                          center_col - roi_size:center_col + roi_size]\n",
        "\n",
        "    roi_mean = np.mean(roi)\n",
        "\n",
        "    threshold = threshold_factor * roi_mean\n",
        "\n",
        "    significant_peaks_exist = np.any(roi > threshold)\n",
        "    if significant_peaks_exist:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "\n",
        "\n",
        "# FROM COLUMN: 44 TO 352 CHECK IF THERE EXSITS ANY WHITE PIXELS---> 48 to 336=7x48\n",
        "\n",
        "def detect_espreso(img):\n",
        "    cell_size,_= [int(x) // 21 for x in img.shape]\n",
        "    locator_box_width=7 *cell_size #7X7\n",
        "    start_row,start_col = find_first_black_pixel(img)\n",
        "    # FLAG\n",
        "    espresso = False\n",
        "    # if start_row!= 44:\n",
        "    #  espresso = False\n",
        "    # else:\n",
        "    white_counter=0\n",
        "    end_col= locator_box_width + start_row\n",
        "    for col in range(start_col, end_col): #LOCATOR BOX WIDTH. 352= 44+308\n",
        "        # print(img[start_row, col])\n",
        "        if img[start_row, col] == 255:  # CHECK intensity at (0, col) FISRT ROW\n",
        "            white_counter +=1\n",
        "        if white_counter ==2:\n",
        "            espresso = True\n",
        "            break  # EXIT IF WHITE FOUND\n",
        "    return espresso\n"
      ],
      "metadata": {
        "id": "RKjHTS4TTYM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# flags to do preprocessing"
      ],
      "metadata": {
        "id": "PzSFn2IAS6EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotationflag= checkrotation(img)\n",
        "\n",
        "SaltandPepper = detect_patterns_in_roi(img)\n",
        "\n",
        "bluredflag =checkblured(img)\n",
        "\n",
        "shiftedrowsflag= detect_shift_rows(img)\n",
        "\n",
        "mostlywhiteflag= is_mostly_white(img)\n",
        "\n",
        "periodicflag = detect_periodic_noise(img)\n",
        "\n",
        "skewedflag,unwarpedflag = checkskew(img)\n",
        "\n",
        "mostlyblackflag=is_mostly_black(img)\n",
        "\n",
        "inversionflag=inversioncheck(img)\n",
        "\n",
        "flipflag =checkflip(img)\n",
        "\n",
        "\n",
        "print(\"The flag of inverted image : \",inversionflag )\n",
        "print(\"The flag of rotation: \",rotationflag )\n",
        "print(\"The flag of all white image: \",mostlywhiteflag )\n",
        "print(\"The flag of blured image: \",bluredflag )\n",
        "print(\"The flag of shifted rows: \",shiftedrowsflag )\n",
        "print(\"The flag of periodic noise: \",periodicflag )\n",
        "print(\"The flag of skewed images : \",skewedflag )\n",
        "print(\"The flag of all black image : \",mostlyblackflag )\n",
        "print(\"The flag of unwarped image : \",unwarpedflag )\n",
        "print(\"The flag of flipped image : \",flipflag )\n",
        "print(\"The flag of saltandpepper image : \",SaltandPepper )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFBLVZSoTGFT",
        "outputId": "8e4387c2-0189-49cc-c992-da2cd4596f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image is not rotated it may have some other noise that must be solved first!!!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-685-a82f630d0ecb>:30: RuntimeWarning: divide by zero encountered in log\n",
            "  magnitude_spectrum = 20*np.log(np.abs(f_transform_shifted))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44 44\n",
            "##########################\n",
            "44\n",
            "not flipped\n",
            "The flag of inverted image :  False\n",
            "The flag of rotation:  False\n",
            "The flag of all white image:  False\n",
            "The flag of blured image:  False\n",
            "The flag of shifted rows:  False\n",
            "The flag of periodic noise:  False\n",
            "The flag of skewed images :  False\n",
            "The flag of all black image :  False\n",
            "The flag of unwarped image :  False\n",
            "The flag of flipped image :  False\n",
            "The flag of saltandpepper image :  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function responsible for preprocessing"
      ],
      "metadata": {
        "id": "3imjv2MEUQYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def invert_image(image):\n",
        "\n",
        "    _,img = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY)\n",
        "    inverted_image=cv2.bitwise_not(img)\n",
        "    return inverted_image\n",
        "\n",
        "def a3dlrotation(img):\n",
        "    print(\"in\")\n",
        "    imgremove= remove_quietnoise(img)\n",
        "    while(checkrotation(imgremove)):\n",
        "        imgremove = cv2.rotate(imgremove, cv2.ROTATE_90_CLOCKWISE)\n",
        "    return imgremove\n",
        "\n",
        "def flip(img):\n",
        "\n",
        "    img=cv2.flip(img,1)\n",
        "    return img\n",
        "\n",
        "def nadafblured(img):\n",
        "         # nazbt el soraa\n",
        "        blurred = cv2.GaussianBlur(img, (7, 7), 0)\n",
        "        sharpened = cv2.addWeighted(img, 2.5, blurred, -0.5, 0)\n",
        "        _, thresh_img = cv2.threshold(sharpened, 127, 255, cv2.THRESH_BINARY)\n",
        "        #shalena el noise w shwait araf erode keda\n",
        "        remove= remove_quietnoise(thresh_img)\n",
        "        se_rect = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
        "        _, se_binarized = cv2.threshold(se_rect, 128, 1, cv2.THRESH_BINARY)\n",
        "        se_binarized = se_binarized.astype(int)\n",
        "        se_binarized[se_binarized == 0] = -1\n",
        "        erosion = cv2.erode(remove, se_binarized, iterations=1)\n",
        "        needcorrectionimg=erosion\n",
        "        return needcorrectionimg\n",
        "\n",
        "def unwarped(img,thresh):\n",
        "        listt  = shahd(img,thresh)\n",
        "        rows1 , cols1  = img.shape\n",
        "        pts2 = np.array([[cols1,0],[cols1,rows1],[0,rows1], [0,0]],np.float32)\n",
        "        pts1 = np.array(listt,np.float32)\n",
        "        M = cv2.getPerspectiveTransform(pts1,pts2)\n",
        "        dst = cv2.warpPerspective(img,M,(cols1,rows1))\n",
        "        return dst\n",
        "\n",
        "def decompresso_espreso(img):\n",
        "    _, imgBinary = cv2.threshold(img, 170, 255, cv2.THRESH_BINARY)\n",
        "    # GAUSSIAN BLUR\n",
        "    blurred = cv2.GaussianBlur(imgBinary, (5, 5), 0)\n",
        "    # OPENNING= EROSION THEN DILATION & FINE TUNING ITERATION PARAMTER ++++++  WITH A 5X5 KERNEL\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    eroded = cv2.erode(blurred, kernel, iterations=6)  # TILL 6TH ITERATION LOCATOR BOX CONTAIN WHITE PIXELS\n",
        "    dilated = cv2.dilate(eroded, kernel, iterations=5)  # NUMBER OF ITERATIONS DE RAGA3 SIZE MAZBOOT --> 44 WA 968\n",
        "    # FOR REMOVAL OF GREY PIXELS\n",
        "    for row in range(dilated.shape[0]):\n",
        "        for col in range(dilated.shape[1]):\n",
        "            # Check if pixel intensity is between 0 and 255\n",
        "            if 0 < dilated[row, col] < 255:\n",
        "                dilated[row, col] = 255  # Convert to white (255)\n",
        "\n",
        "    return dilated\n",
        "\n",
        "def edit_white_img(img):\n",
        "    first_pixel=img[0,0]\n",
        "    for i in range(img.shape[0]):\n",
        "        for j in range(img.shape[1]):\n",
        "            if img[i][j] == first_pixel:\n",
        "                img[i][j] = 255\n",
        "            else:\n",
        "                img[i][j] = 0\n",
        "    #nfr2 ma ben malak w brwana\n",
        "    if(detect_espreso(img)):\n",
        "        img= decompresso_espreso(img)\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "def solve_shifted_rows(img):\n",
        "    start_row = -1\n",
        "    start_col = -1\n",
        "    end_row = -1\n",
        "    end_col = -1\n",
        "    _, img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
        "    for row_index, row in enumerate(img):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                start_row = row_index\n",
        "                start_col =row_index\n",
        "                break\n",
        "        if start_row != -1:\n",
        "            break\n",
        "\n",
        "    for row_index, row in enumerate(img[::-1]):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                end_row = img.shape[0] - row_index\n",
        "                end_col =img.shape[0] - row_index\n",
        "                break\n",
        "        if end_row != -1:\n",
        "            break\n",
        "\n",
        "\n",
        "    qr_no_quiet_zone = img[start_row:end_row, start_col:end_col]\n",
        "\n",
        "    size = 0\n",
        "    for pixel in qr_no_quiet_zone[0]:\n",
        "        if (pixel != 0): break\n",
        "        size += 1\n",
        "\n",
        "    grid_cell_size = round(size/7)\n",
        "    grid_cells_num = round(qr_no_quiet_zone.shape[0]/grid_cell_size)\n",
        "\n",
        "    img_resized = cv2.resize(qr_no_quiet_zone, (grid_cells_num*grid_cell_size, grid_cells_num*grid_cell_size))\n",
        "\n",
        "    qr_cells = img_resized.reshape((\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "    )).swapaxes(1, 2)\n",
        "\n",
        "    for i in range(qr_cells.shape[0]):\n",
        "        for j in range(qr_cells.shape[1]):\n",
        "            cell=qr_cells[i][j]\n",
        "            white_pixel_count = np.sum(cell == 255)\n",
        "            black_pixel_count = np.sum(cell == 0)\n",
        "            if white_pixel_count > black_pixel_count:\n",
        "                for k in range(grid_cell_size):\n",
        "                    for l in range(grid_cell_size):\n",
        "                        qr_cells[i][j][k][l]=255\n",
        "            elif black_pixel_count > white_pixel_count:\n",
        "                for k in range(grid_cell_size):\n",
        "                    for l in range(grid_cell_size):\n",
        "                        qr_cells[i][j][k][l]=0\n",
        "\n",
        "\n",
        "            elif black_pixel_count == white_pixel_count:\n",
        "                for k in range(grid_cell_size):\n",
        "                    for l in range(grid_cell_size):\n",
        "                        qr_cells[i][j][k][l]=0\n",
        "    return img_resized\n",
        "\n",
        "\n",
        "def dalma(image):\n",
        "        image1 = image\n",
        "        thresh,binary_image = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "        image = cv2.inpaint(image1, binary_image, inpaintRadius=3,flags=cv2.INPAINT_TELEA)\n",
        "\n",
        "\n",
        "\n",
        "        mask = cv2.threshold(image, 10, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "        lightened_image = np.where(mask == 255, np.clip(image * 100, 0, 255).astype(np.uint8), image)\n",
        "\n",
        "        _, mask = cv2.threshold(lightened_image, 75, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        mask = cv2.bitwise_not(mask)\n",
        "\n",
        "        _, bimage = cv2.threshold(lightened_image, 0, 255, cv2.THRESH_BINARY)\n",
        "        return bimage\n",
        "\n",
        "def orientSkewness(img):\n",
        "        _, img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
        "        edges = cv2.Canny(img, 100, 200)\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "        qr_code_region = img[y:y + h, x:x + w]\n",
        "        # Apply edge detection\n",
        "        edges = cv2.Canny(qr_code_region, 50, 150, apertureSize=3)\n",
        "        lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)\n",
        "        vertical_angles = []\n",
        "        horizontal_angles = []\n",
        "\n",
        "        for line in lines:\n",
        "            rho, theta = line[0]\n",
        "            if np.pi / 4 < theta < 3 * np.pi / 4:\n",
        "                vertical_angles.append(theta)\n",
        "            else:\n",
        "                horizontal_angles.append(theta)\n",
        "\n",
        "        vertical_skewness = np.mean(vertical_angles) if vertical_angles else 0\n",
        "        horizontal_skewness = np.mean(horizontal_angles) if horizontal_angles else 0\n",
        "\n",
        "        vertical_skewness_deg = np.rad2deg(vertical_skewness)\n",
        "        horizontal_skewness_deg = np.rad2deg(horizontal_skewness)\n",
        "\n",
        "        rotation_angle_deg = 180+horizontal_skewness_deg\n",
        "        rows, cols = img.shape[:2]\n",
        "        rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotation_angle_deg, 1)\n",
        "        img = cv2.warpAffine(img, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR,\n",
        "                                    borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255) )\n",
        "\n",
        "        qr_code_region = cv2.warpAffine(qr_code_region, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR,\n",
        "                            borderMode=cv2.BORDER_CONSTANT)\n",
        "\n",
        "        contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        rect = cv2.minAreaRect(largest_contour)\n",
        "        angle = rect[-1]\n",
        "        if angle < -45:\n",
        "            angle += 90\n",
        "\n",
        "        rows, cols = img.shape[:2]\n",
        "        rotation_matrix = cv2.getRotationMatrix2D(rect[0], angle, 1)\n",
        "        rotated_image = cv2.warpAffine(img, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR,\n",
        "                                    borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "        border_width = 20  # Adjust the border width as needed\n",
        "        border_color = (255, 255, 255)  # White color\n",
        "        img = cv2.copyMakeBorder(img, border_width, border_width, border_width, border_width,\n",
        "                                            cv2.BORDER_CONSTANT, value=border_color)\n",
        "        if(checkrotation(img)):\n",
        "            img=a3dlrotation(img)\n",
        "            return img\n",
        "        else: return img\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def periodicnoiseSolver(img):\n",
        "    fourier_transform = np.fft.fft2(img)\n",
        "    center_shift = np.fft.fftshift(fourier_transform)\n",
        "    epsilon = 1e-10\n",
        "    fourier_noisy = 20 * np.log(np.abs(center_shift)+epsilon)\n",
        "\n",
        "    rows, cols = img.shape\n",
        "    crow, ccol = rows // 2, cols // 2\n",
        "\n",
        "\n",
        "    center_shift[crow :crow + 1, 0:ccol - 10] = 1\n",
        "    center_shift[crow :crow + 1, ccol + 10:] = 1\n",
        "\n",
        "\n",
        "    filtered = center_shift * butterworthLP(80, img.shape, 10)\n",
        "\n",
        "    f_shift = np.fft.ifftshift(center_shift)\n",
        "    denoised_image = np.fft.ifft2(f_shift)\n",
        "    denoised_image = np.real(denoised_image)\n",
        "\n",
        "    f_ishift_blpf = np.fft.ifftshift(filtered)\n",
        "    denoised_image_blpf = np.fft.ifft2(f_ishift_blpf)\n",
        "    denoised_image_blpf = np.real(denoised_image_blpf)\n",
        "\n",
        "    fourier_noisy_noise_removed = 20 * np.log(np.abs(center_shift)+epsilon)\n",
        "    _, denoised_image_blpf_bin = cv2.threshold(denoised_image_blpf, 128, 255, cv2.THRESH_BINARY)\n",
        "    se_rect = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
        "    _, se_binarized = cv2.threshold(se_rect, 128, 1, cv2.THRESH_BINARY)\n",
        "    se_binarized = se_binarized.astype(int)\n",
        "    se_binarized[se_binarized == 0] = -1\n",
        "    imgdilate= cv2.dilate(denoised_image_blpf_bin, se_rect, iterations=2)\n",
        "    denoised_image_blpf_bin=cv2.erode(imgdilate, se_rect, iterations=1)\n",
        "    return denoised_image_blpf_bin\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def denoiseSaltPepper(image):\n",
        "\n",
        "      f_transform = np.fft.fft2(image)\n",
        "      f_transform_shifted = np.fft.fftshift(f_transform)\n",
        "      rect_width = 150\n",
        "      rect_height = 20\n",
        "      rows, cols = image.shape\n",
        "      mask_rect = np.zeros((rows, cols), dtype=np.uint8)\n",
        "      center_row, center_col = rows // 2, cols // 2\n",
        "      start_row = center_row - rect_height // 2\n",
        "      start_col = center_col - rect_width // 2\n",
        "      end_row = start_row + rect_height\n",
        "      end_col = start_col + rect_width\n",
        "      mask_rect[start_row:end_row, start_col:end_col] = 1\n",
        "      rect_width2 = 20\n",
        "      rect_height2 = 150\n",
        "      rows, cols = image.shape\n",
        "      mask_rect2 = np.zeros((rows, cols), dtype=np.uint8)\n",
        "      center_row, center_col = rows // 2, cols // 2\n",
        "      start_row = center_row - rect_height2 // 2\n",
        "      start_col = center_col - rect_width2 // 2\n",
        "      end_row = start_row + rect_height2\n",
        "      end_col = start_col + rect_width2\n",
        "      mask_rect2[start_row:end_row, start_col:end_col] = 1\n",
        "\n",
        "      # circular mask\n",
        "      rows, cols = image.shape\n",
        "      center_row, center_col = rows // 2, cols // 2\n",
        "      radius_inner_circle = 0  # Radius for the central circular region (DC component)\n",
        "      radius_outer_circle = 30  # Radius for the outer annular region (bandpass filter)\n",
        "      mask_circle = np.zeros((rows, cols), dtype=np.uint8)\n",
        "      for i in range(rows):\n",
        "          for j in range(cols):\n",
        "              distance = np.sqrt((i - center_row) ** 2 + (j - center_col) ** 2)\n",
        "              if distance <= radius_outer_circle and distance >= radius_inner_circle:\n",
        "                  mask_circle[i, j] = 1\n",
        "\n",
        "      mask=mask_rect|mask_rect2|mask_circle\n",
        "      mask2=mask_rect|mask_rect2\n",
        "\n",
        "      # Apply the bandpass filter\n",
        "      f_transform_filtered = f_transform_shifted *mask\n",
        "\n",
        "      # f_transform_filtered = f_transform_shifted * mask_circle\n",
        "      filtered_image = np.fft.ifftshift(f_transform_filtered)\n",
        "      filtered_image = np.fft.ifft2(filtered_image)\n",
        "      filtered_image = np.abs(filtered_image)\n",
        "\n",
        "\n",
        "      # Apply inverse Fourier Transform to obtain the filtered image\n",
        "      filtered_image = np.fft.ifftshift(f_transform_filtered)\n",
        "      filtered_image = np.fft.ifft2(filtered_image)\n",
        "      filtered_image = np.abs(filtered_image)\n",
        "      _, filtered_image = cv2.threshold(filtered_image, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "      plt.figure(figsize=(10, 5))\n",
        "      filtered_image = filtered_image.astype(np.uint8)\n",
        "\n",
        "      blur_radius = 3\n",
        "      blurred_img = cv2.GaussianBlur(filtered_image, (blur_radius, blur_radius), 0)\n",
        "      _, binary_image = cv2.threshold(blurred_img, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "      # 1)opening :erosion then dilation\n",
        "      structuring_elementopen = np.ones((9,9))\n",
        "      opened_image = binary_opening( binary_image, structure=structuring_elementopen)\n",
        "      opened_image = np.array(opened_image * 255, dtype=np.uint8)\n",
        "\n",
        "      # 2)Closing to fill gaps  dilates  then erodes\n",
        "      closing_kernel = np.ones((33, 33), np.uint8)\n",
        "      closed_image = cv2.morphologyEx(opened_image, cv2.MORPH_CLOSE, closing_kernel)\n",
        "\n",
        "      # 3)opening :erosion then dilation\n",
        "      structuring_elementopen = np.ones((29,29))\n",
        "      opened_image2 = binary_opening(closed_image, structure=structuring_elementopen)\n",
        "      opened_image2 = np.array(opened_image2 * 255, dtype=np.uint8)\n",
        "      blurred_img2 = cv2.GaussianBlur(opened_image2, (blur_radius, blur_radius), 0)\n",
        "      return blurred_img2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C2-13QUoUTMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "yHlyJo5b_Wo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgafterpreproc=img\n",
        "while(rotationflag or bluredflag or inversionflag or mostlywhiteflag or shiftedrowsflag or mostlyblackflag or skewedflag or unwarpedflag or periodicflag or flipflag or SaltandPepper ):\n",
        "    if(inversionflag == True):\n",
        "        imgafterpreproc=invert_image(imgafterpreproc)\n",
        "\n",
        "    if(rotationflag==True):\n",
        "        imgafterpreproc= a3dlrotation(imgafterpreproc)\n",
        "\n",
        "    if(bluredflag==True):\n",
        "        imgafterpreproc= nadafblured(imgafterpreproc)\n",
        "\n",
        "    if(shiftedrowsflag==True):\n",
        "        imgafterpreproc = solve_shifted_rows(imgafterpreproc)\n",
        "\n",
        "    if(mostlywhiteflag==True):\n",
        "        imgafterpreproc=edit_white_img(imgafterpreproc)\n",
        "\n",
        "    if(periodicflag==True):\n",
        "        imgafterpreproc=periodicnoiseSolver(imgafterpreproc)\n",
        "\n",
        "    if(mostlyblackflag==True):\n",
        "        imgafterpreproc=dalma(imgafterpreproc)\n",
        "\n",
        "    if(skewedflag ==True):\n",
        "        imgafterpreproc=orientSkewness(imgafterpreproc)\n",
        "\n",
        "    if(unwarpedflag ==True):\n",
        "        _,thresh = cv2.threshold(imgafterpreproc, 128, 255, cv2.THRESH_BINARY)\n",
        "        imgafterpreproc=unwarped(imgafterpreproc,thresh)\n",
        "\n",
        "    if(flipflag == True):\n",
        "        imgafterpreproc=flip(imgafterpreproc)\n",
        "\n",
        "    if(SaltandPepper ==True):\n",
        "        imgafterpreproc=denoiseSaltPepper(imgafterpreproc)\n",
        "\n",
        "\n",
        "    rotationflag= checkrotation(imgafterpreproc)\n",
        "\n",
        "    SaltandPepper = detect_patterns_in_roi(imgafterpreproc)\n",
        "\n",
        "    bluredflag = checkblured(imgafterpreproc)\n",
        "\n",
        "    shiftedrowsflag= detect_shift_rows(imgafterpreproc)\n",
        "\n",
        "    mostlywhiteflag= is_mostly_white(imgafterpreproc)\n",
        "\n",
        "    skewedflag,unwarpedflag = checkskew(imgafterpreproc)\n",
        "\n",
        "    periodicflag=detect_periodic_noise(imgafterpreproc)\n",
        "\n",
        "    mostlyblackflag=is_mostly_black(imgafterpreproc)\n",
        "\n",
        "    inversionflag=inversioncheck(imgafterpreproc)\n",
        "\n",
        "    flipflag=checkflip(imgafterpreproc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cv2_imshow(imgafterpreproc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "etR2RDcf9-L4",
        "outputId": "e09a4873-fd11-49e3-979b-f93be0549d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=1012x1012>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reshape** hy5osh 3ala decode"
      ],
      "metadata": {
        "id": "DiJDka4pVBOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, thresh = cv2.threshold(imgafterpreproc, 142, 255, cv2.THRESH_BINARY)\n",
        "imgremove= remove_quietnoise(thresh)\n",
        "plt.imshow(imgremove,cmap='gray')\n",
        "print(\"shape:\",imgremove.shape)\n",
        "if(imgremove.shape[0]<imgremove.shape[1]):\n",
        "    num_rows = abs(imgremove.shape[1] - imgremove.shape[0])\n",
        "    num_cols = imgremove.shape[1]\n",
        "    my_array = np.ones((num_rows, num_cols))\n",
        "    imgremove = np.concatenate((my_array, imgremove))\n",
        "\n",
        "if(imgremove.shape[0]>imgremove.shape[1]):\n",
        "    num_rows =  imgremove.shape[0]\n",
        "    num_cols = abs(imgremove.shape[1] - imgremove.shape[0])\n",
        "    my_array = np.ones((num_rows, num_cols))\n",
        "    print(my_array.shape)\n",
        "    imgremove = np.hstack((my_array, imgremove))\n",
        "plt.imshow(imgremove,cmap='gray')\n",
        "\n",
        "grid_cells_num=21\n",
        "cell_sizex,cell_sizey= [int(x) // grid_cells_num for x in img.shape]\n",
        "if(cell_sizex<cell_sizey):\n",
        "    grid_cell_size=cell_sizey\n",
        "\n",
        "else:\n",
        "    grid_cell_size= cell_sizex\n",
        "\n",
        "print(grid_cell_size)\n",
        "\n",
        "qr_cells= getqrcell(imgremove,grid_cell_size,grid_cells_num)\n",
        "# _, axes = plt.subplots(grid_cells_num, grid_cells_num, figsize=(5, 5))\n",
        "# for i, row in enumerate(axes):\n",
        "#     for j, col in enumerate(row):\n",
        "#         col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
        "#         col.get_xaxis().set_visible(False)\n",
        "#         col.get_yaxis().set_visible(False)\n",
        "#         col.spines[:].set_color('red')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "U6delO1j1067",
        "outputId": "5d7dc976-f8dd-4a32-df14-dd9732779f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (924, 924)\n",
            "48\n",
            "1008\n",
            "Warning: Grid cell size resulted in fraction. Adjusting...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGiCAYAAABd6zmYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAt4klEQVR4nO3de3RUVZ728SeVeyRVETApwh1lBrmMgChEwLbHCCLd3mi66UEHwSUtnSAXR4V5hVYUwmDbjVGE0TUCM4IMzBIvNKDp0I0whkAi0AgIKrYEJImIqSIScqv9/uFLvR1FNJ5jaif5ftY6a0GdXb/6nZ2qenIqVbWjjDFGAABYyBPpBgAA+CaEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFoRC6klS5aoW7duSkhI0ODBg7Vz585ItQIAsFREQuq///u/NXPmTP3mN7/RO++8oyuuuEIjR45UeXl5JNoBAFgqKhJfMDt48GBdddVVeuaZZyRJoVBInTt31tSpUzVr1qymbgcAYKmYpr7BmpoaFRcXa/bs2eHLPB6PMjMzVVBQcN7rVFdXq7q6Ovz/UCikU6dOqV27doqKivrBewYAuMsYo9OnTys9PV0ezze/qNfkIXXy5EnV19crLS2tweVpaWl67733znudnJwcPfroo03RHgCgCZWUlKhTp07fuL/JQ+r7mD17tmbOnBn+fyAQUJcuXSLYEZrSihUrdNttt0W6DdeEQiH9+Mc/1p49exzV6d+/v/70pz9d8LfQ7+LBBx/Uv//7vzuqkZycrMLCQnXs2NFRnfXr1+uuu+5yVAPNS3Jy8gX3N3lItW/fXtHR0SorK2tweVlZmfx+/3mvEx8fr/j4+KZoDxZKSkqS1+uNdBuuCYVCio6OdlwnOjpaXq/XcUjFxcU57iUqKkrJycmOf05JSUmOe0Hz8m1/smnyd/fFxcXpyiuvVH5+fviyUCik/Px8ZWRkNHU7AACLReTlvpkzZ2rChAkaNGiQrr76ai1evFhffPGFJk6cGIl2AACWikhI/eIXv9Cnn36quXPnqrS0VP3799fmzZu/9mYKAEDrFrE3TmRnZys7OztSNw8AaAb47j4AgLUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1msVSHT+Uyy67TMOHD490Gy3WsWPHlJeXF+k2JElnzpzRyy+/rNraWkd1evfurcGDB7vUFX4oN9xwwwXXKIIz27Zt0wcffNAkt9WqQ2r48OF64YUXIt1Gi7V582ZrQurUqVPKzs5WIBBwVGfq1KmEVDMwY8YMjRo1KtJttFiTJk1qspDi5T4AgLUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1CCmgGTPGRLoFSVJUVFSkW0AL1aoXPXTLfffdp71790a6DdfEx8dr5cqV6tChQ6RbwQUcOnRI1113nTweZ79rjh49Wlu3bnVUIyYmRqmpqY5q2ObEiROaMGGCqqurI92Ka6644grl5uZGuo1GIaRcsHv3bm3fvj3SbbgmMTFRVVVVkW4D36KystKV+93PfvYzXXvttS501LJUVVVp+/btLeqxEAqFIt1Co/FyHwDAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqsJ4VWIS4uTr169dLp06cd1fH7/a7006NHD2vWKaqpqdGBAwcc1fB4PLrssssUE8NTCtzFPQqtQmpqqrZt2+a4jtNVcM/VWL16tTVLv//Lv/yL+vfv76iGz+fT3r17lZ6e7k5TwP9DSKHViI2NjXQLYTadcRhjVFtb66hGTU1Ns1z1Ffbjb1IAAGsRUgAAaxFSAABrEVIAAGsRUgAAaxFSAABrEVIAAGsRUgAAaxFSAABrEVIAAGsRUgAAaxFSAABrEVIAAGsRUgAAaxFSAABr2bOoDfADCgaDeuqpp6xZDdcmBQUFkW4B+EaEFFqFYDCoJ598UoFAINKtAGgEXu4DAFiLkAIAWIuQAgBYi5ACAFiLkAIAWKtRIZWTk6OrrrpKycnJSk1N1a233qpDhw41GHP27FllZWWpXbt2atOmjcaMGaOysrIGY44eParRo0crKSlJqampeuCBB1RXV+f8aAAALUqjQmrr1q3KysrSjh07lJeXp9raWo0YMUJffPFFeMyMGTP0+uuva926ddq6das++eQT3X777eH99fX1Gj16tGpqavT2229r5cqVWrFihebOneveUQEAWoRGfU5q8+bNDf6/YsUKpaamqri4WNdee60CgYD+4z/+Q6tXr9Y//uM/SpKWL1+uyy+/XDt27NCQIUP05ptv6sCBA/rjH/+otLQ09e/fX4899pgeeughPfLII4qLi3Pv6AAAzZqjv0md+2Bk27ZtJUnFxcWqra1VZmZmeEyvXr3UpUuX8KfaCwoK1K9fP6WlpYXHjBw5UsFgUPv37z/v7VRXVysYDDbYAAAt3/cOqVAopOnTp2vo0KHq27evJKm0tFRxcXFKSUlpMDYtLU2lpaXhMX8bUOf2n9t3Pjk5OfL5fOGtc+fO37dtAEAz8r1DKisrS++++67WrFnjZj/nNXv2bAUCgfBWUlLyg98mACDyvtd392VnZ2vDhg1666231KlTp/Dlfr9fNTU1qqioaHA2VVZWJr/fHx6zc+fOBvXOvfvv3Jivio+PV3x8/PdpFQDQjDXqTMoYo+zsbK1fv15btmxR9+7dG+y/8sorFRsbq/z8/PBlhw4d0tGjR5WRkSFJysjI0L59+1ReXh4ek5eXJ6/Xq969ezs5FgBAC9OoM6msrCytXr1ar776qpKTk8N/Q/L5fEpMTJTP59Pdd9+tmTNnqm3btvJ6vZo6daoyMjI0ZMgQSdKIESPUu3dv3XnnnVq0aJFKS0v18MMPKysri7MlAEADjQqppUuXSpKuu+66BpcvX75cd911lyTp97//vTwej8aMGaPq6mqNHDlSzz77bHhsdHS0NmzYoClTpigjI0MXXXSRJkyYoHnz5jk7EgBAi9OokDLGfOuYhIQELVmyREuWLPnGMV27dtXGjRsbc9NWS0xMVGJiYqTbcE1SUpI8Hr4xy3ZRUVFKSEiIdBuSvnwMtLT7jMfjUVJSUqTbcFVzfJ5i0UMXrFy5skWt+OrxeBq8IQZ26tOnj9avX29FOHg8nq99tKS569Spk4qKihQKhSLdimsIqVaqQ4cOkW4BrVB8fLx69OhhRUi1RDExMerWrVuk22j1uHcDAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCs1arXkzp27Jg2b94c6TZarKKioki34LquXbvq8ssvd1TDGKOCggIFg0GXunLm4MGD+vjjjx3ViImJ0fDhwxUfH+9SV84UFRUpKioq0m20WMeOHWuy22rVIZWXl6e8vLxIt4Fm5Oabb1Zubq6jGqFQSFdffbWKi4td6sqZpUuX6umnn3ZUw+v1av/+/das6Dx37txItwCX8HIfAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBazXrRwxUrVigpKSnSbeAHlpGREekWXOXxeLRw4UJ9/vnnjupcfPHF8nic/545adIkDR8+3FGN2NhYtWvXznEvGRkZWrt2reM6sN+ZM2d01113feu4KGOM+eHbcVcwGJTP51MgEJDX6410O2gGjh07pr59+yoQCDiqM3XqVMcr8wL47s/jvNwHALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwVrNe9PD48eMKBoORbkOpqamKi4tzVKOurk7l5eUKhUKO6vh8PiUnJzuq4Zbq6mp9+umnkW5DknTy5En5/X61adPGUZ2UlBRX+vn0009VXV3tSi0bREdHKy0tzfEijFVVVfrss89c6soOXq/XlXXvysvLVVNT40JHzrVt27bJFpxt1iE1ZMgQRUVFRboNbdq0yfHqsR9++KGGDRum2tpaR3XmzJmj+++/31ENt2zbtk0/+9nPIt2GJMnv9+uPf/yj4wCPj4933EsoFNLYsWO1Z88ex7VskZycrJ07d6pDhw6O6rzxxhvfabXW5mTmzJmaO3euoxq1tbW6+eab9d5777nUlTPPPPOM7rjjjia5rWYdUjacRUlfngU5VV9fr0Ag4DikbPrtvK6uzvFKuG5p06aNkpOT5fP5It2KJKmystKauXGDMUb19fWO69TW1raoeZGks2fPulLn9OnT1syN0+epxuBvUgAAaxFSAABrEVIAAGsRUgAAaxFSAABrEVIAAGsRUgAAaxFSAABrEVIAAGsRUgAAaxFSAABrEVIAAGsRUgAAaxFSAABrOQqphQsXKioqStOnTw9fdvbsWWVlZaldu3Zq06aNxowZo7KysgbXO3r0qEaPHq2kpCSlpqbqgQcecGW5CwBAyxJljDHf54q7du3Sz3/+c3m9Xv34xz/W4sWLJUlTpkzRH/7wB61YsUI+n0/Z2dnyeDz63//9X0lfrpvUv39/+f1+PfHEEzpx4oT++Z//Wffcc48WLFjwnW47GAzK5/PpV7/6leMVcd3QqVMnJSYmOqpx4sQJLVq0yPGaPD/5yU80YsQIRzViYmI0fvx4x6uJHjx4UEuXLnVUwy0xMTHq2rWr45Vjr7jiCl177bWOahhj9OSTT+ro0aOO6pSXl2vt2rX6ng/hsGuvvVZXXHGFoxoej0ddu3ZVTIyzJeoqKyt14sQJRzUk6bXXXtPHH3/suI4bbrjhBv30pz91VMMYo6NHj1qzMm9qaqrjtdmqqqr00EMPKRAIXPi5xnwPp0+fNj179jR5eXnmRz/6kZk2bZoxxpiKigoTGxtr1q1bFx578OBBI8kUFBQYY4zZuHGj8Xg8prS0NDxm6dKlxuv1murq6u90+4FAwEgygUDg+7TvumHDhhlJLWZLTEw0H374YaSn1VUlJSXG5/M5npupU6dG+lDCioqKjMfjcXxMubm5jnsJBAKmY8eOjnsZO3asCzNjzKhRoyL+OHJzi42NNfv373dlbtwwceJE147t257Hv9evlVlZWRo9erQyMzMbXF5cXKza2toGl/fq1UtdunRRQUGBJKmgoED9+vVTWlpaeMzIkSMVDAa1f//+895edXW1gsFggw0A0PI1+tx8zZo1euedd7Rr166v7SstLVVcXJxSUlIaXJ6WlqbS0tLwmL8NqHP7z+07n5ycHD366KONbRUA0Mw16kyqpKRE06ZN06pVq5SQkPBD9fQ1s2fPViAQCG8lJSVNdtsAgMhpVEgVFxervLxcAwcOVExMjGJiYrR161bl5uYqJiZGaWlpqqmpUUVFRYPrlZWVye/3S5L8fv/X3u137v/nxnxVfHy8vF5vgw0A0PI1KqSuv/567du3T3v27AlvgwYN0vjx48P/jo2NVX5+fvg6hw4d0tGjR5WRkSFJysjI0L59+1ReXh4ek5eXJ6/Xq969e7t0WACAlqBRf5NKTk5W3759G1x20UUXqV27duHL7777bs2cOVNt27aV1+vV1KlTlZGRoSFDhkiSRowYod69e+vOO+/UokWLVFpaqocfflhZWVmKj4936bAAAC2Bsw81nMfvf/97eTwejRkzRtXV1Ro5cqSeffbZ8P7o6Ght2LBBU6ZMUUZGhi666CJNmDBB8+bNc7sVAEAz5zik/vznPzf4f0JCgpYsWaIlS5Z843W6du2qjRs3Or1pAEALx3f3AQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCs5fqHeZsTY4zjBeOcXv9vOV2QT3LnmCQpFAopFAo5rmMLY4w8Ho/jOXbjZ4RvZoxx7X5ny8+qJT4m3Xze+zatOqQ2bNjgyhIghw4dclyjW7dueumllxQbG+uozpIlS7R8+XJHNc6ePavbbrutRX1NVUpKil577TXHKyinpqa61BHOJz8/X1dffbXjOlOnTtVjjz3mQkfOLV++/IJfbvBd1NXV6Re/+IXj+69b/vrXvzbZbbXqkDp58qSKi4sj3YYkKSkpSVdeeaXjkPqmb5JvDGOM3n33Xcd1bNKxY0f169fP8ZLX+GF9/vnnrjwmU1NTdeWVV7rQkXNvvvmm4xrGGB04cMCFbpofO86HAQA4D0IKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYK1WvZ5U+/btrVlzpkOHDtq9e7eio6Md1YmOjrbmmGySmprqeG4lqby8XCUlJY5qREVFqVevXkpKSnJUJykpSQMHDnS8SurZs2cdr+FUVVWlXr16OV7P7PPPP9eRI0cc1ZCk999/3/EClfHx8erTp4+ioqIc1fH7/dY8JisrK11ZpLUpRZmmXAfYJcFgUD6fT4FAQF6v93vXcWtZZzccOHBAV111lWpqahzVeeyxxzRr1iyXumpZ3FhO/JlnntG0adMc1YiOjtaOHTs0cOBAx/24sZz4jBkz9Mwzzziq4fP5tHfvXnXs2NFRnXXr1mncuHGOakhf/iLgNFx69Oihv/zlL45Xw7XpeWbbtm267rrrIt1GA9/2PN6qz6TcuCO7xePxqL6+3pUnHTeejHF+xhhXfkZuPWm58bN245jq6+sVFRXluB+37rtuBIMbP2fJvueZ5qb5dQwAaDUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1mvV6Ug8++KDi4uK+9/WHDBmif/qnf3Lcx1NPPaUPP/zQUY1Tp06pvr7ecS9uqK2tVU5Ojk6ePBnpViRJkyZNUv/+/R3VCAQCWrBggaqqqhzV2bt3r6Pru6mkpERPPvmk43WPLrnkEuXm5jqqERcXp5SUFEc1JGnAgAGOe5GkZcuW6cCBA45qnDx5Uvfff79iYpw9TY4YMUI/+clPHNVwy6WXXurK/K5atUqFhYUudPQdmGYoEAgYSY63iRMnutLPsGHDXOnHjW3+/PmOj+fMmTOmR48eET+Wc9vatWsdH1NJSYnx+XwRPxZJxuPxmKKiIsfHVFRUZDwej+N+cnNzHfdim1GjRkX853xumz17dqSnw3UTJ050bX4CgcAFb4uX+wAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANZq1oseJicnKyoq6ntfPyEhwZU+2rRpI6/X60otp+Lj412pY9MxxcbGRroF11VWVioYDDqu0dLU1dXpzJkzrtRxKioqSsnJyY7ruPU8U1lZ6XiBS7fU1NQ02W0165AqLCx0dCdq06aNK33813/9l86ePetKLad8Pp/jGgkJCXrzzTdVW1vrQkfOtWvXLtItuCoUCmns2LGOVpWWvnyisOVJyy2bN2/Wvffe67iOG6tKd+7cWVu2bHH8i58bv+zV1tbq5ptv1uHDhx3XcsPnn3/eZLfVrEOqY8eOVvy23759+0i34KqoqCilpaVFuo0W7dNPP410C1aqqqrS8ePHI92GJCkmJkbp6elKTEyMdCuSpLKyMmvmpinxNykAgLUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1Gh1Sx48f1x133KF27dopMTFR/fr1U1FRUXi/MUZz585Vhw4dlJiYqMzMTL3//vsNapw6dUrjx4+X1+tVSkqK7r777hb5wUQAgDONCqnPP/9cQ4cOVWxsrDZt2qQDBw7oySef1MUXXxwes2jRIuXm5mrZsmUqLCzURRddpJEjRzb4sOv48eO1f/9+5eXlacOGDXrrrbc0efJk944KANAymEZ46KGHzLBhw75xfygUMn6/3zzxxBPhyyoqKkx8fLx56aWXjDHGHDhwwEgyu3btCo/ZtGmTiYqKMsePH/9OfQQCASPJBAKBxrSPVqykpMT4fD4jie0rW25ubqR/PGFr166N+Hyc23r06GHOnDkT6SkxxhhTU1NjevfuHfE5+SG2b3seb9SZ1GuvvaZBgwZp7NixSk1N1YABA/T888+H93/00UcqLS1VZmZm+DKfz6fBgweroKBAklRQUKCUlBQNGjQoPCYzM1Mej0eFhYXnvd3q6moFg8EGGwCg5WtUSB05ckRLly5Vz5499cYbb2jKlCm67777tHLlSklSaWmpJH3tK3XS0tLC+0pLS5Wamtpgf0xMjNq2bRse81U5OTny+XzhrXPnzo1pGwDQTDUqpEKhkAYOHKgFCxZowIABmjx5su655x4tW7bsh+pPkjR79mwFAoHwVlJS8oPeHgDADo0KqQ4dOqh3794NLrv88st19OhRSZLf75f05Rch/q2ysrLwPr/fr/Ly8gb76+rqdOrUqfCYr4qPj5fX622wAQBavkaF1NChQ3Xo0KEGlx0+fFhdu3aVJHXv3l1+v1/5+fnh/cFgUIWFhcrIyJAkZWRkqKKiQsXFxeExW7ZsUSgU0uDBg7/3gQAAWp5GLdUxY8YMXXPNNVqwYIF+/vOfa+fOnXruuef03HPPSfpyiYfp06fr8ccfV8+ePdW9e3fNmTNH6enpuvXWWyV9eeZ14403hl8mrK2tVXZ2tsaNG6f09HTXDxAA0Hw1KqSuuuoqrV+/XrNnz9a8efPUvXt3LV68WOPHjw+PefDBB/XFF19o8uTJqqio0LBhw7R58+YGq1OuWrVK2dnZuv766+XxeDRmzBjl5uY2uvlXXnlFSUlJjb4empchQ4aoU6dOkW5DknTZZZepf//+kW5D0pefW/zbVy2+r927d+t//ud/HNWIjY3VyJEjXVuF1gaVlZVav36948Upe/Xqpb59+7rUlTPt27fXddddF+k2JH25kOOrr7767QOb6G3+rjr3OSm21rGtXbvW8X3Grc9JTZ061YV7sDuKioqMx+OJ+M9HkvF6vaakpMTxMdn0OSm3ttmzZzueF7c+J3Whz7k2te/6eVe+uw8AYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYC1CCgBgLUIKAGAtQgoAYK1Grczb0txwww2aMWNGpNtosYqKijR37txItyFJuuSSS7Ru3TrV1dU5qtO1a1eXOnKuZ8+e+sMf/iBjTKRbUUxMjC655BLHdYYPH66NGze60JFzpaWluvfee1VTUxPpVhQTE6Nly5apsrLSUZ1PPvlEN910k+N+ZsyYoRtuuMFxne+iVYdUp06dNGrUqEi30WJFRUVFuoWw+Pj4JntQNRWv16sbb7wx0m24yu/3W/OYPHLkiKKjoyPdhqQvH0vDhw93XGfbtm3atGmT4zpjx451XOO74uU+AIC1CCkAgLUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1CCkAgLUIKQCAtQgpAIC1CCkAgLUIKQCAtVr1elJuOXHihKqqqiLdhms8Ho86deqkmBjuHl8VDAZ18uTJSLchSYqLi1OnTp0c1/nss88UCARc6Mi5Nm3aKDU11XGd0tJSnTlzxlGNkpISKxaUPOfYsWOOF2A8deqUevTo4biX5ORkxzW+K56FXDBhwgRt37490m24JikpSUVFRerWrVukW7HOqlWrdP/990e6DUnSwIED9dZbb8njcfaCSE5Ojp599lmXunLm9ttv14svvui4zpQpU/TGG284qmGM0dmzZx334oba2lrdcsstOnjwoKM6Q4YM0b59+xwvSBoXF+fo+o1BSLmgqqqqRZ1JSVIoFIp0C1aqq6uz5mft1hNoTU2NNcfk1lLt1dXV1hyTW86ePev4mGpra5WUlORSR02Dv0kBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCsxXpSaBUqKyv13HPPqbq62lGdmpoazZ4926WunElPT3e8eJ1b4uLiNHnyZMcrtvbr18+ljuzx9ttvKycnx3Gd2267TbfccoujGtHR0a704obvuh4aIYVWoaKiQvPmzXO8TPrUqVOVm5vrUlctR0JCgh566CFXlrNvabZu3aqtW7c6qhEbG6s9e/aod+/ejups27ZN1157raMaTY2X+wAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANYipAAA1iKkAADWIqQAANZiPSm0Ch6PR7GxsYqNjXVUJyoqSrW1tS515UxUVJRiYux5CNfV1TmeG4/Ho+joaJc6wldFRUUpLi5OxhhHderr6xUKhVzq6sIadQ+vr6/XI488ohdffFGlpaVKT0/XXXfdpYcffji8QqgxRr/5zW/0/PPPq6KiQkOHDtXSpUvVs2fPcJ1Tp05p6tSpev311+XxeDRmzBg99dRTatOmjbtHB/w/qamp2r59u+rr6x3V2bRpk/r37+9OUw716dNHa9askccT+RdEKisrdcMNNyguLs5RnZEjR+p3v/udS13hqwYOHKjdu3c7rvPwww9r/fr1LnT07RoVUv/2b/+mpUuXauXKlerTp4+Kioo0ceJE+Xw+3XfffZKkRYsWKTc3VytXrlT37t01Z84cjRw5UgcOHFBCQoIkafz48Tpx4oTy8vJUW1uriRMnavLkyVq9erX7RwhIiomJ0d///d87rpOfn68DBw640JFziYmJkW4hLBQK6YMPPnBcp0+fPi50g2+SlJTkeHVfSUpJSXHezHfUqJB6++23dcstt2j06NGSpG7duumll17Szp07JX15FrV48WI9/PDDuuWWWyRJ//mf/6m0tDS98sorGjdunA4ePKjNmzdr165dGjRokCTp6aef1k033aTf/va3Sk9Pd/P4AADNWKNeJ7jmmmuUn5+vw4cPS5L27t2r7du3a9SoUZKkjz76SKWlpcrMzAxfx+fzafDgwSooKJAkFRQUKCUlJRxQkpSZmSmPx6PCwsLz3m51dbWCwWCDDQDQ8jXqTGrWrFkKBoPq1auXoqOjVV9fr/nz52v8+PGSpNLSUklSWlpag+ulpaWF95WWlio1NbVhEzExatu2bXjMV+Xk5OjRRx9tTKsAgBagUWdSa9eu1apVq7R69Wq98847WrlypX77299q5cqVP1R/kqTZs2crEAiEt5KSkh/09gAAdmjUmdQDDzygWbNmady4cZKkfv366eOPP1ZOTo4mTJggv98vSSorK1OHDh3C1ysrKwu/I8rv96u8vLxB3bq6Op06dSp8/a+Kj49XfHx8Y1oFALQAjTqTOnPmzNfe7hodHR1+v3z37t3l9/uVn58f3h8MBlVYWKiMjAxJUkZGhioqKlRcXBwes2XLFoVCIQ0ePPh7HwgAoOVp1JnUT3/6U82fP19dunRRnz59tHv3bv3ud7/TpEmTJH35QbHp06fr8ccfV8+ePcNvQU9PT9ett94qSbr88st144036p577tGyZctUW1ur7OxsjRs3jnf2AQAaaFRIPf3005ozZ45+/etfq7y8XOnp6frVr36luXPnhsc8+OCD+uKLLzR58mRVVFRo2LBh2rx5c/gzUpK0atUqZWdn6/rrrw9/mDc3N9e9owIAtAiNCqnk5GQtXrxYixcv/sYxUVFRmjdvnubNm/eNY9q2bcsHdwEA3yry36cCAMA3IKQAANYipAAA1iKkAADWIqQAANYipAAA1rJnWc9mzJZF8NySmJho1VpFbqipqVFxcbHq6uoc1amqqtKwYcNc6sqZTp06adu2bY4XPfzkk09c6sgeffv21enTpyPdhmtiY2OVlJQU6TbC/u7v/s7x46Curk47duz41nGElAuefvrpSLeAb1FeXq5Ro0YpEAg4qjN16lRt27bNpa6cKS4u1uDBgx2vNtwSLVq0KNIttGizZs3SrFmzHNUIBoPy+XzfOo6X+4BmzBgT6RaAHxQhBQCwFiEFALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwFiEFALAWIQUAsBYhBQCwFiEFALAWIQUAsFarXvRw27ZtmjRpUqTbaLGOHTsW6RZcl5eX5/g+4/F4NGfOHHXt2tWlriIvMTFRjz/+uC6++GJHdU6ePGnNY/KSSy7RY489pri4OEd1NmzYoJdfftlRjZiYGD3yyCNKT093VOfw4cNauHChoxqSNGnSpKZbodo0Q4FAwEhiayXb2rVrHd9nSkpKjM/ni/ixSDIej8cUFRU5PqaioiLj8XgifjySjNfrNSUlJY6Pae3atRE/lnNbjx49zJkzZxwf04IFCxz3Ehsba/bv3++4l7feesuVuXnhhRcc93LueTwQCFxwHC/3AQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArEVIAQCsRUgBAKxFSAEArNUsFz00xkS6BTShM2fOKBgMOqpx+vRpa+43xhhVVlY6PqbKykqrjun06dOOj+nMmTMudeRcKBRSMBhUbW2tozpnz5513Itb95kvvvjCcS+SVFVV5biXc9f/tvtwlLHlXt4IR44c0aWXXhrpNgAADpWUlKhTp07fuL9Znkm1bdtWknT06FH5fL4Id9P8BINBde7cWSUlJfJ6vZFup9lh/pxh/pxpKfN37uw7PT39guOaZUh5PF/+Kc3n8zXrH1Kkeb1e5s8B5s8Z5s+ZljB/3+UkgzdOAACsRUgBAKzVLEMqPj5ev/nNbxQfHx/pVpol5s8Z5s8Z5s+Z1jZ/zfLdfQCA1qFZnkkBAFoHQgoAYC1CCgBgLUIKAGAtQgoAYK1mGVJLlixRt27dlJCQoMGDB2vnzp2RbinicnJydNVVVyk5OVmpqam69dZbdejQoQZjzp49q6ysLLVr105t2rTRmDFjVFZW1mDM0aNHNXr0aCUlJSk1NVUPPPCA6urqmvJQrLBw4UJFRUVp+vTp4cuYvws7fvy47rjjDrVr106JiYnq16+fioqKwvuNMZo7d646dOigxMREZWZm6v33329Q49SpUxo/fry8Xq9SUlJ09913q7KysqkPpcnV19drzpw56t69uxITE3XppZfqsccea/Dlq612/kwzs2bNGhMXF2deeOEFs3//fnPPPfeYlJQUU1ZWFunWImrkyJFm+fLl5t133zV79uwxN910k+nSpYuprKwMj7n33ntN586dTX5+vikqKjJDhgwx11xzTXh/XV2d6du3r8nMzDS7d+82GzduNO3btzezZ8+OxCFFzM6dO023bt3MP/zDP5hp06aFL2f+vtmpU6dM165dzV133WUKCwvNkSNHzBtvvGE++OCD8JiFCxcan89nXnnlFbN3715z8803m+7du5uqqqrwmBtvvNFcccUVZseOHWbbtm3msssuM7/85S8jcUhNav78+aZdu3Zmw4YN5qOPPjLr1q0zbdq0MU899VR4TGudv2YXUldffbXJysoK/7++vt6kp6ebnJycCHZln/LyciPJbN261RhjTEVFhYmNjTXr1q0Ljzl48KCRZAoKCowxxmzcuNF4PB5TWloaHrN06VLj9XpNdXV10x5AhJw+fdr07NnT5OXlmR/96EfhkGL+Luyhhx4yw4YN+8b9oVDI+P1+88QTT4Qvq6ioMPHx8eall14yxhhz4MABI8ns2rUrPGbTpk0mKirKHD9+/Idr3gKjR482kyZNanDZ7bffbsaPH2+Mad3z16xe7qupqVFxcbEyMzPDl3k8HmVmZqqgoCCCndknEAhI+v/fGF9cXKza2toGc9erVy916dIlPHcFBQXq16+f0tLSwmNGjhypYDCo/fv3N2H3kZOVlaXRo0c3mCeJ+fs2r732mgYNGqSxY8cqNTVVAwYM0PPPPx/e/9FHH6m0tLTB/Pl8Pg0ePLjB/KWkpGjQoEHhMZmZmfJ4PCosLGy6g4mAa665Rvn5+Tp8+LAkae/evdq+fbtGjRolqXXPX7P6FvSTJ0+qvr6+wZOAJKWlpem9996LUFf2CYVCmj59uoYOHaq+fftKkkpLSxUXF6eUlJQGY9PS0lRaWhoec765PbevpVuzZo3eeecd7dq162v7mL8LO3LkiJYuXaqZM2fqX//1X7Vr1y7dd999iouL04QJE8LHf775+dv5S01NbbA/JiZGbdu2bfHzN2vWLAWDQfXq1UvR0dGqr6/X/PnzNX78eElq1fPXrEIK301WVpbeffddbd++PdKtNBslJSWaNm2a8vLylJCQEOl2mp1QKKRBgwZpwYIFkqQBAwbo3Xff1bJlyzRhwoQId2e/tWvXatWqVVq9erX69OmjPXv2aPr06UpPT2/189esXu5r3769oqOjv/aOqrKyMvn9/gh1ZZfs7Gxt2LBBf/rTnxqsdun3+1VTU6OKiooG4/927vx+/3nn9ty+lqy4uFjl5eUaOHCgYmJiFBMTo61btyo3N1cxMTFKS0tj/i6gQ4cO6t27d4PLLr/8ch09elTS/z/+Cz12/X6/ysvLG+yvq6vTqVOnWvz8PfDAA5o1a5bGjRunfv366c4779SMGTOUk5MjqXXPX7MKqbi4OF155ZXKz88PXxYKhZSfn6+MjIwIdhZ5xhhlZ2dr/fr12rJli7p3795g/5VXXqnY2NgGc3fo0CEdPXo0PHcZGRnat29fgzt6Xl6evF7v156AWprrr79e+/bt0549e8LboEGDNH78+PC/mb9vNnTo0K995OHw4cPq2rWrJKl79+7y+/0N5i8YDKqwsLDB/FVUVKi4uDg8ZsuWLQqFQho8eHATHEXknDlzJryY6znR0dEKhUKSWvn8RfqdG421Zs0aEx8fb1asWGEOHDhgJk+ebFJSUhq8o6o1mjJlivH5fObPf/6zOXHiRHg7c+ZMeMy9995runTpYrZs2WKKiopMRkaGycjICO8/9xbqESNGmD179pjNmzebSy65pFW8hfp8/vbdfcYwfxeyc+dOExMTY+bPn2/ef/99s2rVKpOUlGRefPHF8JiFCxealJQU8+qrr5q//OUv5pZbbjnvW6gHDBhgCgsLzfbt203Pnj2b/Vuov4sJEyaYjh07ht+C/vLLL5v27dubBx98MDymtc5fswspY4x5+umnTZcuXUxcXJy5+uqrzY4dOyLdUsRJOu+2fPny8Jiqqirz61//2lx88cUmKSnJ3HbbbebEiRMN6vz1r381o0aNMomJiaZ9+/bm/vvvN7W1tU18NHb4akgxfxf2+uuvm759+5r4+HjTq1cv89xzzzXYHwqFzJw5c0xaWpqJj483119/vTl06FCDMZ999pn55S9/adq0aWO8Xq+ZOHGiOX36dFMeRkQEg0Ezbdo006VLF5OQkGB69Ohh/s//+T8NPrrQWueP9aQAANZqVn+TAgC0LoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBahBQAwFqEFADAWoQUAMBa/xfsXEzKEHMwzQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decode"
      ],
      "metadata": {
        "id": "lAK7kIcDSHTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def change_binary(qr_cell,grid_cell_num):\n",
        "    qr_cells_numeric = np.ndarray((grid_cells_num, grid_cells_num), dtype=np.uint8)\n",
        "    for i, row in enumerate(qr_cells):\n",
        "        for j, cell in enumerate(row):\n",
        "            qr_cells_numeric[i, j] = (np.median(cell) // 255)\n",
        "    return qr_cells_numeric"
      ],
      "metadata": {
        "id": "ORTXvspcSGnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qr_cells_numeric=change_binary(qr_cells,grid_cells_num)\n",
        "\n",
        "\n",
        "MASKS = {\n",
        "    \"000\": lambda i, j: (i * j) % 2 + (i * j) % 3 == 0,\n",
        "    \"001\": lambda i, j: (i / 2 + j / 3) % 2 == 0,\n",
        "    \"010\": lambda i, j: ((i * j) % 3 + i + j) % 2 == 0,\n",
        "    \"011\": lambda i, j: ((i * j) % 3 + i * j) % 2 == 0,\n",
        "    \"100\": lambda i, j: i % 2 == 0,\n",
        "    \"101\": lambda i, j: (i + j) % 2 == 0,\n",
        "    \"110\": lambda i, j: (i + j) % 3 == 0,\n",
        "    \"111\": lambda i, j: j % 3 == 0,\n",
        "}\n",
        "\n",
        "\n",
        "def getecldown(qr_cells_numeric):\n",
        "    qr_cells_numeric[-1][8]\n",
        "\n",
        "    ecl = [int(not(c)) for c in qr_cells_numeric[-1:-3:-1, 8]]\n",
        "    # Why \"not\"? Because the standard uses '1's for black and '0's for white\n",
        "    #\n",
        "    # \"A dark module is a binary one and a light module is a binary zero.\"\n",
        "    #  - ISO/IEC 18004:2000(E)\n",
        "    #\n",
        "    # In image processing, we use them the other way.. Hence the inversion\n",
        "    return ecl\n",
        "\n",
        "def get_maskdown(qr_cells_numeric):\n",
        "    # Dictionary of all masks and their equivalent formulae\n",
        "    # Same row as above, the three cells after the ecl cells (converted to a string)\n",
        "    mask = [int(not(c)) for c in qr_cells_numeric[-3:-6:-1,8]]\n",
        "    mask_str = ''.join([str(c) for c in mask])\n",
        "    return mask,mask_str\n",
        "\n",
        "def get_fecdown(qr_cells_numeric):\n",
        "    fec = []\n",
        "    fec.extend(qr_cells_numeric[-6:-8:-1, 8])\n",
        "    # fec.append(qr_cells_numeric[8, 8])\n",
        "    fec.extend(qr_cells_numeric[0:6, 8])\n",
        "    fec.extend(qr_cells_numeric[7:9, 8])\n",
        "    fec = [int(not(c)) for c in fec]\n",
        "    return fec\n",
        "\n",
        "print(getecldown(qr_cells_numeric))\n",
        "print(get_maskdown(qr_cells_numeric))\n",
        "print(get_fecdown(qr_cells_numeric))\n",
        "def showneededpixel(qr_cells_numeric):\n",
        "   _, axes = plt.subplots(grid_cells_num, grid_cells_num, figsize=(5, 5))\n",
        "   for i, row in enumerate(axes):\n",
        "       for j, col in enumerate(row):\n",
        "\n",
        "            col.get_xaxis().set_visible(False)\n",
        "            col.get_yaxis().set_visible(False)\n",
        "            if (i == 8 and j <= 8) or (i <= 8 and j == 8):\n",
        "                if (i != 6) and (j != 6):\n",
        "                    col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
        "                    col.spines[:].set_color('red')\n",
        "                    continue\n",
        "            col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=-1275, vmax=510)"
      ],
      "metadata": {
        "id": "lOGyoteyR6RD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66196c6b-b3a6-4fd2-b250-5c5f399a75e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1]\n",
            "([0, 1, 0], '010')\n",
            "[0, 1, 0, 1, 1, 0, 1, 1, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def makeinfo(ecl,mask,fec):\n",
        "    ecl[0] ^= 1\n",
        "    mask[0] ^= 1\n",
        "    mask[2] ^= 1\n",
        "    fec[5] ^= 1\n",
        "    fec[8] ^= 1\n",
        "mask,mask_str=get_maskdown(qr_cells_numeric)\n",
        "ecl=getecldown(qr_cells_numeric)\n",
        "fec=get_fecdown(qr_cells_numeric)\n",
        "makeinfo(ecl,mask,fec)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4YhDqtyjUpOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lw bayz"
      ],
      "metadata": {
        "id": "J-4w_BwesDIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (is_mostly_black(img)):\n",
        "  qr_cells_numeric = cv2.resize(imgremove, (21, 21), interpolation=cv2.INTER_AREA) // 255\n",
        "print(is_mostly_black(img))\n",
        "qr_cells_numeric_inv = 1 - qr_cells_numeric\n",
        "UP8, UP4, DOWN8, DOWN4, CW8, CCW8 = range(6)\n",
        "print(qr_cells_numeric.shape)"
      ],
      "metadata": {
        "id": "OllZ81rHsRp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f895d5c4-3581-4521-d0e5-9b5e77b17d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "(21, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_mask_general(data_start_i, data_start_j, data, mask, direction):\n",
        "    result = []\n",
        "    row_offsets = []\n",
        "    col_offsets = []\n",
        "    mask_str = ''.join([str(c) for c in mask])\n",
        "    if (direction in [UP8, UP4]):\n",
        "        row_offsets = [0,  0, -1, -1, -2, -2, -3, -3]\n",
        "        col_offsets = [0, -1,  0, -1,  0, -1,  0, -1]\n",
        "    if (direction in [DOWN8, DOWN4]):\n",
        "        row_offsets = [0,  0,  1,  1,  2,  2,  3,  3]\n",
        "        col_offsets = [0, -1,  0, -1,  0, -1,  0, -1]\n",
        "    if (direction == CW8):\n",
        "        row_offsets = [0,  0,  1,  1,  1,  1,  0,  0]\n",
        "        col_offsets = [0, -1,  0, -1, -2, -3, -2, -3]\n",
        "    if (direction == CCW8):\n",
        "        row_offsets = [0,  0, -1, -1, -1, -1,  0,  0]\n",
        "        col_offsets = [0, -1,  0, -1, -2, -3, -2, -3]\n",
        "    for i, j in zip(row_offsets, col_offsets):\n",
        "        cell_bit = bool(data[data_start_i+i, data_start_j+j])\n",
        "        mask_bit = MASKS[mask_str](data_start_i+i, data_start_j+j)\n",
        "        # Modules corresponding to the dark areas of the mask are inverted.\n",
        "        result.append(int(not cell_bit if mask_bit else cell_bit))\n",
        "    return result[:4] if direction in [UP4, DOWN4] else result"
      ],
      "metadata": {
        "id": "usqYaKXLswv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ecl = qr_cells_numeric_inv[-1:-3:-1, 8]\n",
        "mask = qr_cells_numeric_inv[-3:-6:-1,8]\n",
        "print(\"ecl: \",ecl)\n",
        "print(\"mask: \",mask)\n",
        "len_bits = apply_mask_general(21-3, 21-1, qr_cells_numeric_inv, mask, UP8)\n",
        "len_int = int(''.join([str(bit) for bit in len_bits]), 2)\n",
        "print(f'{len_bits} = {len_int} data symbols, each consisting of 8 bits')\n",
        "block_starting_indices = [\n",
        "    [21-7,  21-1,  UP8],\n",
        "    [21-11, 21-1,  CCW8],\n",
        "    [21-10, 21-3,  DOWN8],\n",
        "    [21-6,  21-3,  DOWN8],\n",
        "    [21-2,  21-3,  CW8],\n",
        "    [21-3,  21-5,  UP8],\n",
        "    [21-7,  21-5,  UP8],\n",
        "    [21-11, 21-5,  CCW8],\n",
        "    [21-10, 21-7,  DOWN8],\n",
        "    [21-6,  21-7,  DOWN8],\n",
        "    [21-2,  21-7,  CW8],\n",
        "    [21-3,  21-9,  UP8],\n",
        "    [21-7,  21-9,  UP8],\n",
        "    [21-11, 21-9,  UP8],\n",
        "    [21-16, 21-9,  UP8],\n",
        "    [21-20, 21-9,  CCW8],\n",
        "    [21-19, 21-11, DOWN8],\n",
        "    [21-14, 21-11, DOWN4],  # Special 4-byte block, reserved for END (if exists!)\n",
        "    [21-12, 21-11, DOWN8],\n",
        "    [21-8,  21-11, DOWN8],\n",
        "    [21-4,  21-11, DOWN8],\n",
        "    [21-9,  21-13, UP8],\n",
        "    [21-12, 21-16, DOWN8],\n",
        "    [21-9,  21-18, UP8],\n",
        "    [21-12, 21-20, DOWN8],\n",
        "]\n",
        "\n",
        "enc_bits = apply_mask_general(21-1, 21-1, qr_cells_numeric_inv, mask, UP4)\n",
        "print(\"encc\",enc_bits)\n",
        "message_bits = []\n",
        "message_bits.extend(enc_bits)\n",
        "message_bits.extend(len_bits)\n",
        "if enc_bits==[0, 1, 0, 0]:\n",
        "  # 0100\tByte encoding (8 bits per character)\n",
        "  print(f'{enc_bits} = Byte encoding (8 bits per character)')\n",
        "  # First, let's read the data bytes, starting from the very first byte after enc and len\n",
        "  byte_index = 0\n",
        "  for _ in range(len_int):\n",
        "      start_i, start_j, dir = block_starting_indices[byte_index]\n",
        "      bits = apply_mask_general(start_i, start_j, qr_cells_numeric_inv, mask, dir)\n",
        "      message_bits.extend(bits)\n",
        "      bit_string = ''.join([str(bit) for bit in bits])\n",
        "      alpha_char = chr(int(bit_string, 2))\n",
        "      print(f'{bit_string} (={int(bit_string, 2):03d}) = {alpha_char}')\n",
        "      byte_index += 1\n",
        "  # After finishing all the characters, the next 4 bits are expected to be '0000'\n",
        "  start_i, start_j, dir = block_starting_indices[byte_index]\n",
        "  bits = apply_mask_general(start_i, start_j, qr_cells_numeric_inv, mask, dir)\n",
        "  message_bits.extend(bits)\n",
        "  bit_string = ''.join([str(bit) for bit in bits])\n",
        "  print(f'{bit_string} (=END) -- the NULL TERMINATOR, followed by padding and/or ECC')\n",
        "  byte_index += 1\n",
        "  # Let's see what the bytes that follow look like\n",
        "  # There supposedly remain 25-len-1 bytes to be read\n",
        "  for _ in range(25 - len_int - 1):\n",
        "      start_i, start_j, dir = block_starting_indices[byte_index]\n",
        "      bits = apply_mask_general(start_i, start_j, qr_cells_numeric_inv, mask, dir)\n",
        "      message_bits.extend(bits)\n",
        "      bit_string = ''.join([str(bit) for bit in bits])\n",
        "      alpha_char = chr(int(bit_string, 2))\n",
        "      print(f'{bit_string} (={int(bit_string, 2):03d}) = {alpha_char}')\n",
        "      byte_index += 1\n",
        "\n",
        "elif enc_bits==[0, 0, 1, 0]:\n",
        "\n",
        "  alpha_eleven=[]\n",
        "  # 0010\tAlphanumeric encoding (11 bits per 2 characters)\n",
        "  print(f'{enc_bits} = Alphanumeric encoding (11 bits per 2 characters)')\n",
        "  byte_index = 0\n",
        "  for _ in range(len_int):\n",
        "      start_i, start_j, dir = block_starting_indices[byte_index]\n",
        "      bits = apply_mask_general(start_i, start_j, qr_cells_numeric_inv, mask, dir)\n",
        "      message_bits.extend(bits)\n",
        "\n",
        "  for i in range(12, len(message_bits), 11):\n",
        "      # Take 11 elements starting from the current index\n",
        "      alpha_two_char = message_bits[i:i+11]\n",
        "      # Append the chunk to the list of chunks\n",
        "      alpha_eleven.append(alpha_two_char)\n",
        "  print(alpha_eleven)\n",
        "  print(len(alpha_eleven))\n",
        "  print('message_bits:',message_bits)\n",
        "  print('message_bits:',len(message_bits))\n",
        "  alphanumeric_table = {\n",
        "    0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9',\n",
        "    10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J',\n",
        "    20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T',\n",
        "    30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z', 36: ' ', 37: '$', 38: '%', 39: '*',\n",
        "    40: '+', 41: '-', 42: '.', 43: '/', 44: ':'\n",
        "    }\n",
        "  alpha_list=[]\n",
        "  for sublist in alpha_eleven:\n",
        "    binary_string = ''.join([str(bit) for bit in sublist])\n",
        "    # print (binary_string)\n",
        "    decimal_value = int(binary_string, 2)\n",
        "    # print(decimal_value)\n",
        "    # Get the first alphanumeric character\n",
        "    first_char_value = decimal_value // 45\n",
        "    first_char = alphanumeric_table[first_char_value]\n",
        "\n",
        "    # Get the second alphanumeric character\n",
        "    second_char_value = decimal_value % 45\n",
        "    second_char = alphanumeric_table[second_char_value]\n",
        "\n",
        "    # Concatenate the characters to form the alphanumeric string\n",
        "    alphanumeric_string = first_char + second_char\n",
        "    alpha_list.append(alphanumeric_string)\n",
        "\n",
        "    print(f\"Binary: {binary_string}\")\n",
        "    print(f\"Decimal Value: {decimal_value}\")\n",
        "    print(f\"Alphanumeric String: {alphanumeric_string}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2hbnrGusx7N",
        "outputId": "550deb0e-f354-407c-c640-64e88b11bda5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ecl:  [1 1]\n",
            "mask:  [0 1 0]\n",
            "[0, 0, 0, 0, 1, 1, 0, 0] = 12 data symbols, each consisting of 8 bits\n",
            "encc [0, 1, 0, 0]\n",
            "[0, 1, 0, 0] = Byte encoding (8 bits per character)\n",
            "00110000 (=048) = 0\n",
            "00110001 (=049) = 1\n",
            "00101101 (=045) = -\n",
            "01000111 (=071) = G\n",
            "01101111 (=111) = o\n",
            "01101111 (=111) = o\n",
            "01100100 (=100) = d\n",
            "00100000 (=032) =  \n",
            "01101010 (=106) = j\n",
            "01101111 (=111) = o\n",
            "01100010 (=098) = b\n",
            "00100001 (=033) = !\n",
            "00001110 (=END) -- the NULL TERMINATOR, followed by padding and/or ECC\n",
            "11000001 (=193) = Á\n",
            "00011110 (=030) = \u001e\n",
            "11000001 (=193) = Á\n",
            "00011110 (=030) = \u001e\n",
            "1100 (=012) = \f\n",
            "01000011 (=067) = C\n",
            "00100111 (=039) = '\n",
            "01011111 (=095) = _\n",
            "00111011 (=059) = ;\n",
            "11110011 (=243) = ó\n",
            "10010001 (=145) = \n",
            "10011000 (=152) = \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For every 8 bits in the extracted message, convert to a byte\n",
        "message_bytes = [int(\"\".join(map(str, message_bits[i:i+8])), 2) for i in range(0, len(message_bits), 8)]\n",
        "\n",
        "# Create the Reed-Solomon Codec for 7 ECC symbols (again, this is L)\n",
        "rsc = rs.RSCodec(nsym=7)\n",
        "\n",
        "# Decode the bytes with the 7-ECC RS Codec\n",
        "message_decoded = rsc.decode(message_bytes)\n",
        "rsc.maxerrata(verbose=True)\n",
        "\n",
        "# In order to extract the actual data, need to convert back to bits\n",
        "# Then take as many bytes as indicated by the message length indicator\n",
        "# That is AFTER removing the first 12 bytes (of enc and len)\n",
        "data_bits = bin(int.from_bytes(message_decoded[0], byteorder='big'))[13:13+len_int*8]\n",
        "\n",
        "# Now convert back to bytes and print it lol\n",
        "data_bytes = int(data_bits, 2).to_bytes((len(data_bits)+7)//8, 'big')\n",
        "print(f'Data in message = \"{data_bytes.decode(encoding=\"iso-8859-1\")}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEhoxpXFtPiE",
        "outputId": "d9016251-8b22-46d9-ec4a-53e5816af1ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This codec can correct up to 3 errors and 7 erasures independently\n",
            "Data in message = \"01-Good job!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7agat 3maltelha comment\n"
      ],
      "metadata": {
        "id": "vvu_ikY4SFz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_mask(qr_cells_numeric):\n",
        "#     # Dictionary of all masks and their equivalent formulae\n",
        "#     # Same row as above, the three cells after the ecl cells (converted to a string)\n",
        "#     mask = [int(not(c)) for c in qr_cells_numeric[8, 2:5]]\n",
        "#     mask_str = ''.join([str(c) for c in mask])\n",
        "#     print(mask)\n",
        "#     return mask,mask_str\n",
        "\n",
        "# def get_fec(qr_cells_numeric):\n",
        "#     fec = []\n",
        "#     fec.append(qr_cells_numeric[8, 5])\n",
        "#     fec.append(qr_cells_numeric[8, 7])\n",
        "#     fec.extend(qr_cells_numeric[0:6, 8])\n",
        "#     fec.extend(qr_cells_numeric[7:9, 8])\n",
        "#     fec = [int(not(c)) for c in fec]\n",
        "#     return fec\n",
        "# def apply_mask(data_start_i, data_start_j, direction):\n",
        "#     '''\n",
        "#     data_start_i/j represent the first cell's coords in its respective direction\n",
        "#     direction is the masking direction, up(-enc)/down/clockwise/anti-clockwise\n",
        "#     '''\n",
        "#     result = []\n",
        "#     row_offsets = []\n",
        "#     col_offsets = []\n",
        "#     if (direction in [UP, UP_ENC]):\n",
        "#         row_offsets = [0,  0, -1, -1, -2, -2, -3, -3]\n",
        "#         col_offsets = [0, -1,  0, -1,  0, -1,  0, -1]\n",
        "#     if (direction == DOWN):\n",
        "#         row_offsets = [0,  0,  1,  1,  2,  2,  3,  3]\n",
        "#         col_offsets = [0, -1,  0, -1,  0, -1,  0, -1]\n",
        "#     if (direction == CW):\n",
        "#         row_offsets = [0,  0,  1,  1,  1,  1,  0,  0]\n",
        "#         col_offsets = [0, -1,  0, -1, -2, -3, -2, -3]\n",
        "#     if (direction == CCW):\n",
        "#         row_offsets = [0,  0, -1, -1, -1, -1,  0,  0]\n",
        "#         col_offsets = [0, -1,  0, -1, -2, -3, -2, -3]\n",
        "\n",
        "#     for i, j in zip(row_offsets, col_offsets):\n",
        "#         cell = qr_cells_numeric[data_start_i+i, data_start_j+j]\n",
        "#         result.append(int(cell if MASKS[mask_str](data_start_i+i, data_start_j+j) else not cell))\n",
        "\n",
        "#     return result[:4] if direction == UP_ENC else result\n",
        "\n",
        "# enc_bits = apply_mask(grid_cells_num-1, grid_cells_num-1, UP_ENC)\n",
        "# enc_int = int(''.join([str(bit) for bit in enc_bits]), 2)\n",
        "# print(f'{enc_bits} = Byte encoding (8 bits per character)')\n",
        "\n",
        "# len_bits = apply_mask(grid_cells_num-3, grid_cells_num-1, UP)\n",
        "# len_int = int(''.join([str(bit) for bit in len_bits]), 2)\n",
        "# print(f'{len_bits} = {len_int} data symbols, each consisting of 8 bits')\n",
        "\n",
        "# data_starting_indices = [\n",
        "# [grid_cells_num-7, grid_cells_num-1, UP],\n",
        "# [grid_cells_num-11, grid_cells_num-1, CCW],\n",
        "# [grid_cells_num-10, grid_cells_num-3, DOWN],\n",
        "# [grid_cells_num-6, grid_cells_num-3, DOWN],\n",
        "# [grid_cells_num-2, grid_cells_num-3, CW],\n",
        "# [grid_cells_num-3, grid_cells_num-5, UP],\n",
        "# [grid_cells_num-7, grid_cells_num-5, UP],\n",
        "# [grid_cells_num-11, grid_cells_num-5, CCW],\n",
        "# [grid_cells_num-10, grid_cells_num-7, DOWN],\n",
        "# [grid_cells_num-6, grid_cells_num-7, DOWN],\n",
        "# [grid_cells_num-2, grid_cells_num-7, CW],\n",
        "# [grid_cells_num-3, grid_cells_num-9, UP],\n",
        "# [grid_cells_num-7, grid_cells_num-9, UP],\n",
        "# [grid_cells_num-11, grid_cells_num-9, UP],\n",
        "# [grid_cells_num-16, grid_cells_num-9, UP],\n",
        "# [grid_cells_num-20, grid_cells_num-9, CCW],\n",
        "# [grid_cells_num-19, grid_cells_num-11, DOWN],\n",
        "# [grid_cells_num-14, grid_cells_num-11, DOWN],\n",
        "# [grid_cells_num-10, grid_cells_num-11, DOWN],\n",
        "# [grid_cells_num-6, grid_cells_num-11, DOWN],\n",
        "# # Hmm..? I actually don't know how to proceed now lol\n",
        "# ]\n",
        "\n",
        "# message_bits = []\n",
        "# message_bits.extend(enc_bits)\n",
        "# message_bits.extend(len_bits)\n",
        "# extracted_data_no_error_correction = ''\n",
        "# for a, b, d in data_starting_indices:  # For each starting index and direction\n",
        "#     bits = apply_mask(a, b, d)  # Extract the bits per the indexed QR code symbol\n",
        "#     bit_string = ''.join([str(bit) for bit in bits])  # Convert to string of bits\n",
        "#     alpha_char = chr(int(bit_string, 2))  # Convert binary to int, then to a char\n",
        "#     if bit_string[:4] == \"0000\":  # If the first 4 bits are 0s, this is the END\n",
        "#         print(f'{bit_string[:4]}...         = NULL TERMINATOR (END Symbol, SKIP!)')\n",
        "#         message_bits.extend(bits[:4])  # Append only the four bits\n",
        "#         break\n",
        "#     else:  # If not the END symbol, append full set of bits\n",
        "#         message_bits.extend(bits)\n",
        "#         extracted_data_no_error_correction += alpha_char\n",
        "#     print(f'{bit_string} (={int(bit_string, 2):03d}) = {alpha_char}')\n",
        "\n",
        "# print(f'\\ni.e., the data and ECCs in the QR code as-is are \"{extracted_data_no_error_correction}\"')"
      ],
      "metadata": {
        "id": "l0HsPj64SFfE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
