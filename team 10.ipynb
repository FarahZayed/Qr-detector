{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0pH4EtGBSPDm"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FarahZayed/Qr-detector/blob/master/team%2010.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **import** **libraries**"
      ],
      "metadata": {
        "id": "UOj6ulzFR7Ki"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GgLWkJvJR5Tu"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFilter\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import io, color, filters, feature\n",
        "from math import sqrt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the image"
      ],
      "metadata": {
        "id": "c3EIx7B1SRfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#insert the path of the image\n",
        "img = cv2.imread(\"/content/03-Leffy-bina-ya-donya.png\", cv2.IMREAD_GRAYSCALE)\n",
        "_, thresh = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n"
      ],
      "metadata": {
        "id": "3ShONM6vSXcX"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Function ma7tgnha"
      ],
      "metadata": {
        "id": "0pH4EtGBSPDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def angle_ABC(a, b, c):\n",
        "\n",
        "\n",
        "    ba = a - b\n",
        "    bc = c - b\n",
        "\n",
        "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "    angle = np.arccos(cosine_angle)\n",
        "    return np.degrees(angle)\n",
        "\n",
        "def find_bad_dists(hull, distance = 10):\n",
        "    mask = []\n",
        "    points, _, _ = hull.shape\n",
        "\n",
        "    for i in range(points):\n",
        "        # determine points to compare and make sure that last and first are compared too\n",
        "        ai = i\n",
        "        bi = (i+1)%points\n",
        "        # x, y for both points\n",
        "        x1 = hull[ai][0][0]\n",
        "        y1 = hull[ai][0][1]\n",
        "        x2 = hull[bi][0][0]\n",
        "        y2 = hull[bi][0][1]\n",
        "\n",
        "        #distance\n",
        "        dist = np.sqrt((x2 - x1)**2 + (y2 - y1)**2 )\n",
        "        #build mask with distances out ot range\n",
        "        if dist < distance:\n",
        "            mask.append(bi)\n",
        "    return mask\n",
        "\n",
        "\n",
        "\n",
        "def find_bad_angles(hull, acute_angle = 30, obtuse_angle = 140):\n",
        "\n",
        "    mask = []\n",
        "    points, _, _ = hull.shape\n",
        "\n",
        "    for i in range(points):\n",
        "        # determine points to compare angle and make sure that last and first are compared too\n",
        "        ai = i\n",
        "        bi = (i+1)%points\n",
        "        ci = (i+2)%points\n",
        "\n",
        "\n",
        "        a = hull[ai][0]\n",
        "        b = hull[bi][0]\n",
        "        c = hull[ci][0]\n",
        "        angle = angle_ABC(a, b, c)\n",
        "        if angle > obtuse_angle or angle < acute_angle:\n",
        "            mask.append(bi)\n",
        "    return mask\n",
        "\n",
        "def mark_points(hull):\n",
        "    a_list=[]\n",
        "    points, _, _ = hull.shape\n",
        "\n",
        "    for i in range(points):\n",
        "        r = int(np.random.randint(100,255,1)[0])\n",
        "        g = int(np.random.randint(100,255,1)[0])\n",
        "        b = int(np.random.randint(100,255,1)[0])\n",
        "        a_list.append(tuple([hull[i][0][0], hull[i][0][1]]))\n",
        "\n",
        "    return a_list\n",
        "\n",
        "\n",
        "\n",
        "def shahd(img,thresh):\n",
        "\n",
        "        invimg = invert_image(img)\n",
        "\n",
        "        #invg = cv2.cvtColor(invimg,cv2.COLOR_RGB2GRAY)\n",
        "        ret,thresh = cv2.threshold(invimg,127,255,0)\n",
        "\n",
        "        contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "      #  image =  invg = cv2.cvtColor(invimg,cv2.COLOR_GRAY2RGB)\n",
        "        length = len(contours)\n",
        "        cont = np.concatenate([contours[i] for i in range(length)], axis=0)\n",
        "\n",
        "        cnt_len = cv2.arcLength(cont, True)\n",
        "        cont = cv2.approxPolyDP(cont, .01*cnt_len, True)\n",
        "        hull = cv2.convexHull(cont)\n",
        "\n",
        "\n",
        "        mask = find_bad_dists(hull)\n",
        "        hull = np.delete(hull, mask, axis=0)\n",
        "\n",
        "        mask = find_bad_angles(hull)\n",
        "        hull = np.delete(hull, mask, axis=0)\n",
        "\n",
        "        a_list=mark_points(hull)\n",
        "\n",
        "        uni_hull = []\n",
        "        uni_hull.append(hull)\n",
        "\n",
        "\n",
        "        shahdlist =  mark_points(hull)\n",
        "        return shahdlist\n"
      ],
      "metadata": {
        "id": "OJByWf-9B_h_"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_quietnoise(img):\n",
        "    start_row = -1\n",
        "    start_col = -1\n",
        "    end_row = -1\n",
        "    end_col = -1\n",
        "    for row_index, row in enumerate(img):\n",
        "     for pixel in row:\n",
        "        if pixel != 255:\n",
        "            start_row = row_index\n",
        "            break\n",
        "     if start_row != -1:\n",
        "        break\n",
        "    for row_index, row in enumerate(img[::-1]):\n",
        "     for pixel in row:\n",
        "        if pixel != 255:\n",
        "            end_row = img.shape[0] - row_index\n",
        "            break\n",
        "     if end_row != -1:\n",
        "        break\n",
        "    for col_index, col in enumerate(cv2.transpose(img)):\n",
        "     for pixel in col:\n",
        "        if pixel != 255:\n",
        "            start_col = col_index\n",
        "            break\n",
        "     if start_col != -1:\n",
        "        break\n",
        "    for col_index, col in enumerate(cv2.transpose(img)[::-1]):\n",
        "     for pixel in col:\n",
        "        if pixel != 255:\n",
        "            end_col = img.shape[1] - col_index\n",
        "            break\n",
        "     if end_col != -1:\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    qr_no_quiet_zone = img[start_row:end_row, start_col:end_col]\n",
        "    return qr_no_quiet_zone\n",
        "\n",
        "    fig = plt.figure(figsize=(5, 5));\n",
        "    plt.xticks([], []);\n",
        "    plt.yticks([], []);\n",
        "    fig.get_axes()[0].spines[:].set_color('red');\n",
        "    fig.get_axes()[0].spines[:].set_linewidth(40);\n",
        "    fig.get_axes()[0].spines[:].set_position((\"outward\", 20))\n",
        "    plt.title('QR code without quiet zone', y = 1.15, color='red');\n",
        "    plt.imshow(qr_no_quiet_zone, cmap='gray');\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def distance(point1, point2):\n",
        "    return sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
        "\n",
        "\n",
        "def butterworthLP(D0, imgShape, n):\n",
        "    base = np.zeros(imgShape[:2])\n",
        "    rows, cols = imgShape[:2]\n",
        "    center = (rows / 2, cols / 2)\n",
        "    for x in range(cols):\n",
        "        for y in range(rows):\n",
        "            base[y, x] = 1 / (1 + (distance((y, x), center) / D0) ** (2 * n))\n",
        "    return base\n",
        "\n",
        "def getcellsize(imgremove):\n",
        "    size=0\n",
        "    for pixel in imgremove[0]:\n",
        "      if (pixel != 0): break\n",
        "      size += 1\n",
        "    if(size ==0): return 0,0\n",
        "    grid_cell_size = round(size/7)\n",
        "    grid_cells_num = round(imgremove.shape[0]/grid_cell_size)\n",
        "    return grid_cell_size,grid_cells_num\n",
        "\n",
        "\n",
        "def get_start_row_col(img):\n",
        "    start_row = -1\n",
        "    start_col = -1\n",
        "    for row_index, row in enumerate(img):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                start_row = row_index\n",
        "                break\n",
        "        if start_row != -1:\n",
        "            break\n",
        "    for col_index, col in enumerate(cv2.transpose(img)):\n",
        "        for pixel in col:\n",
        "            if pixel != 255:\n",
        "                start_col = col_index\n",
        "                break\n",
        "        if start_col != -1:\n",
        "            break\n",
        "    return start_row, start_col\n",
        "\n",
        "\n",
        "def getcellsizeForRotation(imgremove):\n",
        "    size=0\n",
        "    for pixel in imgremove[-1, ::-1]:\n",
        "      if (pixel != 0): break\n",
        "      size += 1\n",
        "    if(size ==0): return 0,0\n",
        "    grid_cell_size = round(size/7)\n",
        "    grid_cells_num = round(imgremove.shape[0]/grid_cell_size)\n",
        "    return grid_cell_size,grid_cells_num\n",
        "\n",
        "def getqrcell(remove, grid_cell_size, grid_cells_num):\n",
        "    if remove.shape[0] % grid_cell_size != 0 or remove.shape[1] % grid_cell_size != 0:\n",
        "            print(\"Warning: Grid cell size resulted in fraction. Adjusting...\")\n",
        "            img_resized = cv2.resize(remove, (924, 924))\n",
        "\n",
        "    # If the resized image is larger than the target size, crop it\n",
        "            if remove.shape[0] > 924 or remove.shape[1] > 924:\n",
        "                remove = img_resized[:924, :924]\n",
        "            else:\n",
        "                remove = img_resized\n",
        "    try:\n",
        "            qr_cells = remove.reshape((\n",
        "            grid_cells_num,\n",
        "            grid_cell_size,\n",
        "            grid_cells_num,\n",
        "            grid_cell_size,\n",
        "            )).swapaxes(1, 2)\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"Error: Unable to reshape image into grid cells.\")\n",
        "        qr_cells=0\n",
        "    return qr_cells\n",
        "\n",
        "def correctqrcell(qr_cells):\n",
        "\n",
        " for i in range(qr_cells.shape[0]):\n",
        "   for j in range(qr_cells.shape[1]):\n",
        "    cell=qr_cells[i][j]\n",
        "    white_pixel_count = np.sum(cell == 255)\n",
        "    black_pixel_count = np.sum(cell == 0)\n",
        "    if white_pixel_count > black_pixel_count:\n",
        "        for k in range(grid_cell_size):\n",
        "            for l in range(grid_cell_size):\n",
        "                qr_cells[i][j][k][l]=255\n",
        "    elif black_pixel_count > white_pixel_count:\n",
        "        for k in range(grid_cell_size):\n",
        "            for l in range(grid_cell_size):\n",
        "                qr_cells[i][j][k][l]=0\n",
        "\n",
        "\n",
        "    elif black_pixel_count == white_pixel_count:\n",
        "        for k in range(grid_cell_size):\n",
        "            for l in range(grid_cell_size):\n",
        "                qr_cells[i][j][k][l]=0\n",
        "    return qr_cells\n"
      ],
      "metadata": {
        "id": "LkeUEJYZSmMY"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# function that raise the flags"
      ],
      "metadata": {
        "id": "LieUdBISTZO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Note: rotation hat crash fi sorten 3ashan el binrization bytl3 kolo aswd aw kolo abyd fa mmken na3ml binarize 7asb el case\n",
        "#mesh 3arfa nashof?? PLUS el banana mafrod ttl3 anha rotated!!! mesh 3arf bardo\n",
        "def checkrotation(img):\n",
        "    imgremove= remove_quietnoise(img)\n",
        "    grid_cell_size,grid_cell_num= getcellsizeForRotation(imgremove)\n",
        "\n",
        "    if grid_cell_size==0:\n",
        "        print(\"The image is not rotated it may have some other noise that must be solved first!!!\")\n",
        "        return False\n",
        "    inverted_img = cv2.bitwise_not(imgremove)\n",
        "    shapeofste=3*grid_cell_size -1\n",
        "    se_rect = cv2.getStructuringElement(cv2.MORPH_RECT, (shapeofste, shapeofste))\n",
        "    _, se_binarized = cv2.threshold(se_rect, 128, 1, cv2.THRESH_BINARY)\n",
        "    se_binarized = se_binarized.astype(int)\n",
        "    se_binarized[se_binarized == 0] = -1\n",
        "    erosion = cv2.erode(inverted_img, se_rect, iterations=1)\n",
        "    partwithrotato=erosion[(imgremove.shape[0]-7*grid_cell_size):imgremove.shape[0], imgremove.shape[1]-7*grid_cell_size:imgremove.shape[1]];\n",
        "    count=0\n",
        "    for row in range(partwithrotato.shape[0]):\n",
        "        for col in range(partwithrotato.shape[1]):\n",
        "            if partwithrotato[row,col] == 255:\n",
        "                count=count+1\n",
        "    if(count>0 and count<10):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def checkblured(image):\n",
        "    f_transform = np.fft.fft2(image)\n",
        "    f_transform_shifted = np.fft.fftshift(f_transform)\n",
        "    magnitude_spectrum = 20*np.log(np.abs(f_transform_shifted))\n",
        "    rows, cols = image.shape\n",
        "    center_row = rows // 2\n",
        "    center_col = cols // 2\n",
        "    roi_size = 10\n",
        "    dc_component = magnitude_spectrum[center_row, center_col]\n",
        "    roi = magnitude_spectrum[center_row - roi_size:center_row + roi_size + 1,\n",
        "                              center_col - roi_size:center_col + roi_size + 1]\n",
        "    avg_roi = round(np.mean(roi))\n",
        "    if(np.mean(magnitude_spectrum[100:-100, 100:-100])== float('-inf')):\n",
        "        return False\n",
        "    else:\n",
        "        high_freq_avg=round(np.mean(magnitude_spectrum[100:-100, 100:-100]))\n",
        "\n",
        "    low_accepted_freqcompatcenter=290\n",
        "    highest_accepted_change=120\n",
        "    if(avg_roi>290 and high_freq_avg<120):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "#check mostly white\n",
        "def is_mostly_white(img):\n",
        "    row, col = img.shape\n",
        "    count=0\n",
        "    for i in range(row):\n",
        "        for j in range(col):\n",
        "            if (img[i][j] < 150) :\n",
        "                count=count+1\n",
        "    if count>0:\n",
        "       return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "#check shifting\n",
        "\n",
        "def detect_shift_rows(img):\n",
        "    row,col=get_start_row_col(img)\n",
        "    print(row,col)\n",
        "    count_black =0\n",
        "    count_white =0\n",
        "    flag=True\n",
        "    first_black_pixel = 0\n",
        "    last_black_pixel = 0\n",
        "    for i in range(len(img[row])-1):\n",
        "        if img[row][i] !=255:\n",
        "            first_black_pixel = i\n",
        "            count_black=count_black+1\n",
        "        if count_black==1:\n",
        "            break\n",
        "    for j in range(first_black_pixel,len(img[row])-1):\n",
        "        if img[row][j]!=0:\n",
        "            last_black_pixel=j-1\n",
        "            count_white+=1\n",
        "        if count_white==1:\n",
        "            break\n",
        "    for k in range(first_black_pixel,last_black_pixel):\n",
        "       if img[row][k]!=0:\n",
        "          flag=False\n",
        "\n",
        "\n",
        "    if row>0 and col>0 and col!=0 and row!=0 and col!=row and flag==True:\n",
        "        if (row-col)<12:\n",
        "            return True\n",
        "        else:\n",
        "          return False\n",
        "    else:\n",
        "          return False\n",
        "\n",
        "\n",
        "#checks skewness\n",
        "def checkskew(img):\n",
        "    skewflag=False\n",
        "    unwarpedflag=False\n",
        "    img = np.uint8(img)\n",
        "    edges = cv2.Canny(img, 100, 200)\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if(contours ==() ):\n",
        "        return skewflag,unwarpedflag\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "    qr_code_region = img[y:y + h, x:x + w]\n",
        "    edges = cv2.Canny(qr_code_region, 50, 150, apertureSize=3)\n",
        "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)\n",
        "    if lines is None:\n",
        "        return skewflag,unwarpedflag\n",
        "    vertical_angles = []\n",
        "    horizontal_angles = []\n",
        "\n",
        "    for line in lines:\n",
        "        rho, theta = line[0]\n",
        "        if np.pi / 4 < theta < 3 * np.pi / 4:\n",
        "            vertical_angles.append(theta)\n",
        "        else:\n",
        "            horizontal_angles.append(theta)\n",
        "    vertical_skewness = np.mean(vertical_angles) if vertical_angles else 0\n",
        "    horizontal_skewness = np.mean(horizontal_angles) if horizontal_angles else 0\n",
        "\n",
        "    vertical_skewness_deg = round(np.rad2deg(vertical_skewness))\n",
        "    horizontal_skewness_deg = round(np.rad2deg(horizontal_skewness))\n",
        "    difference=round(abs(horizontal_skewness_deg - vertical_skewness_deg))\n",
        "    if(difference==90 and vertical_skewness_deg!=90 and horizontal_skewness_deg!=90):\n",
        "        skewflag=True\n",
        "        return skewflag,unwarpedflag\n",
        "    elif(horizontal_skewness_deg < 90 and horizontal_skewness_deg>10 and vertical_skewness_deg<90):\n",
        "        unwarpedflag=True\n",
        "        return skewflag,unwarpedflag\n",
        "    else:\n",
        "        return skewflag,unwarpedflag\n",
        "\n",
        "\n",
        "#check black image\n",
        "def is_mostly_black(image):\n",
        "    image = np.uint8(image)\n",
        "    hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
        "    hist /= hist.sum()\n",
        "\n",
        "    cumulative_sum = hist.cumsum()\n",
        "\n",
        "    return cumulative_sum.argmax() < 30\n",
        "\n",
        "def checkflip(img):\n",
        "    flipped_image = cv2.flip(img, 1) # original  flipp\n",
        "    imgremove = remove_quietnoise(flipped_image)\n",
        "    grid_cell_size,grid_cells_num=getcellsize(imgremove)\n",
        "    if grid_cell_size==0: return False\n",
        "    print(\"##########################\")\n",
        "    print(grid_cell_size)\n",
        "    qr_cells=getqrcell(imgremove,grid_cell_size,grid_cells_num)\n",
        "    if isinstance(qr_cells, (int)):\n",
        "        print(\"cant do qrcell\")\n",
        "        return False\n",
        "    qr_cells_numeric = np.ndarray((grid_cells_num, grid_cells_num), dtype=np.uint8)\n",
        "    for i, row in enumerate(qr_cells):\n",
        "      for j, cell in enumerate(row):\n",
        "          qr_cells_numeric[i, j] = (np.median(cell) // 255)\n",
        "\n",
        "    fec = []\n",
        "    fec.append(qr_cells_numeric[8, 0:6])\n",
        "    fec.extend(qr_cells_numeric[8, 7:8])\n",
        "\n",
        "    fec.extend(qr_cells_numeric[0:6, 8])\n",
        "    fec.extend(qr_cells_numeric[7:9, 8])\n",
        "    fec = [int(c) for sublist in fec for c in (sublist.ravel() if isinstance(sublist, np.ndarray) else [sublist])]\n",
        "\n",
        "    fec2 = []\n",
        "    fec2.append(qr_cells_numeric[-1:-8:-1, 8])\n",
        "    fec2.extend(qr_cells_numeric[8, -1:-9:-1])\n",
        "    fec2 = [int(c) for sublist in fec2 for c in (sublist.ravel() if isinstance(sublist, np.ndarray) else [sublist])]\n",
        "\n",
        "    if (np.array_equal(fec2, fec)):\n",
        "      print(\"photo was flipped\")\n",
        "      return True\n",
        "    else:\n",
        "      print(\"not flipped\")\n",
        "      return False\n",
        "\n",
        "def inversioncheck(img):\n",
        "    mean_intensity = cv2.mean(img)[0]\n",
        "    #MESH GENERIC WALA EHHH\n",
        "    return (mean_intensity < 100 and mean_intensity>30)\n",
        "\n",
        "\n",
        "def detect_periodic_noise(image,threshold_factor=1 / 4):\n",
        "    resized_image = cv2.resize(image, (256, 256))\n",
        "    fft_image = np.fft.fft2(resized_image)\n",
        "    max_intensity = np.max(fft_image)\n",
        "    print(\"Maximum value of the whole image\", max_intensity)\n",
        "    horizontal_component = np.abs(np.fft.fftshift(fft_image)[:, :fft_image.shape[1] // 2])\n",
        "    max_horizontal_component = np.max(horizontal_component)\n",
        "    print(\"Maximum value of horizontal component:\", max_horizontal_component)\n",
        "    noise_threshold = max_intensity * threshold_factor\n",
        "    if max_horizontal_component > noise_threshold:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def detect_patterns_in_roi(image, threshold_factor=1.2):\n",
        "    resized_image = cv2.resize(image, (256, 256))\n",
        "    dft_noise = np.fft.fft2(resized_image)\n",
        "    dft_noise_shift = np.fft.fftshift(dft_noise)\n",
        "    epsilon = 1e-10\n",
        "    magnitude_spectrum = 20 * np.log(np.abs(dft_noise_shift)+ epsilon)\n",
        "\n",
        "    rows, cols = dft_noise_shift.shape\n",
        "    center_row, center_col = rows // 2, cols // 2\n",
        "\n",
        "    roi_size = 250\n",
        "    roi = magnitude_spectrum[center_row - roi_size:center_row + roi_size,\n",
        "                          center_col - roi_size:center_col + roi_size]\n",
        "\n",
        "    roi_mean = np.mean(roi)\n",
        "\n",
        "    threshold = threshold_factor * roi_mean\n",
        "\n",
        "    significant_peaks_exist = np.any(roi > threshold)\n",
        "    if significant_peaks_exist:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n"
      ],
      "metadata": {
        "id": "RKjHTS4TTYM1"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# flags to do preprocessing"
      ],
      "metadata": {
        "id": "PzSFn2IAS6EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotationflag= checkrotation(img)\n",
        "\n",
        "SaltandPepper = detect_patterns_in_roi(img)\n",
        "\n",
        "bluredflag =checkblured(img)\n",
        "\n",
        "shiftedrowsflag= detect_shift_rows(img)\n",
        "\n",
        "mostlywhiteflag= is_mostly_white(img)\n",
        "\n",
        "periodicflag = detect_periodic_noise(img)\n",
        "\n",
        "skewedflag,unwarpedflag = checkskew(img)\n",
        "\n",
        "mostlyblackflag=is_mostly_black(img)\n",
        "\n",
        "inversionflag=inversioncheck(img)\n",
        "\n",
        "flipflag =checkflip(img)\n",
        "\n",
        "print(\"The flag of inverted image : \",inversionflag )\n",
        "print(\"The flag of rotation: \",rotationflag )\n",
        "print(\"The flag of all white image: \",mostlywhiteflag )\n",
        "print(\"The flag of blured image: \",bluredflag )\n",
        "print(\"The flag of shifted rows: \",shiftedrowsflag )\n",
        "print(\"The flag of periodic noise: \",periodicflag )\n",
        "print(\"The flag of skewed images : \",skewedflag )\n",
        "print(\"The flag of all black image : \",mostlyblackflag )\n",
        "print(\"The flag of unwarped image : \",unwarpedflag )\n",
        "print(\"The flag of flipped image : \",flipflag )\n",
        "print(\"The flag of saltandpepper image : \",SaltandPepper )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFBLVZSoTGFT",
        "outputId": "5943454f-5955-4bdc-8b8c-44783c2fe970"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-91-84ef0f7e57d0>:31: RuntimeWarning: divide by zero encountered in log\n",
            "  magnitude_spectrum = 20*np.log(np.abs(f_transform_shifted))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44 44\n",
            "Maximum value of the whole image (9605172+0j)\n",
            "Maximum value of horizontal component: 989213.7444540999\n",
            "##########################\n",
            "44\n",
            "not flipped\n",
            "The flag of inverted image :  False\n",
            "The flag of rotation:  True\n",
            "The flag of all white image:  False\n",
            "The flag of blured image:  False\n",
            "The flag of shifted rows:  False\n",
            "The flag of periodic noise:  False\n",
            "The flag of skewed images :  False\n",
            "The flag of all black image :  False\n",
            "The flag of unwarped image :  False\n",
            "The flag of flipped image :  False\n",
            "The flag of saltandpepper image :  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function responsible for preprocessing"
      ],
      "metadata": {
        "id": "3imjv2MEUQYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def invert_image(image):\n",
        "    # inverted_gray = 255 - image\n",
        "    # inverted_image = cv2.cvtColor(inverted_gray, cv2.COLOR_GRAY2BGR)\n",
        "    _,img = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY)\n",
        "    inverted_image=cv2.bitwise_not(img)\n",
        "    return inverted_image\n",
        "\n",
        "def a3dlrotation(img):\n",
        "    print(\"in\")\n",
        "    imgremove= remove_quietnoise(img)\n",
        "    while(checkrotation(imgremove)):\n",
        "        imgremove = cv2.rotate(imgremove, cv2.ROTATE_90_CLOCKWISE)\n",
        "    return imgremove\n",
        "\n",
        "def flip(img):\n",
        "\n",
        "    img=cv2.flip(img,1)\n",
        "    return img\n",
        "\n",
        "def nadafblured(img):\n",
        "         # nazbt el soraa\n",
        "        blurred = cv2.GaussianBlur(img, (7, 7), 0)\n",
        "        sharpened = cv2.addWeighted(img, 2.5, blurred, -0.5, 0)\n",
        "        _, thresh_img = cv2.threshold(sharpened, 127, 255, cv2.THRESH_BINARY)\n",
        "        #shalena el noise w shwait araf erode keda\n",
        "        remove= remove_quietnoise(thresh_img)\n",
        "        se_rect = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
        "        _, se_binarized = cv2.threshold(se_rect, 128, 1, cv2.THRESH_BINARY)\n",
        "        se_binarized = se_binarized.astype(int)\n",
        "        se_binarized[se_binarized == 0] = -1\n",
        "        erosion = cv2.erode(remove, se_binarized, iterations=1)\n",
        "        needcorrectionimg=erosion\n",
        "        return needcorrectionimg\n",
        "\n",
        "def unwarped(img,thresh):\n",
        "        listt  = shahd(img,thresh)\n",
        "        rows1 , cols1  = img.shape\n",
        "        pts2 = np.array([[cols1,rows1],[0,rows1],[0,0], [cols1,0]],np.float32)\n",
        "        pts1 = np.array(listt,np.float32)\n",
        "        M = cv2.getPerspectiveTransform(pts1,pts2)\n",
        "        dst = cv2.warpPerspective(img,M,(cols1,rows1))\n",
        "        return dst\n",
        "\n",
        "\n",
        "def edit_white_img(img):\n",
        "    first_pixel=img[0,0]\n",
        "    for i in range(img.shape[0]):\n",
        "        for j in range(img.shape[1]):\n",
        "            if img[i][j] == first_pixel:\n",
        "                img[i][j] = 225\n",
        "            else:\n",
        "                img[i][j] = 0\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "def solve_shifted_rows(img):\n",
        "    start_row = -1\n",
        "    start_col = -1\n",
        "    end_row = -1\n",
        "    end_col = -1\n",
        "    _, img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
        "    for row_index, row in enumerate(img):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                start_row = row_index\n",
        "                start_col =row_index\n",
        "                break\n",
        "        if start_row != -1:\n",
        "            break\n",
        "\n",
        "    for row_index, row in enumerate(img[::-1]):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                end_row = img.shape[0] - row_index\n",
        "                end_col =img.shape[0] - row_index\n",
        "                break\n",
        "        if end_row != -1:\n",
        "            break\n",
        "\n",
        "\n",
        "    qr_no_quiet_zone = img[start_row:end_row, start_col:end_col]\n",
        "\n",
        "    size = 0\n",
        "    for pixel in qr_no_quiet_zone[0]:\n",
        "        if (pixel != 0): break\n",
        "        size += 1\n",
        "\n",
        "    grid_cell_size = round(size/7)\n",
        "    grid_cells_num = round(qr_no_quiet_zone.shape[0]/grid_cell_size)\n",
        "\n",
        "    img_resized = cv2.resize(qr_no_quiet_zone, (grid_cells_num*grid_cell_size, grid_cells_num*grid_cell_size))\n",
        "\n",
        "    qr_cells = img_resized.reshape((\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "    )).swapaxes(1, 2)\n",
        "\n",
        "    # BRWANA 3AYZHA HENA LEHHH\n",
        "    for i in range(qr_cells.shape[0]):\n",
        "        for j in range(qr_cells.shape[1]):\n",
        "            cell=qr_cells[i][j]\n",
        "            white_pixel_count = np.sum(cell == 255)\n",
        "            black_pixel_count = np.sum(cell == 0)\n",
        "            if white_pixel_count > black_pixel_count:\n",
        "                for k in range(grid_cell_size):\n",
        "                    for l in range(grid_cell_size):\n",
        "                        qr_cells[i][j][k][l]=255\n",
        "            elif black_pixel_count > white_pixel_count:\n",
        "                for k in range(grid_cell_size):\n",
        "                    for l in range(grid_cell_size):\n",
        "                        qr_cells[i][j][k][l]=0\n",
        "\n",
        "\n",
        "            elif black_pixel_count == white_pixel_count:\n",
        "                for k in range(grid_cell_size):\n",
        "                    for l in range(grid_cell_size):\n",
        "                        qr_cells[i][j][k][l]=0\n",
        "    return img_resized\n",
        "\n",
        "\n",
        "def dalma(image):\n",
        "        image1 = image\n",
        "        thresh,binary_image = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "        image = cv2.inpaint(image1, binary_image, inpaintRadius=3,flags=cv2.INPAINT_TELEA)\n",
        "\n",
        "\n",
        "\n",
        "        mask = cv2.threshold(image, 10, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "        lightened_image = np.where(mask == 255, np.clip(image * 100, 0, 255).astype(np.uint8), image)\n",
        "\n",
        "        _, mask = cv2.threshold(lightened_image, 75, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        mask = cv2.bitwise_not(mask)\n",
        "\n",
        "        _, bimage = cv2.threshold(lightened_image, 0, 255, cv2.THRESH_BINARY)\n",
        "        return bimage\n",
        "\n",
        "def orientSkewness(img):\n",
        "        _, img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
        "        edges = cv2.Canny(img, 100, 200)\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "        qr_code_region = img[y:y + h, x:x + w]\n",
        "        # Apply edge detection\n",
        "        edges = cv2.Canny(qr_code_region, 50, 150, apertureSize=3)\n",
        "        lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)\n",
        "        vertical_angles = []\n",
        "        horizontal_angles = []\n",
        "\n",
        "        for line in lines:\n",
        "            rho, theta = line[0]\n",
        "            if np.pi / 4 < theta < 3 * np.pi / 4:\n",
        "                vertical_angles.append(theta)\n",
        "            else:\n",
        "                horizontal_angles.append(theta)\n",
        "\n",
        "        vertical_skewness = np.mean(vertical_angles) if vertical_angles else 0\n",
        "        horizontal_skewness = np.mean(horizontal_angles) if horizontal_angles else 0\n",
        "\n",
        "        vertical_skewness_deg = np.rad2deg(vertical_skewness)\n",
        "        horizontal_skewness_deg = np.rad2deg(horizontal_skewness)\n",
        "\n",
        "        rotation_angle_deg = 180+horizontal_skewness_deg\n",
        "        rows, cols = img.shape[:2]\n",
        "        rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotation_angle_deg, 1)\n",
        "        img = cv2.warpAffine(img, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR,\n",
        "                                    borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255) )\n",
        "\n",
        "        qr_code_region = cv2.warpAffine(qr_code_region, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR,\n",
        "                            borderMode=cv2.BORDER_CONSTANT)\n",
        "\n",
        "        contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        rect = cv2.minAreaRect(largest_contour)\n",
        "        angle = rect[-1]\n",
        "        if angle < -45:\n",
        "            angle += 90\n",
        "\n",
        "        rows, cols = img.shape[:2]\n",
        "        rotation_matrix = cv2.getRotationMatrix2D(rect[0], angle, 1)\n",
        "        rotated_image = cv2.warpAffine(img, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR,\n",
        "                                    borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "        border_width = 20  # Adjust the border width as needed\n",
        "        border_color = (255, 255, 255)  # White color\n",
        "        img = cv2.copyMakeBorder(img, border_width, border_width, border_width, border_width,\n",
        "                                            cv2.BORDER_CONSTANT, value=border_color)\n",
        "        if(checkrotation(img)):\n",
        "            img=a3dlrotation(img)\n",
        "            return img\n",
        "        else: return img\n",
        "\n",
        "\n",
        "def decompresso_espreso(img):\n",
        "    # convert to binary image\n",
        "    _, imgBinary = cv2.threshold(img, 170, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # apply Gaussian blur to smooth the image\n",
        "    blurred = cv2.GaussianBlur(imgBinary, (5, 5), 0)\n",
        "\n",
        "    # opening--> erosion then dilation 3ashan asheel el abyad and did finetuning till weselt le number of iterations da\n",
        "    # a 5x5 kernel of ones (3x3 msh hatenfa3)\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    eroded = cv2.erode(blurred, kernel, iterations = 6)\n",
        "    dilated = cv2.dilate(eroded, kernel, iterations = 7)\n",
        "    return dilated\n",
        "\n",
        "\n",
        "def periodicnoiseSolver(img):\n",
        "    fourier_transform = np.fft.fft2(img)\n",
        "    center_shift = np.fft.fftshift(fourier_transform)\n",
        "    epsilon = 1e-10  # A small constant to avoid zero values\n",
        "    fourier_noisy = 20 * np.log(np.abs(center_shift)+epsilon)\n",
        "\n",
        "    rows, cols = img.shape\n",
        "    crow, ccol = rows // 2, cols // 2\n",
        "\n",
        "    # horizontal mask\n",
        "    center_shift[crow :crow + 1, 0:ccol - 10] = 1\n",
        "    center_shift[crow :crow + 1, ccol + 10:] = 1\n",
        "    # vertical mask\n",
        "    # center_shift[:crow - 10, ccol - 4:ccol + 4] = 1\n",
        "    # center_shift[crow + 10:, ccol - 4:ccol + 4] = 1\n",
        "\n",
        "    filtered = center_shift * butterworthLP(80, img.shape, 10)\n",
        "\n",
        "    f_shift = np.fft.ifftshift(center_shift)\n",
        "    denoised_image = np.fft.ifft2(f_shift)\n",
        "    denoised_image = np.real(denoised_image)\n",
        "\n",
        "    f_ishift_blpf = np.fft.ifftshift(filtered)\n",
        "    denoised_image_blpf = np.fft.ifft2(f_ishift_blpf)\n",
        "    denoised_image_blpf = np.real(denoised_image_blpf)\n",
        "\n",
        "    fourier_noisy_noise_removed = 20 * np.log(np.abs(center_shift)+epsilon)\n",
        "    _, denoised_image_blpf_bin = cv2.threshold(denoised_image_blpf, 128, 255, cv2.THRESH_BINARY)\n",
        "    return denoised_image_blpf_bin\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Read the QR code image\n",
        "\n",
        "# Apply Gaussian blur\n",
        "def denoiseSaltPepper(image):\n",
        "      blurred_image = cv2.GaussianBlur(image, (1, 1), 0)\n",
        "      equalized_image = cv2.equalizeHist(blurred_image)\n",
        "      # Compute the Fourier Transform\n",
        "      f_transform = np.fft.fft2(image)\n",
        "      f_transform_shifted = np.fft.fftshift(f_transform)\n",
        "     # Create a rectangular mask\n",
        "      rect_width = 150\n",
        "      rect_height = 20\n",
        "      rows, cols = image.shape\n",
        "      mask_rect = np.zeros((rows, cols), dtype=np.uint8)\n",
        "      center_row, center_col = rows // 2, cols // 2\n",
        "      start_row = center_row - rect_height // 2\n",
        "      start_col = center_col - rect_width // 2\n",
        "      end_row = start_row + rect_height\n",
        "      end_col = start_col + rect_width\n",
        "      mask_rect[start_row:end_row, start_col:end_col] = 1\n",
        "      # Create a rectangular mask\n",
        "      rect_width2 = 20\n",
        "      rect_height2 = 150\n",
        "      rows, cols = image.shape\n",
        "      mask_rect2 = np.zeros((rows, cols), dtype=np.uint8)\n",
        "      center_row, center_col = rows // 2, cols // 2\n",
        "      start_row = center_row - rect_height2 // 2\n",
        "      start_col = center_col - rect_width2 // 2\n",
        "      end_row = start_row + rect_height2\n",
        "      end_col = start_col + rect_width2\n",
        "      mask_rect2[start_row:end_row, start_col:end_col] = 1\n",
        "      # circular mask\n",
        "      rows, cols = image.shape\n",
        "      center_row, center_col = rows // 2, cols // 2\n",
        "      radius_inner_circle = 0  # Radius for the central circular region (DC component)\n",
        "      radius_outer_circle = 30  # Radius for the outer annular region (bandpass filter)\n",
        "      mask_circle = np.zeros((rows, cols), dtype=np.uint8)\n",
        "      for i in range(rows):\n",
        "          for j in range(cols):\n",
        "              distance = np.sqrt((i - center_row) ** 2 + (j - center_col) ** 2)\n",
        "              if distance <= radius_outer_circle and distance >= radius_inner_circle:\n",
        "                  mask_circle[i, j] = 1\n",
        "\n",
        "      mask=mask_rect|mask_rect2|mask_circle\n",
        "\n",
        "      # Apply the bandpass filter\n",
        "      f_transform_filtered = f_transform_shifted *mask\n",
        "\n",
        "      # f_transform_filtered = f_transform_shifted * mask_circle\n",
        "      filtered_image = np.fft.ifftshift(f_transform_filtered)\n",
        "      filtered_image = np.fft.ifft2(filtered_image)\n",
        "      filtered_image = np.abs(filtered_image)\n",
        "\n",
        "      # Apply inverse Fourier Transform to obtain the filtered image\n",
        "      filtered_image = np.fft.ifftshift(f_transform_filtered)\n",
        "      filtered_image = np.fft.ifft2(filtered_image)\n",
        "      filtered_image = np.abs(filtered_image)\n",
        "      _, filtered_image = cv2.threshold(filtered_image, 128, 255, cv2.THRESH_BINARY)\n",
        "      # inverted_image = cv2.bitwise_not(filtered_image)\n",
        "\n",
        "      filtered_image = filtered_image.astype(np.uint8)\n",
        "      closing_kernel = np.ones((11,11), np.uint8)\n",
        "      closed_image= cv2.morphologyEx(filtered_image, cv2.MORPH_CLOSE, closing_kernel)\n",
        "\n",
        "      # erosion\n",
        "      closed_image = np.array(closed_image)\n",
        "      closed_image = closed_image.astype(np.uint8)\n",
        "      kernel = np.ones((9,9), np.uint8)  # You can adjust the size of the kernel as needed\n",
        "      eroded_image = cv2.erode(closed_image, kernel, iterations=1)\n",
        "\n",
        "      # ASEEEB EL PLOTS WALA LA YA GAM3A???? EL MO3EED 3AYZ YESHOFHA SA7?\n",
        "      # print(result_image.shape)\n",
        "      return eroded_image\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C2-13QUoUTMv"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "8L3NxC3xUH_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgafterpreproc=img\n",
        "\n",
        "if(rotationflag==True):\n",
        "    imgafterpreproc= a3dlrotation(img)\n",
        "\n",
        "if(bluredflag==True):\n",
        "    imgafterpreproc= nadafblured(img)\n",
        "\n",
        "if(mostlywhiteflag==True):\n",
        "    imgafterpreproc=edit_white_img(img)\n",
        "\n",
        "if(shiftedrowsflag==True):\n",
        "    imgafterpreproc = solve_shifted_rows(img)\n",
        "\n",
        "if(mostlyblackflag==True):\n",
        "    imgafterpreproc=dalma(img)\n",
        "\n",
        "if(skewedflag ==True):\n",
        "    imgafterpreproc=orientSkewness(img)\n",
        "\n",
        "if (periodicflag==True):\n",
        "    imgafterpreproc=periodicnoiseSolver(img)\n",
        "\n",
        "if(unwarpedflag ==True):\n",
        "    imgafterpreproc=unwarped(img,thresh)\n",
        "    plt.imshow(imgafterpreproc,cmap='gray')\n",
        "#ba2et el if\n",
        "# plt.imshow(imgafterpreproc,cmap='gray')"
      ],
      "metadata": {
        "id": "qc794tlrUHp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78056dd6-6761-4ff1-b25b-e46fdafba277"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in\n",
            "The image is not rotated it may have some other noise that must be solved first!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgafterpreproc=img\n",
        "while(rotationflag or bluredflag or inversionflag or mostlywhiteflag or shiftedrowsflag or mostlyblackflag or skewedflag or unwarpedflag or periodicflag or flipflag or SaltandPepper):\n",
        "    if(inversionflag == True):\n",
        "        imgafterpreproc=invert_image(imgafterpreproc)\n",
        "\n",
        "    if(rotationflag==True):\n",
        "        imgafterpreproc= a3dlrotation(imgafterpreproc)\n",
        "\n",
        "    if(bluredflag==True):\n",
        "        imgafterpreproc= nadafblured(imgafterpreproc)\n",
        "\n",
        "    if(mostlywhiteflag==True):\n",
        "        imgafterpreproc=edit_white_img(imgafterpreproc)\n",
        "\n",
        "    if(shiftedrowsflag==True):\n",
        "        imgafterpreproc = solve_shifted_rows(imgafterpreproc)\n",
        "\n",
        "    if(periodicflag==True):\n",
        "        imgafterpreproc=periodicnoiseSolver(imgafterpreproc)\n",
        "\n",
        "    if(mostlyblackflag==True):\n",
        "        imgafterpreproc=dalma(imgafterpreproc)\n",
        "\n",
        "    if(skewedflag ==True):\n",
        "        imgafterpreproc=orientSkewness(imgafterpreproc)\n",
        "\n",
        "    if(unwarpedflag ==True):\n",
        "        _,thresh = cv2.threshold(imgafterpreproc, 128, 255, cv2.THRESH_BINARY)\n",
        "        imgafterpreproc=unwarped(imgafterpreproc,thresh)\n",
        "\n",
        "    if(flipflag == True):\n",
        "        imgafterpreproc=flip(imgafterpreproc)\n",
        "\n",
        "    if(SaltandPepper ==True):\n",
        "        imgafterpreproc=denoiseSaltPepper(imgafterpreproc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    rotationflag= checkrotation(imgafterpreproc)\n",
        "\n",
        "    SaltandPepper = detect_patterns_in_roi(imgafterpreproc)\n",
        "\n",
        "    bluredflag = checkblured(imgafterpreproc)\n",
        "\n",
        "    shiftedrowsflag= detect_shift_rows(imgafterpreproc)\n",
        "\n",
        "    mostlywhiteflag= is_mostly_white(imgafterpreproc)\n",
        "\n",
        "    skewedflag,unwarpedflag = checkskew(imgafterpreproc)\n",
        "\n",
        "    periodicflag=detect_periodic_noise(imgafterpreproc)\n",
        "\n",
        "    mostlyblackflag=is_mostly_black(imgafterpreproc)\n",
        "\n",
        "    inversionflag=inversioncheck(imgafterpreproc)\n",
        "\n",
        "    flipflag=checkflip(imgafterpreproc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.imshow(imgafterpreproc,cmap='gray')"
      ],
      "metadata": {
        "id": "n52jZ1uBDVTm",
        "outputId": "39c6fb39-3ab1-48fb-86ff-30b3a5a47b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in\n",
            "The image is not rotated it may have some other noise that must be solved first!!!\n",
            "The image is not rotated it may have some other noise that must be solved first!!!\n",
            "0 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-91-84ef0f7e57d0>:31: RuntimeWarning: divide by zero encountered in log\n",
            "  magnitude_spectrum = 20*np.log(np.abs(f_transform_shifted))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum value of the whole image (8270096+0j)\n",
            "Maximum value of horizontal component: 945265.197488779\n",
            "##########################\n",
            "44\n",
            "not flipped\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79922609ec80>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reshape** hy5osh 3ala decode"
      ],
      "metadata": {
        "id": "DiJDka4pVBOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#later note:mmken nb2a nashel el condition el zayda wala ba an el sora ela 7ad ma htro7 mazbota shwia\n",
        "\n",
        "def getimageafterreshape(img):\n",
        "    #dah 3ak ATSRFYYYY\n",
        "    if(img[0][0]==255):\n",
        "        imgremove,_,_ = remove_quietnoise(img)\n",
        "\n",
        "    else:\n",
        "        inverted_img = cv2.bitwise_not(img)            #noha 3ayza el invert hena\n",
        "        imgremove,_,_ = remove_quietnoise(inverted_img)\n",
        "\n",
        "    size = 0\n",
        "\n",
        "    #h8yr hena leh 3ashan el taree2 dih mesh htnf3 3ala kol el sewar zay el rotated fa ana h7sb el 3aded el pixel bel change w inshallah 5er\n",
        "    if(imgremove[0][0]==255):\n",
        "        for pixel in imgremove[-1, ::-1]:\n",
        "         if (pixel != 0): break\n",
        "         size += 1\n",
        "\n",
        "    else:\n",
        "        for pixel in imgremove[0]:\n",
        "         if (pixel != 0): break\n",
        "         size += 1\n",
        "    grid_cell_size = round(size/7)\n",
        "    print(grid_cell_size)\n",
        "    grid_cells_num = round(imgremove.shape[0]/grid_cell_size)\n",
        "    print(grid_cells_num)\n",
        "    #NOHAAA\n",
        "    if imgremove.shape[0] % grid_cell_size != 0 or imgremove.shape[1] % grid_cell_size != 0:\n",
        "        print(\"Warning: Grid cell size resulted in fraction. Adjusting...\")\n",
        "        img_resized = cv2.resize(imgremove, (924, 924))\n",
        "\n",
        "# If the resized image is larger than the target size, crop it\n",
        "\n",
        "        if img_resized.shape[0] > 924 or img_resized.shape[1] > 924:\n",
        "            imgremove = img_resized[:924, :924]\n",
        "        else:\n",
        "            imgremove = img_resized\n",
        "\n",
        "\n",
        "            #cv2_imshow(imgremove)\n",
        "\n",
        "    try:\n",
        "\n",
        "        qr_cells = imgremove.reshape((\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "        )).swapaxes(1, 2)\n",
        "        plt.imshow(imgremove,cmap='gray')\n",
        "        _, axes = plt.subplots(grid_cells_num, grid_cells_num, figsize=(5, 5))\n",
        "        for i, row in enumerate(axes):\n",
        "          for j, col in enumerate(row):\n",
        "              col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
        "              col.get_xaxis().set_visible(False)\n",
        "              col.get_yaxis().set_visible(False)\n",
        "              col.spines[:].set_color('red')\n",
        "\n",
        "\n",
        "        return qr_cells,grid_cells_num,grid_cell_size,imgremove\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"Error: Unable to reshape image into grid cells.\")\n",
        "        return \"none\",grid_cells_num,grid_cell_size,imgremove\n",
        "\n",
        "\n",
        "\n",
        "#plt.imshow(imgremove,cmap='gray')\n",
        "\n",
        "#salama\n",
        "# print(size)\n",
        "# grid_cell_size = round(size/7)\n",
        "# print(grid_cell_size)\n",
        "# grid_cells_num = round(imgremove.shape[0]/grid_cell_size)\n",
        "# print(grid_cells_num)\n",
        "# qr_cells = imgremove.reshape((\n",
        "#     grid_cells_num,\n",
        "#     grid_cell_size,\n",
        "#     grid_cells_num,\n",
        "#     grid_cell_size,\n",
        "# )).swapaxes(1, 2)\n",
        "# plt.imshow(imgremove,cmap='gray')\n",
        "# _, axes = plt.subplots(grid_cells_num, grid_cells_num, figsize=(5, 5))\n",
        "# for i, row in enumerate(axes):\n",
        "#     for j, col in enumerate(row):\n",
        "#         col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
        "#         col.get_xaxis().set_visible(False)\n",
        "#         col.get_yaxis().set_visible(False)\n",
        "#         col.spines[:].set_color('red')\n"
      ],
      "metadata": {
        "id": "ky3ogaTVSrtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decode"
      ],
      "metadata": {
        "id": "lAK7kIcDSHTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def change_binary(qr_cell,grid_cell_num):\n",
        "    qr_cells_numeric = np.ndarray((grid_cells_num, grid_cells_num), dtype=np.uint8)\n",
        "    for i, row in enumerate(qr_cells):\n",
        "        for j, cell in enumerate(row):\n",
        "            qr_cells_numeric[i, j] = (np.median(cell) // 255)\n",
        "    return qr_cells_numeric"
      ],
      "metadata": {
        "id": "ORTXvspcSGnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getecl(qr_cells_numeric):\n",
        "    qr_cells_numeric[8]\n",
        "    # The first two bits determine the error correction level\n",
        "    # Level L (Low)         [11]\t7%  of data bytes can be restored.\n",
        "    # Level M (Medium)      [10]\t15% of data bytes can be restored.\n",
        "    # Level Q (Quartile)    [01]\t25% of data bytes can be restored.\n",
        "    # Level H (High)        [00]\t30% of data bytes can be restored.\n",
        "    ecl = [int(not(c)) for c in qr_cells_numeric[8, 0:2]]\n",
        "    # Why \"not\"? Because the standard uses '1's for black and '0's for white\n",
        "    #\n",
        "    # \"A dark module is a binary one and a light module is a binary zero.\"\n",
        "    #  - ISO/IEC 18004:2000(E)\n",
        "    #\n",
        "    # In image processing, we use them the other way.. Hence the inversion\n",
        "    return ecl\n",
        "\n",
        "def get_mask(qr_cells_numeric):\n",
        "    # Dictionary of all masks and their equivalent formulae\n",
        "    # Same row as above, the three cells after the ecl cells (converted to a string)\n",
        "    mask = [int(not(c)) for c in qr_cells_numeric[8, 2:5]]\n",
        "    mask_str = ''.join([str(c) for c in mask])\n",
        "    return mask,mask_str\n",
        "\n",
        "def get_fec(qr_cells_numeric):\n",
        "    fec = []\n",
        "    fec.append(qr_cells_numeric[8, 5])\n",
        "    fec.append(qr_cells_numeric[8, 7])\n",
        "    fec.extend(qr_cells_numeric[0:6, 8])\n",
        "    fec.extend(qr_cells_numeric[7:9, 8])\n",
        "    fec = [int(not(c)) for c in fec]\n",
        "    return fec\n",
        "\n",
        "\n",
        "#def showneededpixel(qr_cells_numeric):\n",
        "#    _, axes = plt.subplots(grid_cells_num, grid_cells_num, figsize=(5, 5))\n",
        "#    for i, row in enumerate(axes):\n",
        "#        for j, col in enumerate(row):\n",
        "\n",
        "            # col.get_xaxis().set_visible(False)\n",
        "            # col.get_yaxis().set_visible(False)\n",
        "            # if (i == 8 and j <= 8) or (i <= 8 and j == 8):\n",
        "            #     if (i != 6) and (j != 6):\n",
        "            #         col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
        "            #         col.spines[:].set_color('red')\n",
        "            #         continue\n",
        "            # col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=-1275, vmax=510)"
      ],
      "metadata": {
        "id": "lOGyoteyR6RD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def makeinfo(ecl,mask,fec):\n",
        "    ecl[0] ^= 1\n",
        "    mask[0] ^= 1\n",
        "    mask[2] ^= 1\n",
        "    fec[5] ^= 1\n",
        "    fec[8] ^= 1\n",
        "\n",
        "# Before we proceed, let's write a function for masking to make our lives easier\n",
        "\n",
        "\n",
        "def apply_mask(qr_cells_numeric,data_start_i, data_start_j, direction,UP,DOWN,CW,CCW,UP_ENC,MASKS,mask_str):\n",
        "\n",
        "    '''\n",
        "    data_start_i/j represent the first cell's coords in its respective direction\n",
        "    direction is the masking direction, up(-enc)/down/clockwise/anti-clockwise\n",
        "    '''\n",
        "\n",
        "    result = []\n",
        "    row_offsets = []\n",
        "    col_offsets = []\n",
        "    if (direction in [UP, UP_ENC]):\n",
        "        row_offsets = [0,  0, -1, -1, -2, -2, -3, -3]\n",
        "        col_offsets = [0, -1,  0, -1,  0, -1,  0, -1]\n",
        "    if (direction == DOWN):\n",
        "        row_offsets = [0,  0,  1,  1,  2,  2,  3,  3]\n",
        "        col_offsets = [0, -1,  0, -1,  0, -1,  0, -1]\n",
        "    if (direction == CW):\n",
        "        row_offsets = [0,  0,  1,  1,  1,  1,  0,  0]\n",
        "        col_offsets = [0, -1,  0, -1, -2, -3, -2, -3]\n",
        "    if (direction == CCW):\n",
        "        row_offsets = [0,  0, -1, -1, -1, -1,  0,  0]\n",
        "        col_offsets = [0, -1,  0, -1, -2, -3, -2, -3]\n",
        "\n",
        "    for i, j in zip(row_offsets, col_offsets):\n",
        "        cell = qr_cells_numeric[data_start_i+i, data_start_j+j]\n",
        "        result.append(int(cell if MASKS[mask_str](data_start_i+i, data_start_j+j) else not cell))\n",
        "\n",
        "    return result[:4] if direction == UP_ENC else result\n",
        "# enc = apply_mask(grid_cells_num-1, grid_cells_num-1, UP_ENC)\n",
        "# len = apply_mask(grid_cells_num-3, grid_cells_num-1, UP)\n",
        "# print(len)"
      ],
      "metadata": {
        "id": "4YhDqtyjUpOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(qr_cells,grid_cells_num):\n",
        "    MASKS = {\n",
        "        \"000\": lambda i, j: (i * j) % 2 + (i * j) % 3 == 0,\n",
        "        \"001\": lambda i, j: (i / 2 + j / 3) % 2 == 0,\n",
        "        \"010\": lambda i, j: ((i * j) % 3 + i + j) % 2 == 0,\n",
        "        \"011\": lambda i, j: ((i * j) % 3 + i * j) % 2 == 0,\n",
        "        \"100\": lambda i, j: i % 2 == 0,\n",
        "        \"101\": lambda i, j: (i + j) % 2 == 0,\n",
        "        \"110\": lambda i, j: (i + j) % 3 == 0,\n",
        "        \"111\": lambda i, j: j % 3 == 0,\n",
        "    }\n",
        "    UP, UP_ENC, DOWN, CW, CCW = range(5)  # A rather old-fashioned pythonic \"Enum\"\n",
        "    qr_cells_numeric=change_binary(qr_cells,grid_cells_num)\n",
        "    ecl=getecl(qr_cells_numeric)\n",
        "    mask,mask_str=get_mask(qr_cells_numeric)\n",
        "    fec=get_fec(qr_cells_numeric)\n",
        "    #showneededpixel(qr_cells_numeric)\n",
        "    makeinfo(ecl,mask,fec)\n",
        "\n",
        "    data_starting_indices = [\n",
        "    [grid_cells_num-7, grid_cells_num-1, UP],\n",
        "    [grid_cells_num-11, grid_cells_num-1, CCW],\n",
        "    [grid_cells_num-10, grid_cells_num-3, DOWN],\n",
        "    [grid_cells_num-6, grid_cells_num-3, DOWN],\n",
        "    [grid_cells_num-2, grid_cells_num-3, CW],\n",
        "    [grid_cells_num-3, grid_cells_num-5, UP],\n",
        "    [grid_cells_num-7, grid_cells_num-5, UP],\n",
        "    [grid_cells_num-11, grid_cells_num-5, CCW],\n",
        "    [grid_cells_num-10, grid_cells_num-7, DOWN],\n",
        "    [grid_cells_num-6, grid_cells_num-7, DOWN],\n",
        "    [grid_cells_num-2, grid_cells_num-7, CW],\n",
        "    [grid_cells_num-3, grid_cells_num-9, UP],\n",
        "    [grid_cells_num-7, grid_cells_num-9, UP],\n",
        "    [grid_cells_num-11, grid_cells_num-9, UP],\n",
        "    [grid_cells_num-16, grid_cells_num-9, UP],\n",
        "    [grid_cells_num-20, grid_cells_num-9, CCW],\n",
        "    [grid_cells_num-19, grid_cells_num-11, DOWN],\n",
        "    [grid_cells_num-14, grid_cells_num-11, DOWN],\n",
        "    [grid_cells_num-10, grid_cells_num-11, DOWN],\n",
        "    [grid_cells_num-6, grid_cells_num-11, DOWN],\n",
        "    # Hmm..? I actually don't know how to proceed now lol\n",
        "    ]\n",
        "\n",
        "    ans = ''\n",
        "    for a, b, d in data_starting_indices:\n",
        "        bits = apply_mask(qr_cells_numeric,a, b, d,UP,DOWN,CW,CCW,UP_ENC,MASKS,mask_str)\n",
        "        bit_string = ''.join([str(bit) for bit in bits])\n",
        "        if bit_string[:4] == \"0000\":\n",
        "            print(f'{bit_string[:4]} = 0 (NULL TERMINATOR)')\n",
        "            break\n",
        "        ans += chr(int(bit_string, 2)) # converts to binary to int, then to ASCII\n",
        "        print(f'{bit_string} = {ans[-1]}')\n",
        "    return ans\n",
        "decode(imgafterpreproc,grid_cells_num)"
      ],
      "metadata": {
        "id": "WYNLK_zmUzYN",
        "outputId": "a74479bb-ab27-40ec-fc4b-5efee55b2ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'grid_cells_num' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-4db2f5ac296c>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{bit_string} = {ans[-1]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgafterpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid_cells_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'grid_cells_num' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST DECODE SA7???"
      ],
      "metadata": {
        "id": "mjro6b7YU484"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tCaiInTgfZ79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check oreintation\n",
        "qr_cells,grid_cells_num,grid_cell_size,removeimg= getimageafterreshape(img)\n",
        "def checkoreintation(removeimg):\n",
        "    flipped_image = cv2.flip(removeimg, 1)\n",
        "    cv2_imshow(flipped_image)\n",
        "    #qr_cells,grid_cells_num,grid_cell_size,removeimg= getimageafterreshape(flipped_image)\n",
        "    #ans=decode(qr_cells,grid_cells_num)\n",
        "    print(ans)\n",
        "    return flipped_image\n",
        "print(\"HHH\")\n",
        "img=checkoreintation(removeimg)\n",
        "print(\"kkkk\")"
      ],
      "metadata": {
        "id": "BskfcQ1CfmKP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}