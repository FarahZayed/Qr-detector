{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0pH4EtGBSPDm"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FarahZayed/Qr-detector/blob/master/team%2010.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **import** **libraries**"
      ],
      "metadata": {
        "id": "UOj6ulzFR7Ki"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GgLWkJvJR5Tu"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFilter\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import io, color, filters, feature\n",
        "from math import sqrt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YTmbo0e1y_2L",
        "outputId": "6d51e7a0-9993-41ce-8ec5-48b6aabab0ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the image"
      ],
      "metadata": {
        "id": "c3EIx7B1SRfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#insert the path of the image\n",
        "img = cv2.imread(\"/content/drive/MyDrive/testcases/CSE483 Sp24 Project Test Cases/11-weewooweewooweewoo.png\", cv2.IMREAD_GRAYSCALE)\n",
        "_, thresh = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n"
      ],
      "metadata": {
        "id": "3ShONM6vSXcX"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Function ma7tgnha"
      ],
      "metadata": {
        "id": "0pH4EtGBSPDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def angle_ABC(a, b, c):\n",
        "\n",
        "\n",
        "    ba = a - b\n",
        "    bc = c - b\n",
        "\n",
        "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "    angle = np.arccos(cosine_angle)\n",
        "    return np.degrees(angle)\n",
        "\n",
        "def find_bad_dists(hull, distance = 10):\n",
        "    mask = []\n",
        "    points, _, _ = hull.shape\n",
        "\n",
        "    for i in range(points):\n",
        "\n",
        "        ai = i\n",
        "        bi = (i+1)%points\n",
        "\n",
        "        x1 = hull[ai][0][0]\n",
        "        y1 = hull[ai][0][1]\n",
        "        x2 = hull[bi][0][0]\n",
        "        y2 = hull[bi][0][1]\n",
        "\n",
        "\n",
        "        dist = np.sqrt((x2 - x1)**2 + (y2 - y1)**2 )\n",
        "\n",
        "        if dist < distance:\n",
        "            mask.append(bi)\n",
        "    return mask\n",
        "\n",
        "\n",
        "\n",
        "def find_bad_angles(hull, acute_angle = 30, obtuse_angle = 140):\n",
        "\n",
        "    mask = []\n",
        "    points, _, _ = hull.shape\n",
        "\n",
        "    for i in range(points):\n",
        "\n",
        "        ai = i\n",
        "        bi = (i+1)%points\n",
        "        ci = (i+2)%points\n",
        "\n",
        "\n",
        "        a = hull[ai][0]\n",
        "        b = hull[bi][0]\n",
        "        c = hull[ci][0]\n",
        "        angle = angle_ABC(a, b, c)\n",
        "        if angle > obtuse_angle or angle < acute_angle:\n",
        "            mask.append(bi)\n",
        "    return mask\n",
        "\n",
        "def mark_points(hull):\n",
        "    a_list=[]\n",
        "    points, _, _ = hull.shape\n",
        "\n",
        "    for i in range(points):\n",
        "        r = int(np.random.randint(100,255,1)[0])\n",
        "        g = int(np.random.randint(100,255,1)[0])\n",
        "        b = int(np.random.randint(100,255,1)[0])\n",
        "        a_list.append(tuple([hull[i][0][0], hull[i][0][1]]))\n",
        "\n",
        "    return a_list\n",
        "\n",
        "\n",
        "\n",
        "def shahd(img,thresh):\n",
        "\n",
        "        invimg = invert_image(img)\n",
        "\n",
        "\n",
        "        ret,thresh = cv2.threshold(invimg,127,255,0)\n",
        "\n",
        "        contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        length = len(contours)\n",
        "        cont = np.concatenate([contours[i] for i in range(length)], axis=0)\n",
        "\n",
        "        cnt_len = cv2.arcLength(cont, True)\n",
        "        cont = cv2.approxPolyDP(cont, .01*cnt_len, True)\n",
        "        hull = cv2.convexHull(cont)\n",
        "\n",
        "\n",
        "        mask = find_bad_dists(hull)\n",
        "        hull = np.delete(hull, mask, axis=0)\n",
        "\n",
        "        mask = find_bad_angles(hull)\n",
        "        hull = np.delete(hull, mask, axis=0)\n",
        "\n",
        "        a_list=mark_points(hull)\n",
        "\n",
        "        uni_hull = []\n",
        "        uni_hull.append(hull)\n",
        "\n",
        "\n",
        "        shahdlist =  mark_points(hull)\n",
        "        return shahdlist\n"
      ],
      "metadata": {
        "id": "OJByWf-9B_h_"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_quietnoise(img):\n",
        "    start_row = -1\n",
        "    start_col = -1\n",
        "    end_row = -1\n",
        "    end_col = -1\n",
        "    for row_index, row in enumerate(img):\n",
        "     for pixel in row:\n",
        "        if pixel != 255:\n",
        "            start_row = row_index\n",
        "            break\n",
        "     if start_row != -1:\n",
        "        break\n",
        "    for row_index, row in enumerate(img[::-1]):\n",
        "     for pixel in row:\n",
        "        if pixel != 255:\n",
        "            end_row = img.shape[0] - row_index\n",
        "            break\n",
        "     if end_row != -1:\n",
        "        break\n",
        "    for col_index, col in enumerate(cv2.transpose(img)):\n",
        "     for pixel in col:\n",
        "        if pixel != 255:\n",
        "            start_col = col_index\n",
        "            break\n",
        "     if start_col != -1:\n",
        "        break\n",
        "    for col_index, col in enumerate(cv2.transpose(img)[::-1]):\n",
        "     for pixel in col:\n",
        "        if pixel != 255:\n",
        "            end_col = img.shape[1] - col_index\n",
        "            break\n",
        "     if end_col != -1:\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    qr_no_quiet_zone = img[start_row:end_row, start_col:end_col]\n",
        "    return qr_no_quiet_zone\n",
        "\n",
        "    fig = plt.figure(figsize=(5, 5));\n",
        "    plt.xticks([], []);\n",
        "    plt.yticks([], []);\n",
        "    fig.get_axes()[0].spines[:].set_color('red');\n",
        "    fig.get_axes()[0].spines[:].set_linewidth(40);\n",
        "    fig.get_axes()[0].spines[:].set_position((\"outward\", 20))\n",
        "    plt.title('QR code without quiet zone', y = 1.15, color='red');\n",
        "    plt.imshow(qr_no_quiet_zone, cmap='gray');\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def distance(point1, point2):\n",
        "    return sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
        "\n",
        "\n",
        "def butterworthLP(D0, imgShape, n):\n",
        "    base = np.zeros(imgShape[:2])\n",
        "    rows, cols = imgShape[:2]\n",
        "    center = (rows / 2, cols / 2)\n",
        "    for x in range(cols):\n",
        "        for y in range(rows):\n",
        "            base[y, x] = 1 / (1 + (distance((y, x), center) / D0) ** (2 * n))\n",
        "    return base\n",
        "\n",
        "def getcellsize(imgremove):\n",
        "    size=0\n",
        "    for pixel in imgremove[0]:\n",
        "      if (pixel != 0): break\n",
        "      size += 1\n",
        "    if(size ==0): return 0,0\n",
        "    grid_cell_size = round(size/7)\n",
        "    grid_cells_num = round(imgremove.shape[0]/grid_cell_size)\n",
        "    return grid_cell_size,grid_cells_num\n",
        "\n",
        "\n",
        "def get_start_row_col(img):\n",
        "    start_row = -1\n",
        "    start_col = -1\n",
        "    for row_index, row in enumerate(img):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                start_row = row_index\n",
        "                break\n",
        "        if start_row != -1:\n",
        "            break\n",
        "    for col_index, col in enumerate(cv2.transpose(img)):\n",
        "        for pixel in col:\n",
        "            if pixel != 255:\n",
        "                start_col = col_index\n",
        "                break\n",
        "        if start_col != -1:\n",
        "            break\n",
        "    return start_row, start_col\n",
        "\n",
        "\n",
        "def getcellsizeForRotation(imgremove):\n",
        "    size=0\n",
        "    for pixel in imgremove[-1, ::-1]:\n",
        "      if (pixel != 0): break\n",
        "      size += 1\n",
        "    if(size ==0): return 0,0\n",
        "    grid_cell_size = round(size/7)\n",
        "    grid_cells_num = round(imgremove.shape[0]/grid_cell_size)\n",
        "    return grid_cell_size,grid_cells_num\n",
        "\n",
        "def getqrcell(remove, grid_cell_size, grid_cells_num):\n",
        "    if remove.shape[0] % grid_cell_size != 0 or remove.shape[1] % grid_cell_size != 0:\n",
        "            print(\"Warning: Grid cell size resulted in fraction. Adjusting...\")\n",
        "            img_resized = cv2.resize(remove, (924, 924))\n",
        "\n",
        "    # If the resized image is larger than the target size, crop it\n",
        "            if remove.shape[0] > 924 or remove.shape[1] > 924:\n",
        "                remove = img_resized[:924, :924]\n",
        "            else:\n",
        "                remove = img_resized\n",
        "    try:\n",
        "            qr_cells = remove.reshape((\n",
        "            grid_cells_num,\n",
        "            grid_cell_size,\n",
        "            grid_cells_num,\n",
        "            grid_cell_size,\n",
        "            )).swapaxes(1, 2)\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"Error: Unable to reshape image into grid cells.\")\n",
        "        qr_cells=0\n",
        "    return qr_cells\n",
        "\n",
        "def correctqrcell(qr_cells):\n",
        "\n",
        " for i in range(qr_cells.shape[0]):\n",
        "   for j in range(qr_cells.shape[1]):\n",
        "    cell=qr_cells[i][j]\n",
        "    white_pixel_count = np.sum(cell == 255)\n",
        "    black_pixel_count = np.sum(cell == 0)\n",
        "    if white_pixel_count > black_pixel_count:\n",
        "        for k in range(grid_cell_size):\n",
        "            for l in range(grid_cell_size):\n",
        "                qr_cells[i][j][k][l]=255\n",
        "    elif black_pixel_count > white_pixel_count:\n",
        "        for k in range(grid_cell_size):\n",
        "            for l in range(grid_cell_size):\n",
        "                qr_cells[i][j][k][l]=0\n",
        "\n",
        "\n",
        "    elif black_pixel_count == white_pixel_count:\n",
        "        for k in range(grid_cell_size):\n",
        "            for l in range(grid_cell_size):\n",
        "                qr_cells[i][j][k][l]=0\n",
        "    return qr_cells\n"
      ],
      "metadata": {
        "id": "LkeUEJYZSmMY"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# function that raise the flags"
      ],
      "metadata": {
        "id": "LieUdBISTZO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def checkrotation(img):\n",
        "    imgremove= remove_quietnoise(img)\n",
        "    grid_cell_size,grid_cell_num= getcellsizeForRotation(imgremove)\n",
        "\n",
        "    if grid_cell_size==0:\n",
        "        print(\"The image is not rotated it may have some other noise that must be solved first!!!\")\n",
        "        return False\n",
        "    inverted_img = cv2.bitwise_not(imgremove)\n",
        "    shapeofste=3*grid_cell_size -1\n",
        "    se_rect = cv2.getStructuringElement(cv2.MORPH_RECT, (shapeofste, shapeofste))\n",
        "    _, se_binarized = cv2.threshold(se_rect, 128, 1, cv2.THRESH_BINARY)\n",
        "    se_binarized = se_binarized.astype(int)\n",
        "    se_binarized[se_binarized == 0] = -1\n",
        "    erosion = cv2.erode(inverted_img, se_rect, iterations=1)\n",
        "    partwithrotato=erosion[(imgremove.shape[0]-7*grid_cell_size):imgremove.shape[0], imgremove.shape[1]-7*grid_cell_size:imgremove.shape[1]];\n",
        "    count=0\n",
        "    for row in range(partwithrotato.shape[0]):\n",
        "        for col in range(partwithrotato.shape[1]):\n",
        "            if partwithrotato[row,col] == 255:\n",
        "                count=count+1\n",
        "    if(count>0 and count<10):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def checkblured(image):\n",
        "    f_transform = np.fft.fft2(image)\n",
        "    f_transform_shifted = np.fft.fftshift(f_transform)\n",
        "    magnitude_spectrum = 20*np.log(np.abs(f_transform_shifted))\n",
        "    rows, cols = image.shape\n",
        "    center_row = rows // 2\n",
        "    center_col = cols // 2\n",
        "    roi_size = 10\n",
        "    dc_component = magnitude_spectrum[center_row, center_col]\n",
        "    roi = magnitude_spectrum[center_row - roi_size:center_row + roi_size + 1,\n",
        "                              center_col - roi_size:center_col + roi_size + 1]\n",
        "    avg_roi = round(np.mean(roi))\n",
        "    if(np.mean(magnitude_spectrum[100:-100, 100:-100])== float('-inf')):\n",
        "        return False\n",
        "    else:\n",
        "        high_freq_avg=round(np.mean(magnitude_spectrum[100:-100, 100:-100]))\n",
        "\n",
        "    low_accepted_freqcompatcenter=290\n",
        "    highest_accepted_change=120\n",
        "    if(avg_roi>290 and high_freq_avg<120):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "#check mostly white\n",
        "def is_mostly_white(img):\n",
        "    row, col = img.shape\n",
        "    count=0\n",
        "    for i in range(row):\n",
        "        for j in range(col):\n",
        "            if (img[i][j] < 150) :\n",
        "                count=count+1\n",
        "    if count>0:\n",
        "       return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "#check shifting\n",
        "\n",
        "def detect_shift_rows(img):\n",
        "    row,col=get_start_row_col(img)\n",
        "    print(row,col)\n",
        "    count_black =0\n",
        "    count_white =0\n",
        "    flag=True\n",
        "    first_black_pixel = 0\n",
        "    last_black_pixel = 0\n",
        "    for i in range(len(img[row])-1):\n",
        "        if img[row][i] !=255:\n",
        "            first_black_pixel = i\n",
        "            count_black=count_black+1\n",
        "        if count_black==1:\n",
        "            break\n",
        "    for j in range(first_black_pixel,len(img[row])-1):\n",
        "        if img[row][j]!=0:\n",
        "            last_black_pixel=j-1\n",
        "            count_white+=1\n",
        "        if count_white==1:\n",
        "            break\n",
        "    for k in range(first_black_pixel,last_black_pixel):\n",
        "       if img[row][k]!=0:\n",
        "          flag=False\n",
        "\n",
        "\n",
        "    if row>0 and col>0 and col!=0 and row!=0 and col!=row and flag==True:\n",
        "        if (row-col)<12:\n",
        "            return True\n",
        "        else:\n",
        "          return False\n",
        "    else:\n",
        "          return False\n",
        "\n",
        "\n",
        "#checks skewness\n",
        "def checkskew(img):\n",
        "    skewflag=False\n",
        "    unwarpedflag=False\n",
        "    img = np.uint8(img)\n",
        "    edges = cv2.Canny(img, 100, 200)\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if(contours ==() ):\n",
        "        return skewflag,unwarpedflag\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "    qr_code_region = img[y:y + h, x:x + w]\n",
        "    edges = cv2.Canny(qr_code_region, 50, 150, apertureSize=3)\n",
        "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)\n",
        "    if lines is None:\n",
        "        return skewflag,unwarpedflag\n",
        "    vertical_angles = []\n",
        "    horizontal_angles = []\n",
        "\n",
        "    for line in lines:\n",
        "        rho, theta = line[0]\n",
        "        if np.pi / 4 < theta < 3 * np.pi / 4:\n",
        "            vertical_angles.append(theta)\n",
        "        else:\n",
        "            horizontal_angles.append(theta)\n",
        "    vertical_skewness = np.mean(vertical_angles) if vertical_angles else 0\n",
        "    horizontal_skewness = np.mean(horizontal_angles) if horizontal_angles else 0\n",
        "\n",
        "    vertical_skewness_deg = round(np.rad2deg(vertical_skewness))\n",
        "    horizontal_skewness_deg = round(np.rad2deg(horizontal_skewness))\n",
        "    difference=round(abs(horizontal_skewness_deg - vertical_skewness_deg))\n",
        "    if(difference==90 and vertical_skewness_deg!=90 and horizontal_skewness_deg!=90):\n",
        "        skewflag=True\n",
        "        return skewflag,unwarpedflag\n",
        "    elif(horizontal_skewness_deg < 90 and horizontal_skewness_deg>10 and vertical_skewness_deg<90):\n",
        "        unwarpedflag=True\n",
        "        return skewflag,unwarpedflag\n",
        "    else:\n",
        "        return skewflag,unwarpedflag\n",
        "\n",
        "\n",
        "#check black image\n",
        "def is_mostly_black(image):\n",
        "    image = np.uint8(image)\n",
        "    hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
        "    hist /= hist.sum()\n",
        "\n",
        "    cumulative_sum = hist.cumsum()\n",
        "\n",
        "    return cumulative_sum.argmax() < 30\n",
        "\n",
        "def checkflip(img):\n",
        "    flipped_image = cv2.flip(img, 1) # original  flipp\n",
        "    imgremove = remove_quietnoise(flipped_image)\n",
        "    grid_cell_size,grid_cells_num=getcellsize(imgremove)\n",
        "    if grid_cell_size==0: return False\n",
        "    print(\"##########################\")\n",
        "    print(grid_cell_size)\n",
        "    qr_cells=getqrcell(imgremove,grid_cell_size,grid_cells_num)\n",
        "    if isinstance(qr_cells, (int)):\n",
        "        print(\"cant do qrcell\")\n",
        "        return False\n",
        "    qr_cells_numeric = np.ndarray((grid_cells_num, grid_cells_num), dtype=np.uint8)\n",
        "    for i, row in enumerate(qr_cells):\n",
        "      for j, cell in enumerate(row):\n",
        "          qr_cells_numeric[i, j] = (np.median(cell) // 255)\n",
        "\n",
        "    fec = []\n",
        "    fec.append(qr_cells_numeric[8, 0:6])\n",
        "    fec.extend(qr_cells_numeric[8, 7:8])\n",
        "\n",
        "    fec.extend(qr_cells_numeric[0:6, 8])\n",
        "    fec.extend(qr_cells_numeric[7:9, 8])\n",
        "    fec = [int(c) for sublist in fec for c in (sublist.ravel() if isinstance(sublist, np.ndarray) else [sublist])]\n",
        "\n",
        "    fec2 = []\n",
        "    fec2.append(qr_cells_numeric[-1:-8:-1, 8])\n",
        "    fec2.extend(qr_cells_numeric[8, -1:-9:-1])\n",
        "    fec2 = [int(c) for sublist in fec2 for c in (sublist.ravel() if isinstance(sublist, np.ndarray) else [sublist])]\n",
        "\n",
        "    if (np.array_equal(fec2, fec)):\n",
        "      print(\"photo was flipped\")\n",
        "      return True\n",
        "    else:\n",
        "      print(\"not flipped\")\n",
        "      return False\n",
        "\n",
        "def inversioncheck(img):\n",
        "    mean_intensity = cv2.mean(img)[0]\n",
        "    return (mean_intensity < 100 and mean_intensity>30)\n",
        "\n",
        "\n",
        "def detect_periodic_noise(image,threshold_factor=1 / 4):\n",
        "    resized_image = cv2.resize(image, (256, 256))\n",
        "    fft_image = np.fft.fft2(resized_image)\n",
        "    max_intensity = np.max(fft_image)\n",
        "\n",
        "    high_frequency_component = np.abs(np.fft.fftshift(fft_image)[:, :fft_image.shape[1] // 2])\n",
        "    max_high_frequency_component = np.max(high_frequency_component)\n",
        "    noise_threshold = max_intensity * threshold_factor\n",
        "    if max_high_frequency_component > noise_threshold:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def detect_patterns_in_roi(image, threshold_factor=1.2):\n",
        "    resized_image = cv2.resize(image, (256, 256))\n",
        "    dft_noise = np.fft.fft2(resized_image)\n",
        "    dft_noise_shift = np.fft.fftshift(dft_noise)\n",
        "    epsilon = 1e-10\n",
        "    magnitude_spectrum = 20 * np.log(np.abs(dft_noise_shift)+ epsilon)\n",
        "\n",
        "    rows, cols = dft_noise_shift.shape\n",
        "    center_row, center_col = rows // 2, cols // 2\n",
        "\n",
        "    roi_size = 250\n",
        "    roi = magnitude_spectrum[center_row - roi_size:center_row + roi_size,\n",
        "                          center_col - roi_size:center_col + roi_size]\n",
        "\n",
        "    roi_mean = np.mean(roi)\n",
        "\n",
        "    threshold = threshold_factor * roi_mean\n",
        "\n",
        "    significant_peaks_exist = np.any(roi > threshold)\n",
        "    if significant_peaks_exist:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n"
      ],
      "metadata": {
        "id": "RKjHTS4TTYM1"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# flags to do preprocessing"
      ],
      "metadata": {
        "id": "PzSFn2IAS6EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotationflag= checkrotation(img)\n",
        "\n",
        "SaltandPepper = detect_patterns_in_roi(img)\n",
        "\n",
        "bluredflag =checkblured(img)\n",
        "\n",
        "shiftedrowsflag= detect_shift_rows(img)\n",
        "\n",
        "mostlywhiteflag= is_mostly_white(img)\n",
        "\n",
        "periodicflag = detect_periodic_noise(img)\n",
        "\n",
        "skewedflag,unwarpedflag = checkskew(img)\n",
        "\n",
        "mostlyblackflag=is_mostly_black(img)\n",
        "\n",
        "inversionflag=inversioncheck(img)\n",
        "\n",
        "flipflag =checkflip(img)\n",
        "\n",
        "print(\"The flag of inverted image : \",inversionflag )\n",
        "print(\"The flag of rotation: \",rotationflag )\n",
        "print(\"The flag of all white image: \",mostlywhiteflag )\n",
        "print(\"The flag of blured image: \",bluredflag )\n",
        "print(\"The flag of shifted rows: \",shiftedrowsflag )\n",
        "print(\"The flag of periodic noise: \",periodicflag )\n",
        "print(\"The flag of skewed images : \",skewedflag )\n",
        "print(\"The flag of all black image : \",mostlyblackflag )\n",
        "print(\"The flag of unwarped image : \",unwarpedflag )\n",
        "print(\"The flag of flipped image : \",flipflag )\n",
        "print(\"The flag of saltandpepper image : \",SaltandPepper )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YFBLVZSoTGFT",
        "outputId": "c42c2a7d-e13a-4c39-a43b-69e72c05aaea"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image is not rotated it may have some other noise that must be solved first!!!\n",
            "0 0\n",
            "The flag of inverted image :  False\n",
            "The flag of rotation:  False\n",
            "The flag of all white image:  False\n",
            "The flag of blured image:  False\n",
            "The flag of shifted rows:  False\n",
            "The flag of periodic noise:  True\n",
            "The flag of skewed images :  False\n",
            "The flag of all black image :  False\n",
            "The flag of unwarped image :  False\n",
            "The flag of flipped image :  False\n",
            "The flag of saltandpepper image :  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function responsible for preprocessing"
      ],
      "metadata": {
        "id": "3imjv2MEUQYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def invert_image(image):\n",
        "\n",
        "    _,img = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY)\n",
        "    inverted_image=cv2.bitwise_not(img)\n",
        "    return inverted_image\n",
        "\n",
        "def a3dlrotation(img):\n",
        "    print(\"in\")\n",
        "    imgremove= remove_quietnoise(img)\n",
        "    while(checkrotation(imgremove)):\n",
        "        imgremove = cv2.rotate(imgremove, cv2.ROTATE_90_CLOCKWISE)\n",
        "    return imgremove\n",
        "\n",
        "def flip(img):\n",
        "\n",
        "    img=cv2.flip(img,1)\n",
        "    return img\n",
        "\n",
        "def nadafblured(img):\n",
        "         # nazbt el soraa\n",
        "        blurred = cv2.GaussianBlur(img, (7, 7), 0)\n",
        "        sharpened = cv2.addWeighted(img, 2.5, blurred, -0.5, 0)\n",
        "        _, thresh_img = cv2.threshold(sharpened, 127, 255, cv2.THRESH_BINARY)\n",
        "        #shalena el noise w shwait araf erode keda\n",
        "        remove= remove_quietnoise(thresh_img)\n",
        "        se_rect = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
        "        _, se_binarized = cv2.threshold(se_rect, 128, 1, cv2.THRESH_BINARY)\n",
        "        se_binarized = se_binarized.astype(int)\n",
        "        se_binarized[se_binarized == 0] = -1\n",
        "        erosion = cv2.erode(remove, se_binarized, iterations=1)\n",
        "        needcorrectionimg=erosion\n",
        "        return needcorrectionimg\n",
        "\n",
        "def unwarped(img,thresh):\n",
        "        listt  = shahd(img,thresh)\n",
        "        rows1 , cols1  = img.shape\n",
        "        pts2 = np.array([[cols1,0],[cols1,rows1],[0,rows1], [0,0]],np.float32)\n",
        "        pts1 = np.array(listt,np.float32)\n",
        "        M = cv2.getPerspectiveTransform(pts1,pts2)\n",
        "        dst = cv2.warpPerspective(img,M,(cols1,rows1))\n",
        "        return dst\n",
        "\n",
        "\n",
        "def edit_white_img(img):\n",
        "    first_pixel=img[0,0]\n",
        "    for i in range(img.shape[0]):\n",
        "        for j in range(img.shape[1]):\n",
        "            if img[i][j] == first_pixel:\n",
        "                img[i][j] = 225\n",
        "            else:\n",
        "                img[i][j] = 0\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "def solve_shifted_rows(img):\n",
        "    start_row = -1\n",
        "    start_col = -1\n",
        "    end_row = -1\n",
        "    end_col = -1\n",
        "    _, img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
        "    for row_index, row in enumerate(img):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                start_row = row_index\n",
        "                start_col =row_index\n",
        "                break\n",
        "        if start_row != -1:\n",
        "            break\n",
        "\n",
        "    for row_index, row in enumerate(img[::-1]):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                end_row = img.shape[0] - row_index\n",
        "                end_col =img.shape[0] - row_index\n",
        "                break\n",
        "        if end_row != -1:\n",
        "            break\n",
        "\n",
        "\n",
        "    qr_no_quiet_zone = img[start_row:end_row, start_col:end_col]\n",
        "\n",
        "    size = 0\n",
        "    for pixel in qr_no_quiet_zone[0]:\n",
        "        if (pixel != 0): break\n",
        "        size += 1\n",
        "\n",
        "    grid_cell_size = round(size/7)\n",
        "    grid_cells_num = round(qr_no_quiet_zone.shape[0]/grid_cell_size)\n",
        "\n",
        "    img_resized = cv2.resize(qr_no_quiet_zone, (grid_cells_num*grid_cell_size, grid_cells_num*grid_cell_size))\n",
        "\n",
        "    qr_cells = img_resized.reshape((\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "    )).swapaxes(1, 2)\n",
        "\n",
        "    for i in range(qr_cells.shape[0]):\n",
        "        for j in range(qr_cells.shape[1]):\n",
        "            cell=qr_cells[i][j]\n",
        "            white_pixel_count = np.sum(cell == 255)\n",
        "            black_pixel_count = np.sum(cell == 0)\n",
        "            if white_pixel_count > black_pixel_count:\n",
        "                for k in range(grid_cell_size):\n",
        "                    for l in range(grid_cell_size):\n",
        "                        qr_cells[i][j][k][l]=255\n",
        "            elif black_pixel_count > white_pixel_count:\n",
        "                for k in range(grid_cell_size):\n",
        "                    for l in range(grid_cell_size):\n",
        "                        qr_cells[i][j][k][l]=0\n",
        "\n",
        "\n",
        "            elif black_pixel_count == white_pixel_count:\n",
        "                for k in range(grid_cell_size):\n",
        "                    for l in range(grid_cell_size):\n",
        "                        qr_cells[i][j][k][l]=0\n",
        "    return img_resized\n",
        "\n",
        "\n",
        "def dalma(image):\n",
        "        image1 = image\n",
        "        thresh,binary_image = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "        image = cv2.inpaint(image1, binary_image, inpaintRadius=3,flags=cv2.INPAINT_TELEA)\n",
        "\n",
        "\n",
        "\n",
        "        mask = cv2.threshold(image, 10, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "        lightened_image = np.where(mask == 255, np.clip(image * 100, 0, 255).astype(np.uint8), image)\n",
        "\n",
        "        _, mask = cv2.threshold(lightened_image, 75, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        mask = cv2.bitwise_not(mask)\n",
        "\n",
        "        _, bimage = cv2.threshold(lightened_image, 0, 255, cv2.THRESH_BINARY)\n",
        "        return bimage\n",
        "\n",
        "def orientSkewness(img):\n",
        "        _, img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
        "        edges = cv2.Canny(img, 100, 200)\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "        qr_code_region = img[y:y + h, x:x + w]\n",
        "        # Apply edge detection\n",
        "        edges = cv2.Canny(qr_code_region, 50, 150, apertureSize=3)\n",
        "        lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)\n",
        "        vertical_angles = []\n",
        "        horizontal_angles = []\n",
        "\n",
        "        for line in lines:\n",
        "            rho, theta = line[0]\n",
        "            if np.pi / 4 < theta < 3 * np.pi / 4:\n",
        "                vertical_angles.append(theta)\n",
        "            else:\n",
        "                horizontal_angles.append(theta)\n",
        "\n",
        "        vertical_skewness = np.mean(vertical_angles) if vertical_angles else 0\n",
        "        horizontal_skewness = np.mean(horizontal_angles) if horizontal_angles else 0\n",
        "\n",
        "        vertical_skewness_deg = np.rad2deg(vertical_skewness)\n",
        "        horizontal_skewness_deg = np.rad2deg(horizontal_skewness)\n",
        "\n",
        "        rotation_angle_deg = 180+horizontal_skewness_deg\n",
        "        rows, cols = img.shape[:2]\n",
        "        rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotation_angle_deg, 1)\n",
        "        img = cv2.warpAffine(img, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR,\n",
        "                                    borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255) )\n",
        "\n",
        "        qr_code_region = cv2.warpAffine(qr_code_region, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR,\n",
        "                            borderMode=cv2.BORDER_CONSTANT)\n",
        "\n",
        "        contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        rect = cv2.minAreaRect(largest_contour)\n",
        "        angle = rect[-1]\n",
        "        if angle < -45:\n",
        "            angle += 90\n",
        "\n",
        "        rows, cols = img.shape[:2]\n",
        "        rotation_matrix = cv2.getRotationMatrix2D(rect[0], angle, 1)\n",
        "        rotated_image = cv2.warpAffine(img, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR,\n",
        "                                    borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "        border_width = 20  # Adjust the border width as needed\n",
        "        border_color = (255, 255, 255)  # White color\n",
        "        img = cv2.copyMakeBorder(img, border_width, border_width, border_width, border_width,\n",
        "                                            cv2.BORDER_CONSTANT, value=border_color)\n",
        "        if(checkrotation(img)):\n",
        "            img=a3dlrotation(img)\n",
        "            return img\n",
        "        else: return img\n",
        "\n",
        "\n",
        "def decompresso_espreso(img):\n",
        "    # convert to binary image\n",
        "    _, imgBinary = cv2.threshold(img, 170, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # apply Gaussian blur to smooth the image\n",
        "    blurred = cv2.GaussianBlur(imgBinary, (5, 5), 0)\n",
        "\n",
        "    # opening--> erosion then dilation 3ashan asheel el abyad and did finetuning till weselt le number of iterations da\n",
        "    # a 5x5 kernel of ones (3x3 msh hatenfa3)\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    eroded = cv2.erode(blurred, kernel, iterations = 6)\n",
        "    dilated = cv2.dilate(eroded, kernel, iterations = 7)\n",
        "    return dilated\n",
        "\n",
        "\n",
        "def periodicnoiseSolver(img):\n",
        "    fourier_transform = np.fft.fft2(img)\n",
        "    center_shift = np.fft.fftshift(fourier_transform)\n",
        "    epsilon = 1e-10\n",
        "    fourier_noisy = 20 * np.log(np.abs(center_shift)+epsilon)\n",
        "\n",
        "    rows, cols = img.shape\n",
        "    crow, ccol = rows // 2, cols // 2\n",
        "\n",
        "\n",
        "    center_shift[crow :crow + 1, 0:ccol - 10] = 1\n",
        "    center_shift[crow :crow + 1, ccol + 10:] = 1\n",
        "\n",
        "\n",
        "    filtered = center_shift * butterworthLP(80, img.shape, 10)\n",
        "\n",
        "    f_shift = np.fft.ifftshift(center_shift)\n",
        "    denoised_image = np.fft.ifft2(f_shift)\n",
        "    denoised_image = np.real(denoised_image)\n",
        "\n",
        "    f_ishift_blpf = np.fft.ifftshift(filtered)\n",
        "    denoised_image_blpf = np.fft.ifft2(f_ishift_blpf)\n",
        "    denoised_image_blpf = np.real(denoised_image_blpf)\n",
        "\n",
        "    fourier_noisy_noise_removed = 20 * np.log(np.abs(center_shift)+epsilon)\n",
        "    _, denoised_image_blpf_bin = cv2.threshold(denoised_image_blpf, 128, 255, cv2.THRESH_BINARY)\n",
        "    return denoised_image_blpf_bin\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def denoiseSaltPepper(image):\n",
        "      blurred_image = cv2.GaussianBlur(image, (1, 1), 0)\n",
        "      equalized_image = cv2.equalizeHist(blurred_image)\n",
        "\n",
        "      f_transform = np.fft.fft2(image)\n",
        "      f_transform_shifted = np.fft.fftshift(f_transform)\n",
        "\n",
        "      rect_width = 150\n",
        "      rect_height = 20\n",
        "      rows, cols = image.shape\n",
        "      mask_rect = np.zeros((rows, cols), dtype=np.uint8)\n",
        "      center_row, center_col = rows // 2, cols // 2\n",
        "      start_row = center_row - rect_height // 2\n",
        "      start_col = center_col - rect_width // 2\n",
        "      end_row = start_row + rect_height\n",
        "      end_col = start_col + rect_width\n",
        "      mask_rect[start_row:end_row, start_col:end_col] = 1\n",
        "\n",
        "      rect_width2 = 20\n",
        "      rect_height2 = 150\n",
        "      rows, cols = image.shape\n",
        "      mask_rect2 = np.zeros((rows, cols), dtype=np.uint8)\n",
        "      center_row, center_col = rows // 2, cols // 2\n",
        "      start_row = center_row - rect_height2 // 2\n",
        "      start_col = center_col - rect_width2 // 2\n",
        "      end_row = start_row + rect_height2\n",
        "      end_col = start_col + rect_width2\n",
        "      mask_rect2[start_row:end_row, start_col:end_col] = 1\n",
        "\n",
        "      rows, cols = image.shape\n",
        "      center_row, center_col = rows // 2, cols // 2\n",
        "      radius_inner_circle = 0\n",
        "      radius_outer_circle = 30\n",
        "      mask_circle = np.zeros((rows, cols), dtype=np.uint8)\n",
        "      for i in range(rows):\n",
        "          for j in range(cols):\n",
        "              distance = np.sqrt((i - center_row) ** 2 + (j - center_col) ** 2)\n",
        "              if distance <= radius_outer_circle and distance >= radius_inner_circle:\n",
        "                  mask_circle[i, j] = 1\n",
        "\n",
        "      mask=mask_rect|mask_rect2|mask_circle\n",
        "\n",
        "\n",
        "      f_transform_filtered = f_transform_shifted *mask\n",
        "\n",
        "      filtered_image = np.fft.ifftshift(f_transform_filtered)\n",
        "      filtered_image = np.fft.ifft2(filtered_image)\n",
        "      filtered_image = np.abs(filtered_image)\n",
        "\n",
        "\n",
        "      filtered_image = np.fft.ifftshift(f_transform_filtered)\n",
        "      filtered_image = np.fft.ifft2(filtered_image)\n",
        "      filtered_image = np.abs(filtered_image)\n",
        "      _, filtered_image = cv2.threshold(filtered_image, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "\n",
        "      filtered_image = filtered_image.astype(np.uint8)\n",
        "      closing_kernel = np.ones((11,11), np.uint8)\n",
        "      closed_image= cv2.morphologyEx(filtered_image, cv2.MORPH_CLOSE, closing_kernel)\n",
        "\n",
        "      # erosion\n",
        "      closed_image = np.array(closed_image)\n",
        "      closed_image = closed_image.astype(np.uint8)\n",
        "      kernel = np.ones((9,9), np.uint8)  # You can adjust the size of the kernel as needed\n",
        "      eroded_image = cv2.erode(closed_image, kernel, iterations=1)\n",
        "\n",
        "      # ASEEEB EL PLOTS WALA LA YA GAM3A???? EL MO3EED 3AYZ YESHOFHA SA7?\n",
        "\n",
        "      return eroded_image\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C2-13QUoUTMv"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "8L3NxC3xUH_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reshape** hy5osh 3ala decode"
      ],
      "metadata": {
        "id": "DiJDka4pVBOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def getimageafterreshape(img):\n",
        "    #dah 3ak ATSRFYYYY\n",
        "    if(img[0][0]==255):\n",
        "        imgremove,_,_ = remove_quietnoise(img)\n",
        "\n",
        "    else:\n",
        "        inverted_img = cv2.bitwise_not(img)            #noha 3ayza el invert hena\n",
        "        imgremove,_,_ = remove_quietnoise(inverted_img)\n",
        "\n",
        "    size = 0\n",
        "\n",
        "    #h8yr hena leh 3ashan el taree2 dih mesh htnf3 3ala kol el sewar zay el rotated fa ana h7sb el 3aded el pixel bel change w inshallah 5er\n",
        "    if(imgremove[0][0]==255):\n",
        "        for pixel in imgremove[-1, ::-1]:\n",
        "         if (pixel != 0): break\n",
        "         size += 1\n",
        "\n",
        "    else:\n",
        "        for pixel in imgremove[0]:\n",
        "         if (pixel != 0): break\n",
        "         size += 1\n",
        "    grid_cell_size = round(size/7)\n",
        "    print(grid_cell_size)\n",
        "    grid_cells_num = round(imgremove.shape[0]/grid_cell_size)\n",
        "    print(grid_cells_num)\n",
        "    #NOHAAA\n",
        "    if imgremove.shape[0] % grid_cell_size != 0 or imgremove.shape[1] % grid_cell_size != 0:\n",
        "        print(\"Warning: Grid cell size resulted in fraction. Adjusting...\")\n",
        "        img_resized = cv2.resize(imgremove, (924, 924))\n",
        "\n",
        "# If the resized image is larger than the target size, crop it\n",
        "\n",
        "        if img_resized.shape[0] > 924 or img_resized.shape[1] > 924:\n",
        "            imgremove = img_resized[:924, :924]\n",
        "        else:\n",
        "            imgremove = img_resized\n",
        "\n",
        "\n",
        "\n",
        "    try:\n",
        "\n",
        "        qr_cells = imgremove.reshape((\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "        )).swapaxes(1, 2)\n",
        "        plt.imshow(imgremove,cmap='gray')\n",
        "        _, axes = plt.subplots(grid_cells_num, grid_cells_num, figsize=(5, 5))\n",
        "        for i, row in enumerate(axes):\n",
        "          for j, col in enumerate(row):\n",
        "              col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
        "              col.get_xaxis().set_visible(False)\n",
        "              col.get_yaxis().set_visible(False)\n",
        "              col.spines[:].set_color('red')\n",
        "\n",
        "\n",
        "        return qr_cells,grid_cells_num,grid_cell_size,imgremove\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"Error: Unable to reshape image into grid cells.\")\n",
        "        return \"none\",grid_cells_num,grid_cell_size,imgremove\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ky3ogaTVSrtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decode"
      ],
      "metadata": {
        "id": "lAK7kIcDSHTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def change_binary(qr_cell,grid_cell_num):\n",
        "    qr_cells_numeric = np.ndarray((grid_cells_num, grid_cells_num), dtype=np.uint8)\n",
        "    for i, row in enumerate(qr_cells):\n",
        "        for j, cell in enumerate(row):\n",
        "            qr_cells_numeric[i, j] = (np.median(cell) // 255)\n",
        "    return qr_cells_numeric"
      ],
      "metadata": {
        "id": "ORTXvspcSGnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getecl(qr_cells_numeric):\n",
        "    qr_cells_numeric[8]\n",
        "\n",
        "    ecl = [int(not(c)) for c in qr_cells_numeric[8, 0:2]]\n",
        "    # Why \"not\"? Because the standard uses '1's for black and '0's for white\n",
        "    #\n",
        "    # \"A dark module is a binary one and a light module is a binary zero.\"\n",
        "    #  - ISO/IEC 18004:2000(E)\n",
        "    #\n",
        "    # In image processing, we use them the other way.. Hence the inversion\n",
        "    return ecl\n",
        "\n",
        "def get_mask(qr_cells_numeric):\n",
        "    # Dictionary of all masks and their equivalent formulae\n",
        "    # Same row as above, the three cells after the ecl cells (converted to a string)\n",
        "    mask = [int(not(c)) for c in qr_cells_numeric[8, 2:5]]\n",
        "    mask_str = ''.join([str(c) for c in mask])\n",
        "    return mask,mask_str\n",
        "\n",
        "def get_fec(qr_cells_numeric):\n",
        "    fec = []\n",
        "    fec.append(qr_cells_numeric[8, 5])\n",
        "    fec.append(qr_cells_numeric[8, 7])\n",
        "    fec.extend(qr_cells_numeric[0:6, 8])\n",
        "    fec.extend(qr_cells_numeric[7:9, 8])\n",
        "    fec = [int(not(c)) for c in fec]\n",
        "    return fec\n",
        "\n",
        "\n",
        "#def showneededpixel(qr_cells_numeric):\n",
        "#    _, axes = plt.subplots(grid_cells_num, grid_cells_num, figsize=(5, 5))\n",
        "#    for i, row in enumerate(axes):\n",
        "#        for j, col in enumerate(row):\n",
        "\n",
        "            # col.get_xaxis().set_visible(False)\n",
        "            # col.get_yaxis().set_visible(False)\n",
        "            # if (i == 8 and j <= 8) or (i <= 8 and j == 8):\n",
        "            #     if (i != 6) and (j != 6):\n",
        "            #         col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
        "            #         col.spines[:].set_color('red')\n",
        "            #         continue\n",
        "            # col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=-1275, vmax=510)"
      ],
      "metadata": {
        "id": "lOGyoteyR6RD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def makeinfo(ecl,mask,fec):\n",
        "    ecl[0] ^= 1\n",
        "    mask[0] ^= 1\n",
        "    mask[2] ^= 1\n",
        "    fec[5] ^= 1\n",
        "    fec[8] ^= 1\n",
        "\n",
        "# Before we proceed, let's write a function for masking to make our lives easier\n",
        "\n",
        "\n",
        "def apply_mask(qr_cells_numeric,data_start_i, data_start_j, direction,UP,DOWN,CW,CCW,UP_ENC,MASKS,mask_str):\n",
        "\n",
        "    '''\n",
        "    data_start_i/j represent the first cell's coords in its respective direction\n",
        "    direction is the masking direction, up(-enc)/down/clockwise/anti-clockwise\n",
        "    '''\n",
        "\n",
        "    result = []\n",
        "    row_offsets = []\n",
        "    col_offsets = []\n",
        "    if (direction in [UP, UP_ENC]):\n",
        "        row_offsets = [0,  0, -1, -1, -2, -2, -3, -3]\n",
        "        col_offsets = [0, -1,  0, -1,  0, -1,  0, -1]\n",
        "    if (direction == DOWN):\n",
        "        row_offsets = [0,  0,  1,  1,  2,  2,  3,  3]\n",
        "        col_offsets = [0, -1,  0, -1,  0, -1,  0, -1]\n",
        "    if (direction == CW):\n",
        "        row_offsets = [0,  0,  1,  1,  1,  1,  0,  0]\n",
        "        col_offsets = [0, -1,  0, -1, -2, -3, -2, -3]\n",
        "    if (direction == CCW):\n",
        "        row_offsets = [0,  0, -1, -1, -1, -1,  0,  0]\n",
        "        col_offsets = [0, -1,  0, -1, -2, -3, -2, -3]\n",
        "\n",
        "    for i, j in zip(row_offsets, col_offsets):\n",
        "        cell = qr_cells_numeric[data_start_i+i, data_start_j+j]\n",
        "        result.append(int(cell if MASKS[mask_str](data_start_i+i, data_start_j+j) else not cell))\n",
        "\n",
        "    return result[:4] if direction == UP_ENC else result\n",
        "# enc = apply_mask(grid_cells_num-1, grid_cells_num-1, UP_ENC)\n",
        "# len = apply_mask(grid_cells_num-3, grid_cells_num-1, UP)\n",
        "# print(len)"
      ],
      "metadata": {
        "id": "4YhDqtyjUpOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(qr_cells,grid_cells_num):\n",
        "    MASKS = {\n",
        "        \"000\": lambda i, j: (i * j) % 2 + (i * j) % 3 == 0,\n",
        "        \"001\": lambda i, j: (i / 2 + j / 3) % 2 == 0,\n",
        "        \"010\": lambda i, j: ((i * j) % 3 + i + j) % 2 == 0,\n",
        "        \"011\": lambda i, j: ((i * j) % 3 + i * j) % 2 == 0,\n",
        "        \"100\": lambda i, j: i % 2 == 0,\n",
        "        \"101\": lambda i, j: (i + j) % 2 == 0,\n",
        "        \"110\": lambda i, j: (i + j) % 3 == 0,\n",
        "        \"111\": lambda i, j: j % 3 == 0,\n",
        "    }\n",
        "    UP, UP_ENC, DOWN, CW, CCW = range(5)  # A rather old-fashioned pythonic \"Enum\"\n",
        "    qr_cells_numeric=change_binary(qr_cells,grid_cells_num)\n",
        "    ecl=getecl(qr_cells_numeric)\n",
        "    mask,mask_str=get_mask(qr_cells_numeric)\n",
        "    fec=get_fec(qr_cells_numeric)\n",
        "    #showneededpixel(qr_cells_numeric)\n",
        "    makeinfo(ecl,mask,fec)\n",
        "\n",
        "    data_starting_indices = [\n",
        "    [grid_cells_num-7, grid_cells_num-1, UP],\n",
        "    [grid_cells_num-11, grid_cells_num-1, CCW],\n",
        "    [grid_cells_num-10, grid_cells_num-3, DOWN],\n",
        "    [grid_cells_num-6, grid_cells_num-3, DOWN],\n",
        "    [grid_cells_num-2, grid_cells_num-3, CW],\n",
        "    [grid_cells_num-3, grid_cells_num-5, UP],\n",
        "    [grid_cells_num-7, grid_cells_num-5, UP],\n",
        "    [grid_cells_num-11, grid_cells_num-5, CCW],\n",
        "    [grid_cells_num-10, grid_cells_num-7, DOWN],\n",
        "    [grid_cells_num-6, grid_cells_num-7, DOWN],\n",
        "    [grid_cells_num-2, grid_cells_num-7, CW],\n",
        "    [grid_cells_num-3, grid_cells_num-9, UP],\n",
        "    [grid_cells_num-7, grid_cells_num-9, UP],\n",
        "    [grid_cells_num-11, grid_cells_num-9, UP],\n",
        "    [grid_cells_num-16, grid_cells_num-9, UP],\n",
        "    [grid_cells_num-20, grid_cells_num-9, CCW],\n",
        "    [grid_cells_num-19, grid_cells_num-11, DOWN],\n",
        "    [grid_cells_num-14, grid_cells_num-11, DOWN],\n",
        "    [grid_cells_num-10, grid_cells_num-11, DOWN],\n",
        "    [grid_cells_num-6, grid_cells_num-11, DOWN],\n",
        "    # Hmm..? I actually don't know how to proceed now lol\n",
        "    ]\n",
        "\n",
        "    ans = ''\n",
        "    for a, b, d in data_starting_indices:\n",
        "        bits = apply_mask(qr_cells_numeric,a, b, d,UP,DOWN,CW,CCW,UP_ENC,MASKS,mask_str)\n",
        "        bit_string = ''.join([str(bit) for bit in bits])\n",
        "        if bit_string[:4] == \"0000\":\n",
        "            print(f'{bit_string[:4]} = 0 (NULL TERMINATOR)')\n",
        "            break\n",
        "        ans += chr(int(bit_string, 2)) # converts to binary to int, then to ASCII\n",
        "        print(f'{bit_string} = {ans[-1]}')\n",
        "    return ans\n",
        "decode(imgafterpreproc,grid_cells_num)"
      ],
      "metadata": {
        "id": "WYNLK_zmUzYN",
        "outputId": "a74479bb-ab27-40ec-fc4b-5efee55b2ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'grid_cells_num' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-4db2f5ac296c>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{bit_string} = {ans[-1]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgafterpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid_cells_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'grid_cells_num' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST DECODE SA7???"
      ],
      "metadata": {
        "id": "mjro6b7YU484"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tCaiInTgfZ79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check oreintation\n",
        "qr_cells,grid_cells_num,grid_cell_size,removeimg= getimageafterreshape(img)\n",
        "def checkoreintation(removeimg):\n",
        "    flipped_image = cv2.flip(removeimg, 1)\n",
        "    cv2_imshow(flipped_image)\n",
        "    #qr_cells,grid_cells_num,grid_cell_size,removeimg= getimageafterreshape(flipped_image)\n",
        "    #ans=decode(qr_cells,grid_cells_num)\n",
        "    print(ans)\n",
        "    return flipped_image\n",
        "print(\"HHH\")\n",
        "img=checkoreintation(removeimg)\n",
        "print(\"kkkk\")"
      ],
      "metadata": {
        "id": "BskfcQ1CfmKP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}