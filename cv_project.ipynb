{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FarahZayed/Qr-detector/blob/master/cv_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **import** **libraries**"
      ],
      "metadata": {
        "id": "UOj6ulzFR7Ki"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "GgLWkJvJR5Tu"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFilter\n",
        "import math\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the image"
      ],
      "metadata": {
        "id": "c3EIx7B1SRfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#insert the path of the image\n",
        "img = cv2.imread(\"/content/04-Black-mirror.png\", cv2.IMREAD_GRAYSCALE)\n",
        "_, thresh = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n"
      ],
      "metadata": {
        "id": "3ShONM6vSXcX"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Function ma7tgnha"
      ],
      "metadata": {
        "id": "0pH4EtGBSPDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def angle_ABC(a, b, c):\n",
        "\n",
        "\n",
        "    ba = a - b\n",
        "    bc = c - b\n",
        "\n",
        "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "    angle = np.arccos(cosine_angle)\n",
        "    return np.degrees(angle)\n",
        "\n",
        "def find_bad_dists(hull, distance = 10):\n",
        "    mask = []\n",
        "    points, _, _ = hull.shape\n",
        "\n",
        "    for i in range(points):\n",
        "        # determine points to compare and make sure that last and first are compared too\n",
        "        ai = i\n",
        "        bi = (i+1)%points\n",
        "        # x, y for both points\n",
        "        x1 = hull[ai][0][0]\n",
        "        y1 = hull[ai][0][1]\n",
        "        x2 = hull[bi][0][0]\n",
        "        y2 = hull[bi][0][1]\n",
        "\n",
        "        #distance\n",
        "        dist = np.sqrt((x2 - x1)**2 + (y2 - y1)**2 )\n",
        "        #build mask with distances out ot range\n",
        "        if dist < distance:\n",
        "            mask.append(bi)\n",
        "    return mask\n",
        "\n",
        "\n",
        "\n",
        "def find_bad_angles(hull, acute_angle = 30, obtuse_angle = 140):\n",
        "\n",
        "    mask = []\n",
        "    points, _, _ = hull.shape\n",
        "\n",
        "    for i in range(points):\n",
        "        # determine points to compare angle and make sure that last and first are compared too\n",
        "        ai = i\n",
        "        bi = (i+1)%points\n",
        "        ci = (i+2)%points\n",
        "\n",
        "\n",
        "        a = hull[ai][0]\n",
        "        b = hull[bi][0]\n",
        "        c = hull[ci][0]\n",
        "        angle = angle_ABC(a, b, c)\n",
        "        if angle > obtuse_angle or angle < acute_angle:\n",
        "            mask.append(bi)\n",
        "    return mask\n",
        "\n",
        "def mark_points(hull):\n",
        "    a_list=[]\n",
        "    points, _, _ = hull.shape\n",
        "\n",
        "    for i in range(points):\n",
        "        r = int(np.random.randint(100,255,1)[0])\n",
        "        g = int(np.random.randint(100,255,1)[0])\n",
        "        b = int(np.random.randint(100,255,1)[0])\n",
        "        a_list.append(tuple([hull[i][0][0], hull[i][0][1]]))\n",
        "\n",
        "    return a_list\n",
        "\n",
        "\n",
        "\n",
        "def shahd(img,thresh):\n",
        "\n",
        "        invimg = invert_image(img)\n",
        "\n",
        "        #invg = cv2.cvtColor(invimg,cv2.COLOR_RGB2GRAY)\n",
        "        ret,thresh = cv2.threshold(invimg,127,255,0)\n",
        "\n",
        "        contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "      #  image =  invg = cv2.cvtColor(invimg,cv2.COLOR_GRAY2RGB)\n",
        "        length = len(contours)\n",
        "        cont = np.concatenate([contours[i] for i in range(length)], axis=0)\n",
        "\n",
        "        cnt_len = cv2.arcLength(cont, True)\n",
        "        cont = cv2.approxPolyDP(cont, .01*cnt_len, True)\n",
        "        hull = cv2.convexHull(cont)\n",
        "\n",
        "\n",
        "        mask = find_bad_dists(hull)\n",
        "        hull = np.delete(hull, mask, axis=0)\n",
        "\n",
        "        mask = find_bad_angles(hull)\n",
        "        hull = np.delete(hull, mask, axis=0)\n",
        "\n",
        "        a_list=mark_points(hull)\n",
        "\n",
        "        uni_hull = []\n",
        "        uni_hull.append(hull)\n",
        "\n",
        "\n",
        "        shahdlist =  mark_points(hull)\n",
        "        return shahdlist\n"
      ],
      "metadata": {
        "id": "OJByWf-9B_h_"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_quietnoise(img):\n",
        "    start_row = -1\n",
        "    start_col = -1\n",
        "    end_row = -1\n",
        "    end_col = -1\n",
        "    for row_index, row in enumerate(img):\n",
        "     for pixel in row:\n",
        "        if pixel != 255:\n",
        "            start_row = row_index\n",
        "            break\n",
        "     if start_row != -1:\n",
        "        break\n",
        "    for row_index, row in enumerate(img[::-1]):\n",
        "     for pixel in row:\n",
        "        if pixel != 255:\n",
        "            end_row = img.shape[0] - row_index\n",
        "            break\n",
        "     if end_row != -1:\n",
        "        break\n",
        "    for col_index, col in enumerate(cv2.transpose(img)):\n",
        "     for pixel in col:\n",
        "        if pixel != 255:\n",
        "            start_col = col_index\n",
        "            break\n",
        "     if start_col != -1:\n",
        "        break\n",
        "    for col_index, col in enumerate(cv2.transpose(img)[::-1]):\n",
        "     for pixel in col:\n",
        "        if pixel != 255:\n",
        "            end_col = img.shape[1] - col_index\n",
        "            break\n",
        "     if end_col != -1:\n",
        "        break\n",
        "    qr_no_quiet_zone = img[start_row:end_row, start_col:end_col]\n",
        "    return qr_no_quiet_zone\n",
        "\n",
        "    fig = plt.figure(figsize=(5, 5));\n",
        "    plt.xticks([], []);\n",
        "    plt.yticks([], []);\n",
        "    fig.get_axes()[0].spines[:].set_color('red');\n",
        "    fig.get_axes()[0].spines[:].set_linewidth(40);\n",
        "    fig.get_axes()[0].spines[:].set_position((\"outward\", 20))\n",
        "    plt.title('QR code without quiet zone', y = 1.15, color='red');\n",
        "    plt.imshow(qr_no_quiet_zone, cmap='gray');\n",
        "\n",
        "def get_start_row_col(img):\n",
        "    start_row = -1\n",
        "    start_col = -1\n",
        "    for row_index, row in enumerate(img):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                start_row = row_index\n",
        "                break\n",
        "        if start_row != -1:\n",
        "            break\n",
        "    for col_index, col in enumerate(cv2.transpose(img)):\n",
        "        for pixel in col:\n",
        "            if pixel != 255:\n",
        "                start_col = col_index\n",
        "                break\n",
        "        if start_col != -1:\n",
        "            break\n",
        "    return start_row, start_col\n",
        "\n",
        "\n",
        "def getcellsizeForRotation(imgremove):\n",
        "    size=0\n",
        "    for pixel in imgremove[-1, ::-1]:\n",
        "      if (pixel != 0): break\n",
        "      size += 1\n",
        "    if(size ==0): return 0,0\n",
        "    grid_cell_size = round(size/7)\n",
        "    grid_cells_num = round(imgremove.shape[0]/grid_cell_size)\n",
        "    return grid_cell_size,grid_cells_num\n",
        "\n",
        "def getqrcell(remove):\n",
        "    if remove.shape[0] % grid_cell_size != 0 or remove.shape[1] % grid_cell_size != 0:\n",
        "            print(\"Warning: Grid cell size resulted in fraction. Adjusting...\")\n",
        "            img_resized = cv2.resize(remove, (924, 924))\n",
        "\n",
        "    # If the resized image is larger than the target size, crop it\n",
        "            if remove.shape[0] > 924 or remove.shape[1] > 924:\n",
        "                remove = img_resized[:924, :924]\n",
        "            else:\n",
        "                remove = img_resized\n",
        "    try:\n",
        "            qr_cells = remove.reshape((\n",
        "            grid_cells_num,\n",
        "            grid_cell_size,\n",
        "            grid_cells_num,\n",
        "            grid_cell_size,\n",
        "            )).swapaxes(1, 2)\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"Error: Unable to reshape image into grid cells.\")\n",
        "        qr_cells=0\n",
        "    return qr_cells\n",
        "\n",
        "def correctqrcell(qr_cells):\n",
        "\n",
        " for i in range(qr_cells.shape[0]):\n",
        "   for j in range(qr_cells.shape[1]):\n",
        "    cell=qr_cells[i][j]\n",
        "    white_pixel_count = np.sum(cell == 255)\n",
        "    black_pixel_count = np.sum(cell == 0)\n",
        "    if white_pixel_count > black_pixel_count:\n",
        "        for k in range(grid_cell_size):\n",
        "            for l in range(grid_cell_size):\n",
        "                qr_cells[i][j][k][l]=255\n",
        "    elif black_pixel_count > white_pixel_count:\n",
        "        for k in range(grid_cell_size):\n",
        "            for l in range(grid_cell_size):\n",
        "                qr_cells[i][j][k][l]=0\n",
        "\n",
        "\n",
        "    elif black_pixel_count == white_pixel_count:\n",
        "        for k in range(grid_cell_size):\n",
        "            for l in range(grid_cell_size):\n",
        "                qr_cells[i][j][k][l]=0\n",
        "    return qr_cells\n"
      ],
      "metadata": {
        "id": "LkeUEJYZSmMY"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# function that raise the flags"
      ],
      "metadata": {
        "id": "LieUdBISTZO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Note: rotation hat crash fi sorten 3ashan el binrization bytl3 kolo aswd aw kolo abyd fa mmken na3ml binarize 7asb el case\n",
        "#mesh 3arfa nashof?? PLUS el banana mafrod ttl3 anha rotated!!! mesh 3arf bardo\n",
        "def checkrotation(img):\n",
        "    imgremove= remove_quietnoise(img)\n",
        "    grid_cell_size,grid_cell_num= getcellsizeForRotation(imgremove)\n",
        "    print(grid_cell_size)\n",
        "    if grid_cell_size==0:\n",
        "        print(\"The image is not rotated it may have some other noise that must be solved first!!!\")\n",
        "        return False\n",
        "    inverted_img = cv2.bitwise_not(imgremove)\n",
        "    shapeofste=3*grid_cell_size -1\n",
        "    se_rect = cv2.getStructuringElement(cv2.MORPH_RECT, (shapeofste, shapeofste))\n",
        "    _, se_binarized = cv2.threshold(se_rect, 128, 1, cv2.THRESH_BINARY)\n",
        "    se_binarized = se_binarized.astype(int)\n",
        "    se_binarized[se_binarized == 0] = -1\n",
        "    erosion = cv2.erode(inverted_img, se_rect, iterations=1)\n",
        "    partwithrotato=erosion[(imgremove.shape[0]-7*grid_cell_size):imgremove.shape[0], imgremove.shape[1]-7*grid_cell_size:imgremove.shape[1]];\n",
        "    count=0\n",
        "    for row in range(partwithrotato.shape[0]):\n",
        "        for col in range(partwithrotato.shape[1]):\n",
        "            if partwithrotato[row,col] == 255:\n",
        "                count=count+1\n",
        "    if(count>0 and count<10):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def checkblured(image):\n",
        "    f_transform = np.fft.fft2(image)\n",
        "    f_transform_shifted = np.fft.fftshift(f_transform)\n",
        "    magnitude_spectrum = 20*np.log(np.abs(f_transform_shifted))\n",
        "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
        "    gradient_magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
        "    avg_gradient_magnitude = np.mean(gradient_magnitude)\n",
        "\n",
        "    frequency_threshold_max = 375\n",
        "    frequency_threshold_min=300\n",
        "    gradient_threshold_max =35\n",
        "    gradient_threshold_min= 20\n",
        "\n",
        "    if (frequency_threshold_min>np.max(magnitude_spectrum) or  frequency_threshold_max < np.max(magnitude_spectrum) ) or ( avg_gradient_magnitude > gradient_threshold_max or avg_gradient_magnitude<gradient_threshold_min):\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "#check mostly white\n",
        "def is_mostly_white(img):\n",
        "    row, col = img.shape\n",
        "    count=0\n",
        "    plt.show()\n",
        "    for i in range(row):\n",
        "        for j in range(col):\n",
        "            if (img[i][j] < 180) or (img[i][j] > 230) :\n",
        "                count=count+1\n",
        "    if count>0:\n",
        "       return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "#check shifting\n",
        "def detect_shift_rows(img):\n",
        "    start_row,start_col=get_start_row_col(img)\n",
        "    if start_row>0 and start_col>0 and start_col!=start_row:\n",
        "        if (start_row-start_col)<20 and (start_row-start_col)>10 :\n",
        "            return True\n",
        "        else:\n",
        "          return False\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "\n",
        "#checks skewness\n",
        "def checkskew(img):\n",
        "    skewflag=False\n",
        "    unwarpedflag=False\n",
        "    edges = cv2.Canny(img, 100, 200)\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if(contours ==() ):\n",
        "        return skewflag,unwarpedflag\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "    qr_code_region = img[y:y + h, x:x + w]\n",
        "    edges = cv2.Canny(qr_code_region, 50, 150, apertureSize=3)\n",
        "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)\n",
        "    if lines is None:\n",
        "        return skewflag,unwarpedflag\n",
        "    vertical_angles = []\n",
        "    horizontal_angles = []\n",
        "\n",
        "    for line in lines:\n",
        "        rho, theta = line[0]\n",
        "        if np.pi / 4 < theta < 3 * np.pi / 4:\n",
        "            vertical_angles.append(theta)\n",
        "        else:\n",
        "            horizontal_angles.append(theta)\n",
        "    vertical_skewness = np.mean(vertical_angles) if vertical_angles else 0\n",
        "    horizontal_skewness = np.mean(horizontal_angles) if horizontal_angles else 0\n",
        "\n",
        "    vertical_skewness_deg = round(np.rad2deg(vertical_skewness))\n",
        "    horizontal_skewness_deg = round(np.rad2deg(horizontal_skewness))\n",
        "    difference=round(abs(horizontal_skewness_deg - vertical_skewness_deg))\n",
        "    if(difference==90 and vertical_skewness_deg!=90 and horizontal_skewness_deg!=90):\n",
        "        skewflag=True\n",
        "        return skewflag,unwarpedflag\n",
        "    elif(horizontal_skewness_deg < 90 and horizontal_skewness_deg>10 and vertical_skewness_deg<90):\n",
        "        unwarpedflag=True\n",
        "        return skewflag,unwarpedflag\n",
        "    else:\n",
        "        return skewflag,unwarpedflag\n",
        "\n",
        "\n",
        "#check black image\n",
        "def is_mostly_black(image, threshold=0.9):\n",
        "\n",
        "    hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
        "\n",
        "    hist /= hist.sum()\n",
        "\n",
        "    cumulative_sum = hist.cumsum()\n",
        "\n",
        "    threshold_index = (cumulative_sum > threshold).argmax()\n",
        "\n",
        "    return threshold_index < 10\n",
        "\n",
        "def checkflip(img):\n",
        "    print(\"in checkk\")\n",
        "    print(checkrotation(img))\n",
        "    if(checkrotation(img)==False):\n",
        "        return False\n",
        "    img= cv2.flip(img, 1)\n",
        "    if(checkrotation(img) ==False):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def inversioncheck(img):\n",
        "    mean_intensity = cv2.mean(img)[0]\n",
        "    return mean_intensity < 100"
      ],
      "metadata": {
        "id": "RKjHTS4TTYM1"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# flags to do preprocessing"
      ],
      "metadata": {
        "id": "PzSFn2IAS6EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotationflag= checkrotation(img)\n",
        "bluredflag =checkblured(img)\n",
        "shiftedrowsflag= detect_shift_rows(img)\n",
        "mostlywhiteflag= is_mostly_white(img)\n",
        "skewedflag,unwarpedflag = checkskew(img)\n",
        "mostlyblackflag=is_mostly_black(img)\n",
        "inversionflag=inversioncheck(img)\n",
        "flipflag=checkflip(img)\n",
        "print(\"The flag of inverted image : \",inversionflag )\n",
        "print(\"The flag of rotation: \",rotationflag )\n",
        "print(\"The flag of all white image: \",mostlywhiteflag )\n",
        "print(\"The flag of blured image: \",bluredflag )\n",
        "print(\"The flag of shifted rows: \",shiftedrowsflag )\n",
        "print(\"The flag of skewed images : \",skewedflag )\n",
        "print(\"The flag of all black image : \",mostlyblackflag )\n",
        "print(\"The flag of unwarped image : \",unwarpedflag )\n",
        "print(\"The flag of flipped image : \",flipflag )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFBLVZSoTGFT",
        "outputId": "63ab9feb-3341-4ed2-e38f-674d6ecb5e33"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145\n",
            "in checkk\n",
            "145\n",
            "False\n",
            "145\n",
            "The flag of inverted image :  True\n",
            "The flag of rotation:  False\n",
            "The flag of all white image:  False\n",
            "The flag of blured image:  False\n",
            "The flag of shifted rows:  False\n",
            "The flag of skewed images :  False\n",
            "The flag of all black image :  False\n",
            "The flag of unwarped image :  False\n",
            "The flag of flipped image :  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function responsible for preprocessing"
      ],
      "metadata": {
        "id": "3imjv2MEUQYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def invert_image(image):\n",
        "    # inverted_gray = 255 - image\n",
        "    # inverted_image = cv2.cvtColor(inverted_gray, cv2.COLOR_GRAY2BGR)\n",
        "    inverted_image=cv2.bitwise_not(image)\n",
        "    return inverted_image\n",
        "\n",
        "def a3dlrotation(img):\n",
        "    print(\"in\")\n",
        "    imgremove= remove_quietnoise(img)\n",
        "    while(checkrotation(imgremove)):\n",
        "        imgremove = cv2.rotate(imgremove, cv2.ROTATE_90_CLOCKWISE)\n",
        "    return imgremove\n",
        "def flip(img):\n",
        "    while(checkflip(img)):\n",
        "     img=cv2.flip(img,1)\n",
        "    return img\n",
        "\n",
        "def nadafblured(img):\n",
        "         # nazbt el soraa\n",
        "        blurred = cv2.GaussianBlur(img, (7, 7), 0)\n",
        "        sharpened = cv2.addWeighted(img, 2.5, blurred, -0.5, 0)\n",
        "        _, thresh_img = cv2.threshold(sharpened, 127, 255, cv2.THRESH_BINARY)\n",
        "        #shalena el noise w shwait araf erode keda\n",
        "        remove= remove_quietnoise(thresh_img)\n",
        "        se_rect = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
        "        _, se_binarized = cv2.threshold(se_rect, 128, 1, cv2.THRESH_BINARY)\n",
        "        se_binarized = se_binarized.astype(int)\n",
        "        se_binarized[se_binarized == 0] = -1\n",
        "        erosion = cv2.erode(remove, se_binarized, iterations=1)\n",
        "        needcorrectionimg=erosion\n",
        "        return needcorrectionimg\n",
        "\n",
        "def unwarped(img,thresh):\n",
        "        listt  = shahd(img,thresh)\n",
        "        rows1 , cols1  = img.shape\n",
        "        pts2 = np.array([[cols1,rows1],[0,rows1],[0,0], [cols1,0]],np.float32)\n",
        "        pts1 = np.array(listt,np.float32)\n",
        "        M = cv2.getPerspectiveTransform(pts1,pts2)\n",
        "        dst = cv2.warpPerspective(img,M,(cols1,rows1))\n",
        "        return dst\n",
        "\n",
        "\n",
        "def edit_white_img(img):\n",
        "    first_pixel=img[0,0]\n",
        "    for i in range(img.shape[0]):\n",
        "        for j in range(img.shape[1]):\n",
        "            if img[i][j] == first_pixel:\n",
        "                img[i][j] = 225\n",
        "            else:\n",
        "                img[i][j] = 0\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "def solve_shifted_rows(img):\n",
        "    start_row = -1\n",
        "    start_col = -1\n",
        "    end_row = -1\n",
        "    end_col = -1\n",
        "    _, img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
        "    for row_index, row in enumerate(img):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                start_row = row_index\n",
        "                start_col =row_index\n",
        "                break\n",
        "        if start_row != -1:\n",
        "            break\n",
        "\n",
        "    for row_index, row in enumerate(img[::-1]):\n",
        "        for pixel in row:\n",
        "            if pixel != 255:\n",
        "                end_row = img.shape[0] - row_index\n",
        "                end_col =img.shape[0] - row_index\n",
        "                break\n",
        "        if end_row != -1:\n",
        "            break\n",
        "\n",
        "\n",
        "    qr_no_quiet_zone = img[start_row:end_row, start_col:end_col]\n",
        "\n",
        "    size = 0\n",
        "    for pixel in qr_no_quiet_zone[0]:\n",
        "        if (pixel != 0): break\n",
        "        size += 1\n",
        "\n",
        "    grid_cell_size = round(size/7)\n",
        "    grid_cells_num = round(qr_no_quiet_zone.shape[0]/grid_cell_size)\n",
        "\n",
        "    img_resized = cv2.resize(qr_no_quiet_zone, (grid_cells_num*grid_cell_size, grid_cells_num*grid_cell_size))\n",
        "\n",
        "    qr_cells = img_resized.reshape((\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "    )).swapaxes(1, 2)\n",
        "\n",
        "    # BRWANA 3AYZHA HENA LEHHH\n",
        "    for i in range(qr_cells.shape[0]):\n",
        "        for j in range(qr_cells.shape[1]):\n",
        "            cell=qr_cells[i][j]\n",
        "            white_pixel_count = np.sum(cell == 255)\n",
        "            black_pixel_count = np.sum(cell == 0)\n",
        "            if white_pixel_count > black_pixel_count:\n",
        "                for k in range(grid_cell_size):\n",
        "                    for l in range(grid_cell_size):\n",
        "                        qr_cells[i][j][k][l]=255\n",
        "            elif black_pixel_count > white_pixel_count:\n",
        "                for k in range(grid_cell_size):\n",
        "                    for l in range(grid_cell_size):\n",
        "                        qr_cells[i][j][k][l]=0\n",
        "\n",
        "\n",
        "            elif black_pixel_count == white_pixel_count:\n",
        "                for k in range(grid_cell_size):\n",
        "                    for l in range(grid_cell_size):\n",
        "                        qr_cells[i][j][k][l]=0\n",
        "    return img_resized\n",
        "\n",
        "\n",
        "def dalma(image):\n",
        "        image1 = image\n",
        "        thresh,binary_image = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "        image = cv2.inpaint(image1, binary_image, inpaintRadius=3,flags=cv2.INPAINT_TELEA)\n",
        "\n",
        "\n",
        "\n",
        "        mask = cv2.threshold(image, 10, 255, cv2.THRESH_BINARY)[1]\n",
        "\n",
        "        lightened_image = np.where(mask == 255, np.clip(image * 100, 0, 255).astype(np.uint8), image)\n",
        "\n",
        "        _, mask = cv2.threshold(lightened_image, 75, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        mask = cv2.bitwise_not(mask)\n",
        "\n",
        "        _, bimage = cv2.threshold(lightened_image, 0, 255, cv2.THRESH_BINARY)\n",
        "        return bimage\n",
        "\n",
        "def orientSkewness(img):\n",
        "        _, img = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
        "        edges = cv2.Canny(img, 100, 200)\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "        qr_code_region = img[y:y + h, x:x + w]\n",
        "        # Apply edge detection\n",
        "        edges = cv2.Canny(qr_code_region, 50, 150, apertureSize=3)\n",
        "        lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)\n",
        "        vertical_angles = []\n",
        "        horizontal_angles = []\n",
        "\n",
        "        for line in lines:\n",
        "            rho, theta = line[0]\n",
        "            if np.pi / 4 < theta < 3 * np.pi / 4:\n",
        "                vertical_angles.append(theta)\n",
        "            else:\n",
        "                horizontal_angles.append(theta)\n",
        "\n",
        "        vertical_skewness = np.mean(vertical_angles) if vertical_angles else 0\n",
        "        horizontal_skewness = np.mean(horizontal_angles) if horizontal_angles else 0\n",
        "\n",
        "        vertical_skewness_deg = np.rad2deg(vertical_skewness)\n",
        "        horizontal_skewness_deg = np.rad2deg(horizontal_skewness)\n",
        "\n",
        "        rotation_angle_deg = 180+horizontal_skewness_deg\n",
        "        rows, cols = img.shape[:2]\n",
        "        rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotation_angle_deg, 1)\n",
        "        img = cv2.warpAffine(img, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR,\n",
        "                                    borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255) )\n",
        "\n",
        "        qr_code_region = cv2.warpAffine(qr_code_region, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR,\n",
        "                            borderMode=cv2.BORDER_CONSTANT)\n",
        "\n",
        "        contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        rect = cv2.minAreaRect(largest_contour)\n",
        "        angle = rect[-1]\n",
        "        if angle < -45:\n",
        "            angle += 90\n",
        "\n",
        "        rows, cols = img.shape[:2]\n",
        "        rotation_matrix = cv2.getRotationMatrix2D(rect[0], angle, 1)\n",
        "        rotated_image = cv2.warpAffine(img, rotation_matrix, (cols, rows), flags=cv2.INTER_LINEAR,\n",
        "                                    borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "        border_width = 20  # Adjust the border width as needed\n",
        "        border_color = (255, 255, 255)  # White color\n",
        "        img = cv2.copyMakeBorder(img, border_width, border_width, border_width, border_width,\n",
        "                                            cv2.BORDER_CONSTANT, value=border_color)\n",
        "        if(checkrotation(img)):\n",
        "            img=a3dlrotation(img)\n",
        "            return img\n",
        "        else: return img\n",
        "\n",
        "\n",
        "def decompresso_espreso(img):\n",
        "    # convert to binary image\n",
        "    _, imgBinary = cv2.threshold(img, 170, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # apply Gaussian blur to smooth the image\n",
        "    blurred = cv2.GaussianBlur(imgBinary, (5, 5), 0)\n",
        "\n",
        "    # opening--> erosion then dilation 3ashan asheel el abyad and did finetuning till weselt le number of iterations da\n",
        "    # a 5x5 kernel of ones (3x3 msh hatenfa3)\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    eroded = cv2.erode(blurred, kernel, iterations = 6)\n",
        "    dilated = cv2.dilate(eroded, kernel, iterations = 7)\n",
        "    return dilated\n",
        "\n"
      ],
      "metadata": {
        "id": "C2-13QUoUTMv"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "8L3NxC3xUH_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgafterpreproc=img\n",
        "\n",
        "if(rotationflag==True):\n",
        "    imgafterpreproc= a3dlrotation(img)\n",
        "if(bluredflag==True):\n",
        "    imgafterpreproc= nadafblured(img)\n",
        "if(mostlywhiteflag==True):\n",
        "    imgafterpreproc=edit_white_img(img)\n",
        "if(shiftedrowsflag==True):\n",
        "    imgafterpreproc = solve_shifted_rows(img)\n",
        "if(mostlyblackflag==True):\n",
        "    imgafterpreproc=dalma(img)\n",
        "if(skewedflag ==True):\n",
        "    imgafterpreproc=orientSkewness(img)\n",
        "if(unwarpedflag ==True):\n",
        "    imgafterpreproc=unwarped(img,thresh)\n",
        "#ba2et el if\n",
        "# plt.imshow(imgafterpreproc,cmap='gray')"
      ],
      "metadata": {
        "id": "qc794tlrUHp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgafterpreproc=img\n",
        "while(rotationflag or bluredflag or inversionflag or mostlywhiteflag or shiftedrowsflag or mostlyblackflag or skewedflag or unwarpedflag or flipflag):\n",
        "    if(inversionflag == True):\n",
        "        imgafterpreproc=invert_image(imgafterpreproc)\n",
        "    if(rotationflag==True):\n",
        "        imgafterpreproc= a3dlrotation(imgafterpreproc)\n",
        "    if(bluredflag==True):\n",
        "        imgafterpreproc= nadafblured(imgafterpreproc)\n",
        "    if(mostlywhiteflag==True):\n",
        "        imgafterpreproc=edit_white_img(imgafterpreproc)\n",
        "    if(shiftedrowsflag==True):\n",
        "        imgafterpreproc = solve_shifted_rows(imgafterpreproc)\n",
        "    if(mostlyblackflag==True):\n",
        "        imgafterpreproc=dalma(imgafterpreproc)\n",
        "    if(skewedflag ==True):\n",
        "        imgafterpreproc=orientSkewness(imgafterpreproc)\n",
        "    if(unwarpedflag ==True):\n",
        "        _, thresh = cv2.threshold(imgafterpreproc, 128, 255, cv2.THRESH_BINARY)\n",
        "        imgafterpreproc=unwarped(imgafterpreproc,thresh)\n",
        "    if(flipflag== True):\n",
        "        imgafterpreproc=flip(imgafterpreproc)\n",
        "    rotationflag= checkrotation(imgafterpreproc)\n",
        "    bluredflag =checkblured(imgafterpreproc)\n",
        "    shiftedrowsflag= detect_shift_rows(imgafterpreproc)\n",
        "    mostlywhiteflag= is_mostly_white(imgafterpreproc)\n",
        "    skewedflag,unwarpedflag = checkskew(imgafterpreproc)\n",
        "    mostlyblackflag=is_mostly_black(imgafterpreproc)\n",
        "    inversionflag=inversioncheck(imgafterpreproc)\n",
        "    flipflag=checkflip(imgafterpreproc)\n",
        "\n",
        "\n",
        "\n",
        "plt.imshow(imgafterpreproc,cmap='gray')"
      ],
      "metadata": {
        "id": "n52jZ1uBDVTm",
        "outputId": "ef540c87-487d-474a-ef19-aa1add3d1f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "The image is not rotated it may have some other noise that must be solved first!!!\n",
            "in checkk\n",
            "0\n",
            "The image is not rotated it may have some other noise that must be solved first!!!\n",
            "False\n",
            "0\n",
            "The image is not rotated it may have some other noise that must be solved first!!!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ed0f2e23fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 155
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reshape** hy5osh 3ala decode"
      ],
      "metadata": {
        "id": "DiJDka4pVBOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#later note:mmken nb2a nashel el condition el zayda wala ba an el sora ela 7ad ma htro7 mazbota shwia\n",
        "\n",
        "def getimageafterreshape(img):\n",
        "    #dah 3ak ATSRFYYYY\n",
        "    if(img[0][0]==255):\n",
        "        imgremove,_,_ = remove_quietnoise(img)\n",
        "\n",
        "    else:\n",
        "        inverted_img = cv2.bitwise_not(img)            #noha 3ayza el invert hena\n",
        "        imgremove,_,_ = remove_quietnoise(inverted_img)\n",
        "\n",
        "    size = 0\n",
        "\n",
        "    #h8yr hena leh 3ashan el taree2 dih mesh htnf3 3ala kol el sewar zay el rotated fa ana h7sb el 3aded el pixel bel change w inshallah 5er\n",
        "    if(imgremove[0][0]==255):\n",
        "        for pixel in imgremove[-1, ::-1]:\n",
        "         if (pixel != 0): break\n",
        "         size += 1\n",
        "\n",
        "    else:\n",
        "        for pixel in imgremove[0]:\n",
        "         if (pixel != 0): break\n",
        "         size += 1\n",
        "    grid_cell_size = round(size/7)\n",
        "    print(grid_cell_size)\n",
        "    grid_cells_num = round(imgremove.shape[0]/grid_cell_size)\n",
        "    print(grid_cells_num)\n",
        "    #NOHAAA\n",
        "    if imgremove.shape[0] % grid_cell_size != 0 or imgremove.shape[1] % grid_cell_size != 0:\n",
        "        print(\"Warning: Grid cell size resulted in fraction. Adjusting...\")\n",
        "        img_resized = cv2.resize(imgremove, (924, 924))\n",
        "\n",
        "# If the resized image is larger than the target size, crop it\n",
        "\n",
        "        if img_resized.shape[0] > 924 or img_resized.shape[1] > 924:\n",
        "            imgremove = img_resized[:924, :924]\n",
        "        else:\n",
        "            imgremove = img_resized\n",
        "\n",
        "\n",
        "            #cv2_imshow(imgremove)\n",
        "\n",
        "    try:\n",
        "\n",
        "        qr_cells = imgremove.reshape((\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "        grid_cells_num,\n",
        "        grid_cell_size,\n",
        "        )).swapaxes(1, 2)\n",
        "        plt.imshow(imgremove,cmap='gray')\n",
        "        _, axes = plt.subplots(grid_cells_num, grid_cells_num, figsize=(5, 5))\n",
        "        for i, row in enumerate(axes):\n",
        "          for j, col in enumerate(row):\n",
        "              col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
        "              col.get_xaxis().set_visible(False)\n",
        "              col.get_yaxis().set_visible(False)\n",
        "              col.spines[:].set_color('red')\n",
        "\n",
        "\n",
        "        return qr_cells,grid_cells_num,grid_cell_size,imgremove\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"Error: Unable to reshape image into grid cells.\")\n",
        "        return \"none\",grid_cells_num,grid_cell_size,imgremove\n",
        "\n",
        "\n",
        "\n",
        "#plt.imshow(imgremove,cmap='gray')\n",
        "\n",
        "#salama\n",
        "# print(size)\n",
        "# grid_cell_size = round(size/7)\n",
        "# print(grid_cell_size)\n",
        "# grid_cells_num = round(imgremove.shape[0]/grid_cell_size)\n",
        "# print(grid_cells_num)\n",
        "# qr_cells = imgremove.reshape((\n",
        "#     grid_cells_num,\n",
        "#     grid_cell_size,\n",
        "#     grid_cells_num,\n",
        "#     grid_cell_size,\n",
        "# )).swapaxes(1, 2)\n",
        "# plt.imshow(imgremove,cmap='gray')\n",
        "# _, axes = plt.subplots(grid_cells_num, grid_cells_num, figsize=(5, 5))\n",
        "# for i, row in enumerate(axes):\n",
        "#     for j, col in enumerate(row):\n",
        "#         col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
        "#         col.get_xaxis().set_visible(False)\n",
        "#         col.get_yaxis().set_visible(False)\n",
        "#         col.spines[:].set_color('red')\n"
      ],
      "metadata": {
        "id": "ky3ogaTVSrtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decode"
      ],
      "metadata": {
        "id": "lAK7kIcDSHTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def change_binary(qr_cell,grid_cell_num):\n",
        "    qr_cells_numeric = np.ndarray((grid_cells_num, grid_cells_num), dtype=np.uint8)\n",
        "    for i, row in enumerate(qr_cells):\n",
        "        for j, cell in enumerate(row):\n",
        "            qr_cells_numeric[i, j] = (np.median(cell) // 255)\n",
        "    return qr_cells_numeric"
      ],
      "metadata": {
        "id": "ORTXvspcSGnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getecl(qr_cells_numeric):\n",
        "    qr_cells_numeric[8]\n",
        "    # The first two bits determine the error correction level\n",
        "    # Level L (Low)         [11]\t7%  of data bytes can be restored.\n",
        "    # Level M (Medium)      [10]\t15% of data bytes can be restored.\n",
        "    # Level Q (Quartile)    [01]\t25% of data bytes can be restored.\n",
        "    # Level H (High)        [00]\t30% of data bytes can be restored.\n",
        "    ecl = [int(not(c)) for c in qr_cells_numeric[8, 0:2]]\n",
        "    # Why \"not\"? Because the standard uses '1's for black and '0's for white\n",
        "    #\n",
        "    # \"A dark module is a binary one and a light module is a binary zero.\"\n",
        "    #  - ISO/IEC 18004:2000(E)\n",
        "    #\n",
        "    # In image processing, we use them the other way.. Hence the inversion\n",
        "    return ecl\n",
        "\n",
        "def get_mask(qr_cells_numeric):\n",
        "    # Dictionary of all masks and their equivalent formulae\n",
        "    # Same row as above, the three cells after the ecl cells (converted to a string)\n",
        "    mask = [int(not(c)) for c in qr_cells_numeric[8, 2:5]]\n",
        "    mask_str = ''.join([str(c) for c in mask])\n",
        "    return mask,mask_str\n",
        "\n",
        "def get_fec(qr_cells_numeric):\n",
        "    fec = []\n",
        "    fec.append(qr_cells_numeric[8, 5])\n",
        "    fec.append(qr_cells_numeric[8, 7])\n",
        "    fec.extend(qr_cells_numeric[0:6, 8])\n",
        "    fec.extend(qr_cells_numeric[7:9, 8])\n",
        "    fec = [int(not(c)) for c in fec]\n",
        "    return fec\n",
        "\n",
        "\n",
        "#def showneededpixel(qr_cells_numeric):\n",
        "#    _, axes = plt.subplots(grid_cells_num, grid_cells_num, figsize=(5, 5))\n",
        "#    for i, row in enumerate(axes):\n",
        "#        for j, col in enumerate(row):\n",
        "\n",
        "            # col.get_xaxis().set_visible(False)\n",
        "            # col.get_yaxis().set_visible(False)\n",
        "            # if (i == 8 and j <= 8) or (i <= 8 and j == 8):\n",
        "            #     if (i != 6) and (j != 6):\n",
        "            #         col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=0, vmax=255)\n",
        "            #         col.spines[:].set_color('red')\n",
        "            #         continue\n",
        "            # col.imshow(qr_cells[i][j], cmap=\"gray\", vmin=-1275, vmax=510)"
      ],
      "metadata": {
        "id": "lOGyoteyR6RD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def makeinfo(ecl,mask,fec):\n",
        "    ecl[0] ^= 1\n",
        "    mask[0] ^= 1\n",
        "    mask[2] ^= 1\n",
        "    fec[5] ^= 1\n",
        "    fec[8] ^= 1\n",
        "\n",
        "# Before we proceed, let's write a function for masking to make our lives easier\n",
        "\n",
        "\n",
        "def apply_mask(qr_cells_numeric,data_start_i, data_start_j, direction,UP,DOWN,CW,CCW,UP_ENC,MASKS,mask_str):\n",
        "\n",
        "    '''\n",
        "    data_start_i/j represent the first cell's coords in its respective direction\n",
        "    direction is the masking direction, up(-enc)/down/clockwise/anti-clockwise\n",
        "    '''\n",
        "\n",
        "    result = []\n",
        "    row_offsets = []\n",
        "    col_offsets = []\n",
        "    if (direction in [UP, UP_ENC]):\n",
        "        row_offsets = [0,  0, -1, -1, -2, -2, -3, -3]\n",
        "        col_offsets = [0, -1,  0, -1,  0, -1,  0, -1]\n",
        "    if (direction == DOWN):\n",
        "        row_offsets = [0,  0,  1,  1,  2,  2,  3,  3]\n",
        "        col_offsets = [0, -1,  0, -1,  0, -1,  0, -1]\n",
        "    if (direction == CW):\n",
        "        row_offsets = [0,  0,  1,  1,  1,  1,  0,  0]\n",
        "        col_offsets = [0, -1,  0, -1, -2, -3, -2, -3]\n",
        "    if (direction == CCW):\n",
        "        row_offsets = [0,  0, -1, -1, -1, -1,  0,  0]\n",
        "        col_offsets = [0, -1,  0, -1, -2, -3, -2, -3]\n",
        "\n",
        "    for i, j in zip(row_offsets, col_offsets):\n",
        "        cell = qr_cells_numeric[data_start_i+i, data_start_j+j]\n",
        "        result.append(int(cell if MASKS[mask_str](data_start_i+i, data_start_j+j) else not cell))\n",
        "\n",
        "    return result[:4] if direction == UP_ENC else result\n",
        "# enc = apply_mask(grid_cells_num-1, grid_cells_num-1, UP_ENC)\n",
        "# len = apply_mask(grid_cells_num-3, grid_cells_num-1, UP)\n",
        "# print(len)"
      ],
      "metadata": {
        "id": "4YhDqtyjUpOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(qr_cells,grid_cells_num):\n",
        "    MASKS = {\n",
        "        \"000\": lambda i, j: (i * j) % 2 + (i * j) % 3 == 0,\n",
        "        \"001\": lambda i, j: (i / 2 + j / 3) % 2 == 0,\n",
        "        \"010\": lambda i, j: ((i * j) % 3 + i + j) % 2 == 0,\n",
        "        \"011\": lambda i, j: ((i * j) % 3 + i * j) % 2 == 0,\n",
        "        \"100\": lambda i, j: i % 2 == 0,\n",
        "        \"101\": lambda i, j: (i + j) % 2 == 0,\n",
        "        \"110\": lambda i, j: (i + j) % 3 == 0,\n",
        "        \"111\": lambda i, j: j % 3 == 0,\n",
        "    }\n",
        "    UP, UP_ENC, DOWN, CW, CCW = range(5)  # A rather old-fashioned pythonic \"Enum\"\n",
        "    qr_cells_numeric=change_binary(qr_cells,grid_cells_num)\n",
        "    ecl=getecl(qr_cells_numeric)\n",
        "    mask,mask_str=get_mask(qr_cells_numeric)\n",
        "    fec=get_fec(qr_cells_numeric)\n",
        "    #showneededpixel(qr_cells_numeric)\n",
        "    makeinfo(ecl,mask,fec)\n",
        "\n",
        "    data_starting_indices = [\n",
        "    [grid_cells_num-7, grid_cells_num-1, UP],\n",
        "    [grid_cells_num-11, grid_cells_num-1, CCW],\n",
        "    [grid_cells_num-10, grid_cells_num-3, DOWN],\n",
        "    [grid_cells_num-6, grid_cells_num-3, DOWN],\n",
        "    [grid_cells_num-2, grid_cells_num-3, CW],\n",
        "    [grid_cells_num-3, grid_cells_num-5, UP],\n",
        "    [grid_cells_num-7, grid_cells_num-5, UP],\n",
        "    [grid_cells_num-11, grid_cells_num-5, CCW],\n",
        "    [grid_cells_num-10, grid_cells_num-7, DOWN],\n",
        "    [grid_cells_num-6, grid_cells_num-7, DOWN],\n",
        "    [grid_cells_num-2, grid_cells_num-7, CW],\n",
        "    [grid_cells_num-3, grid_cells_num-9, UP],\n",
        "    [grid_cells_num-7, grid_cells_num-9, UP],\n",
        "    [grid_cells_num-11, grid_cells_num-9, UP],\n",
        "    [grid_cells_num-16, grid_cells_num-9, UP],\n",
        "    [grid_cells_num-20, grid_cells_num-9, CCW],\n",
        "    [grid_cells_num-19, grid_cells_num-11, DOWN],\n",
        "    [grid_cells_num-14, grid_cells_num-11, DOWN],\n",
        "    [grid_cells_num-10, grid_cells_num-11, DOWN],\n",
        "    [grid_cells_num-6, grid_cells_num-11, DOWN],\n",
        "    # Hmm..? I actually don't know how to proceed now lol\n",
        "    ]\n",
        "\n",
        "    ans = ''\n",
        "    for a, b, d in data_starting_indices:\n",
        "        bits = apply_mask(qr_cells_numeric,a, b, d,UP,DOWN,CW,CCW,UP_ENC,MASKS,mask_str)\n",
        "        bit_string = ''.join([str(bit) for bit in bits])\n",
        "        if bit_string[:4] == \"0000\":\n",
        "            print(f'{bit_string[:4]} = 0 (NULL TERMINATOR)')\n",
        "            break\n",
        "        ans += chr(int(bit_string, 2)) # converts to binary to int, then to ASCII\n",
        "        print(f'{bit_string} = {ans[-1]}')\n",
        "    return ans\n",
        "decode(imgafterpreproc,grid_cells_num)"
      ],
      "metadata": {
        "id": "WYNLK_zmUzYN",
        "outputId": "a74479bb-ab27-40ec-fc4b-5efee55b2ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'grid_cells_num' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-4db2f5ac296c>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{bit_string} = {ans[-1]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgafterpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid_cells_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'grid_cells_num' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST DECODE SA7???"
      ],
      "metadata": {
        "id": "mjro6b7YU484"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tCaiInTgfZ79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check oreintation\n",
        "qr_cells,grid_cells_num,grid_cell_size,removeimg= getimageafterreshape(img)\n",
        "def checkoreintation(removeimg):\n",
        "    flipped_image = cv2.flip(removeimg, 1)\n",
        "    cv2_imshow(flipped_image)\n",
        "    #qr_cells,grid_cells_num,grid_cell_size,removeimg= getimageafterreshape(flipped_image)\n",
        "    #ans=decode(qr_cells,grid_cells_num)\n",
        "    print(ans)\n",
        "    return flipped_image\n",
        "print(\"HHH\")\n",
        "img=checkoreintation(removeimg)\n",
        "print(\"kkkk\")"
      ],
      "metadata": {
        "id": "BskfcQ1CfmKP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}